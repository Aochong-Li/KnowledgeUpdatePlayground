                                                
{'loss': 1.6221, 'grad_norm': 88.9676284790039, 'learning_rate': 6.25e-08, 'epoch': 0.0}
{'loss': 1.7343, 'grad_norm': 86.10255432128906, 'learning_rate': 1.25e-07, 'epoch': 0.01}
{'loss': 1.6457, 'grad_norm': 132.0984344482422, 'learning_rate': 1.875e-07, 'epoch': 0.01}
{'loss': 1.6196, 'grad_norm': 91.8897476196289, 'learning_rate': 2.5e-07, 'epoch': 0.01}
{'loss': 1.7787, 'grad_norm': 4924.9150390625, 'learning_rate': 3.1249999999999997e-07, 'epoch': 0.02}
{'loss': 1.5069, 'grad_norm': 35.86575698852539, 'learning_rate': 3.75e-07, 'epoch': 0.02}
{'loss': 1.4818, 'grad_norm': 14.75890064239502, 'learning_rate': 4.375e-07, 'epoch': 0.02}
{'loss': 1.4926, 'grad_norm': 20.840770721435547, 'learning_rate': 5e-07, 'epoch': 0.03}
{'loss': 1.4992, 'grad_norm': 21.985029220581055, 'learning_rate': 5.625e-07, 'epoch': 0.03}
{'loss': 1.5676, 'grad_norm': 15.651805877685547, 'learning_rate': 6.249999999999999e-07, 'epoch': 0.03}
{'loss': 1.4789, 'grad_norm': 10.878486633300781, 'learning_rate': 6.875e-07, 'epoch': 0.04}
{'loss': 1.473, 'grad_norm': 21.79714584350586, 'learning_rate': 7.5e-07, 'epoch': 0.04}
{'loss': 1.3459, 'grad_norm': 7.315750598907471, 'learning_rate': 8.125e-07, 'epoch': 0.04}
{'loss': 1.4687, 'grad_norm': 4.564352035522461, 'learning_rate': 8.75e-07, 'epoch': 0.05}
{'loss': 1.4746, 'grad_norm': 13.46090030670166, 'learning_rate': 9.374999999999999e-07, 'epoch': 0.05}
{'loss': 1.5057, 'grad_norm': 7.5931267738342285, 'learning_rate': 1e-06, 'epoch': 0.05}
{'loss': 1.4657, 'grad_norm': 6.575123310089111, 'learning_rate': 9.999704580069346e-07, 'epoch': 0.06}
{'loss': 1.5193, 'grad_norm': 11.999911308288574, 'learning_rate': 9.998818355186559e-07, 'epoch': 0.06}
{'loss': 1.3844, 'grad_norm': 7.913625240325928, 'learning_rate': 9.997341430075035e-07, 'epoch': 0.06}
{'loss': 1.246, 'grad_norm': 22.668254852294922, 'learning_rate': 9.995273979260021e-07, 'epoch': 0.07}
{'loss': 1.3858, 'grad_norm': 7.603207588195801, 'learning_rate': 9.99261624704799e-07, 'epoch': 0.07}
{'loss': 1.4271, 'grad_norm': 7.549336910247803, 'learning_rate': 9.989368547497761e-07, 'epoch': 0.07}
{'loss': 1.5183, 'grad_norm': 456.9930725097656, 'learning_rate': 9.98553126438341e-07, 'epoch': 0.08}
{'loss': 1.4519, 'grad_norm': 3.727799654006958, 'learning_rate': 9.981104851148903e-07, 'epoch': 0.08}
{'loss': 1.351, 'grad_norm': 254.8307647705078, 'learning_rate': 9.976089830854513e-07, 'epoch': 0.08}
{'loss': 1.3705, 'grad_norm': 5.449299335479736, 'learning_rate': 9.97048679611502e-07, 'epoch': 0.09}
{'loss': 1.1977, 'grad_norm': 3.9307961463928223, 'learning_rate': 9.964296409029675e-07, 'epoch': 0.09}
{'loss': 1.4137, 'grad_norm': 4.786599636077881, 'learning_rate': 9.957519401103972e-07, 'epoch': 0.09}
{'loss': 1.3966, 'grad_norm': 4.957669734954834, 'learning_rate': 9.95015657316319e-07, 'epoch': 0.09}
{'loss': 1.3357, 'grad_norm': 5.492462158203125, 'learning_rate': 9.942208795257785e-07, 'epoch': 0.1}
{'loss': 1.3812, 'grad_norm': 28.832321166992188, 'learning_rate': 9.93367700656055e-07, 'epoch': 0.1}
{'loss': 1.236, 'grad_norm': 6.272480487823486, 'learning_rate': 9.924562215255655e-07, 'epoch': 0.1}
{'loss': 1.3493, 'grad_norm': 3.404364585876465, 'learning_rate': 9.91486549841951e-07, 'epoch': 0.11}
{'loss': 1.3318, 'grad_norm': 5.221589088439941, 'learning_rate': 9.904588001893476e-07, 'epoch': 0.11}
{'loss': 1.2525, 'grad_norm': 3.8750810623168945, 'learning_rate': 9.89373094014848e-07, 'epoch': 0.11}
{'loss': 1.2841, 'grad_norm': 3.7918882369995117, 'learning_rate': 9.882295596141496e-07, 'epoch': 0.12}
{'loss': 1.2191, 'grad_norm': 5.993936061859131, 'learning_rate': 9.870283321163932e-07, 'epoch': 0.12}
{'loss': 1.4799, 'grad_norm': 4.503109931945801, 'learning_rate': 9.85769553468197e-07, 'epoch': 0.12}
{'loss': 1.4662, 'grad_norm': 3.90165376663208, 'learning_rate': 9.84453372416881e-07, 'epoch': 0.13}
{'loss': 1.4117, 'grad_norm': 5.7341413497924805, 'learning_rate': 9.83079944492891e-07, 'epoch': 0.13}
{'loss': 1.2379, 'grad_norm': 4.970424652099609, 'learning_rate': 9.816494319914202e-07, 'epoch': 0.13}
{'loss': 1.3239, 'grad_norm': 2.9411070346832275, 'learning_rate': 9.801620039532302e-07, 'epoch': 0.14}
{'loss': 1.3108, 'grad_norm': 3.469867467880249, 'learning_rate': 9.78617836144676e-07, 'epoch': 0.14}
{'loss': 1.5114, 'grad_norm': 3.438194513320923, 'learning_rate': 9.770171110369362e-07, 'epoch': 0.14}
{'loss': 1.3902, 'grad_norm': 8.766556739807129, 'learning_rate': 9.753600177844511e-07, 'epoch': 0.15}
{'loss': 1.3534, 'grad_norm': 4.6936235427856445, 'learning_rate': 9.736467522025703e-07, 'epoch': 0.15}
{'loss': 1.2511, 'grad_norm': 4.119572639465332, 'learning_rate': 9.718775167444138e-07, 'epoch': 0.15}
{'loss': 1.1712, 'grad_norm': 3.772188425064087, 'learning_rate': 9.700525204769475e-07, 'epoch': 0.16}
{'loss': 1.3401, 'grad_norm': 3.1074626445770264, 'learning_rate': 9.6817197905628e-07, 'epoch': 0.16}
{'loss': 1.2046, 'grad_norm': 3.666318416595459, 'learning_rate': 9.66236114702178e-07, 'epoch': 0.16}
{'loss': 1.1406, 'grad_norm': 3.7872936725616455, 'learning_rate': 9.642451561718062e-07, 'epoch': 0.17}
{'loss': 1.25, 'grad_norm': 3.487168073654175, 'learning_rate': 9.621993387326977e-07, 'epoch': 0.17}
{'loss': 1.0814, 'grad_norm': 159.5499725341797, 'learning_rate': 9.600989041349503e-07, 'epoch': 0.17}
{'loss': 1.3953, 'grad_norm': 3.00079083442688, 'learning_rate': 9.579441005826615e-07, 'epoch': 0.18}
{'loss': 1.3263, 'grad_norm': 3.3555872440338135, 'learning_rate': 9.55735182704598e-07, 'epoch': 0.18}
{'loss': 1.2632, 'grad_norm': 3.3123321533203125, 'learning_rate': 9.534724115241058e-07, 'epoch': 0.18}
{'loss': 1.21, 'grad_norm': 2.8883347511291504, 'learning_rate': 9.511560544282675e-07, 'epoch': 0.19}
{'loss': 1.3357, 'grad_norm': 21.758108139038086, 'learning_rate': 9.487863851363037e-07, 'epoch': 0.19}
{'loss': 1.3093, 'grad_norm': 3.2860519886016846, 'learning_rate': 9.463636836672298e-07, 'epoch': 0.19}
{'loss': 1.2884, 'grad_norm': 3.132796049118042, 'learning_rate': 9.43888236306766e-07, 'epoch': 0.2}
{'loss': 1.297, 'grad_norm': 4.936842441558838, 'learning_rate': 9.413603355735068e-07, 'epoch': 0.2}
{'loss': 1.2639, 'grad_norm': 6.743327617645264, 'learning_rate': 9.387802801843562e-07, 'epoch': 0.2}
{'loss': 1.3373, 'grad_norm': 4.432375907897949, 'learning_rate': 9.361483750192281e-07, 'epoch': 0.21}
{'loss': 1.2152, 'grad_norm': 9.154409408569336, 'learning_rate': 9.334649310850188e-07, 'epoch': 0.21}
{'loss': 1.2111, 'grad_norm': 3.8377082347869873, 'learning_rate': 9.307302654788567e-07, 'epoch': 0.21}
{'loss': 1.2803, 'grad_norm': 3.2665369510650635, 'learning_rate': 9.279447013506312e-07, 'epoch': 0.22}
{'loss': 1.2374, 'grad_norm': 1551.6571044921875, 'learning_rate': 9.251085678648071e-07, 'epoch': 0.22}
{'loss': 1.383, 'grad_norm': 3.17014741897583, 'learning_rate': 9.222222001615274e-07, 'epoch': 0.22}
{'loss': 1.2022, 'grad_norm': 3.3524298667907715, 'learning_rate': 9.192859393170107e-07, 'epoch': 0.23}
{'loss': 1.3562, 'grad_norm': 3.304042100906372, 'learning_rate': 9.163001323032473e-07, 'epoch': 0.23}
{'loss': 1.4634, 'grad_norm': 3.153726100921631, 'learning_rate': 9.132651319469974e-07, 'epoch': 0.23}
{'loss': 1.2881, 'grad_norm': 3.1488354206085205, 'learning_rate': 9.10181296888099e-07, 'epoch': 0.24}
{'loss': 1.1436, 'grad_norm': 2.8242347240448, 'learning_rate': 9.070489915370876e-07, 'epoch': 0.24}
{'loss': 1.2378, 'grad_norm': 3.4993669986724854, 'learning_rate': 9.038685860321354e-07, 'epoch': 0.24}
{'loss': 1.4373, 'grad_norm': 5.707894802093506, 'learning_rate': 9.006404561953114e-07, 'epoch': 0.25}
{'loss': 1.3769, 'grad_norm': 5.262243270874023, 'learning_rate': 8.973649834881729e-07, 'epoch': 0.25}
{'loss': 1.1709, 'grad_norm': 2.917733669281006, 'learning_rate': 8.94042554966688e-07, 'epoch': 0.25}
{'loss': 1.2083, 'grad_norm': 3.429962635040283, 'learning_rate': 8.906735632354978e-07, 'epoch': 0.26}
{'loss': 1.2763, 'grad_norm': 4.368435859680176, 'learning_rate': 8.872584064015241e-07, 'epoch': 0.26}
{'loss': 1.3179, 'grad_norm': 2.802886962890625, 'learning_rate': 8.837974880269245e-07, 'epoch': 0.26}
{'loss': 1.2801, 'grad_norm': 3.0150082111358643, 'learning_rate': 8.802912170814059e-07, 'epoch': 0.27}
{'loss': 1.2843, 'grad_norm': 3.0203053951263428, 'learning_rate': 8.767400078938958e-07, 'epoch': 0.27}
{'loss': 1.3298, 'grad_norm': 31.136253356933594, 'learning_rate': 8.731442801035831e-07, 'epoch': 0.27}
{'loss': 1.1598, 'grad_norm': 3.179616689682007, 'learning_rate': 8.695044586103295e-07, 'epoch': 0.27}
{'loss': 1.1532, 'grad_norm': 3.2885594367980957, 'learning_rate': 8.658209735244603e-07, 'epoch': 0.28}
{'loss': 1.179, 'grad_norm': 3.030484199523926, 'learning_rate': 8.620942601159393e-07, 'epoch': 0.28}
{'loss': 1.393, 'grad_norm': 5.559247016906738, 'learning_rate': 8.583247587629326e-07, 'epoch': 0.28}
{'loss': 1.3079, 'grad_norm': 3.4678030014038086, 'learning_rate': 8.545129148997718e-07, 'epoch': 0.29}
{'loss': 1.1873, 'grad_norm': 2.8527724742889404, 'learning_rate': 8.506591789643169e-07, 'epoch': 0.29}
{'loss': 1.1832, 'grad_norm': 32.62582778930664, 'learning_rate': 8.467640063447288e-07, 'epoch': 0.29}
{'loss': 1.3458, 'grad_norm': 4.008626937866211, 'learning_rate': 8.428278573256577e-07, 'epoch': 0.3}
{'loss': 1.1609, 'grad_norm': 2.9606289863586426, 'learning_rate': 8.388511970338517e-07, 'epoch': 0.3}
{'loss': 1.3254, 'grad_norm': 3.5670430660247803, 'learning_rate': 8.348344953831938e-07, 'epoch': 0.3}
{'loss': 1.4242, 'grad_norm': 3.294693946838379, 'learning_rate': 8.307782270191732e-07, 'epoch': 0.31}
{'loss': 1.0946, 'grad_norm': 12.221077919006348, 'learning_rate': 8.266828712627976e-07, 'epoch': 0.31}
{'loss': 1.2137, 'grad_norm': 3.73980450630188, 'learning_rate': 8.225489120539521e-07, 'epoch': 0.31}
{'loss': 1.3875, 'grad_norm': 3.504634141921997, 'learning_rate': 8.183768378942142e-07, 'epoch': 0.32}
{'loss': 1.3047, 'grad_norm': 2.9168832302093506, 'learning_rate': 8.141671417891273e-07, 'epoch': 0.32}
{'loss': 1.1198, 'grad_norm': 6.682754993438721, 'learning_rate': 8.099203211899441e-07, 'epoch': 0.32}
{'loss': 1.3242, 'grad_norm': 3.0648481845855713, 'learning_rate': 8.056368779348431e-07, 'epoch': 0.33}
{'loss': 1.318, 'grad_norm': 4.464173316955566, 'learning_rate': 8.013173181896282e-07, 'epoch': 0.33}
{'loss': 1.1897, 'grad_norm': 3.3995509147644043, 'learning_rate': 7.969621523879156e-07, 'epoch': 0.33}
{'loss': 1.2484, 'grad_norm': 7.464644908905029, 'learning_rate': 7.92571895170817e-07, 'epoch': 0.34}
{'loss': 1.2688, 'grad_norm': 3.38020396232605, 'learning_rate': 7.881470653261251e-07, 'epoch': 0.34}
{'loss': 1.2116, 'grad_norm': 2.938527822494507, 'learning_rate': 7.836881857270105e-07, 'epoch': 0.34}
{'loss': 1.1184, 'grad_norm': 2.8449888229370117, 'learning_rate': 7.791957832702343e-07, 'epoch': 0.35}
{'loss': 1.1972, 'grad_norm': 2.9856576919555664, 'learning_rate': 7.746703888138848e-07, 'epoch': 0.35}
{'loss': 1.1595, 'grad_norm': 2.953047037124634, 'learning_rate': 7.701125371146491e-07, 'epoch': 0.35}
{'loss': 1.2077, 'grad_norm': 2.780479669570923, 'learning_rate': 7.6552276676462e-07, 'epoch': 0.36}
{'loss': 1.2006, 'grad_norm': 5.6451592445373535, 'learning_rate': 7.609016201276532e-07, 'epoch': 0.36}
{'loss': 1.6014, 'grad_norm': 3.55439829826355, 'learning_rate': 7.562496432752761e-07, 'epoch': 0.36}
{'loss': 1.2182, 'grad_norm': 3.330753803253174, 'learning_rate': 7.515673859221605e-07, 'epoch': 0.37}
{'loss': 1.363, 'grad_norm': 3.378511905670166, 'learning_rate': 7.468554013611632e-07, 'epoch': 0.37}
{'loss': 1.1216, 'grad_norm': 3.9575114250183105, 'learning_rate': 7.421142463979453e-07, 'epoch': 0.37}
{'loss': 1.0688, 'grad_norm': 3.204535722732544, 'learning_rate': 7.37344481285175e-07, 'epoch': 0.38}
{'loss': 1.13, 'grad_norm': 2.805107355117798, 'learning_rate': 7.325466696563238e-07, 'epoch': 0.38}
{'loss': 1.2191, 'grad_norm': 3.1052098274230957, 'learning_rate': 7.277213784590629e-07, 'epoch': 0.38}
{'loss': 1.1478, 'grad_norm': 3.3574490547180176, 'learning_rate': 7.228691778882692e-07, 'epoch': 0.39}
{'loss': 1.2613, 'grad_norm': 2.9625673294067383, 'learning_rate': 7.179906413186447e-07, 'epoch': 0.39}
{'loss': 1.288, 'grad_norm': 7.000211715698242, 'learning_rate': 7.130863452369635e-07, 'epoch': 0.39}
{'loss': 1.0937, 'grad_norm': 6.903616905212402, 'learning_rate': 7.081568691739491e-07, 'epoch': 0.4}
{'loss': 1.441, 'grad_norm': 3.3846118450164795, 'learning_rate': 7.032027956357922e-07, 'epoch': 0.4}
{'loss': 1.0998, 'grad_norm': 2.9042882919311523, 'learning_rate': 6.982247100353171e-07, 'epoch': 0.4}
{'loss': 1.3209, 'grad_norm': 3.2927093505859375, 'learning_rate': 6.932232006228051e-07, 'epoch': 0.41}
{'loss': 1.4336, 'grad_norm': 4.2115960121154785, 'learning_rate': 6.881988584164815e-07, 'epoch': 0.41}
{'loss': 1.282, 'grad_norm': 2.8628904819488525, 'learning_rate': 6.831522771326769e-07, 'epoch': 0.41}
{'loss': 1.1664, 'grad_norm': 18.674118041992188, 'learning_rate': 6.780840531156684e-07, 'epoch': 0.42}
{'loss': 1.1567, 'grad_norm': 4.5109357833862305, 'learning_rate': 6.729947852672114e-07, 'epoch': 0.42}
{'loss': 1.2738, 'grad_norm': 2.952239990234375, 'learning_rate': 6.678850749757672e-07, 'epoch': 0.42}
{'loss': 1.2852, 'grad_norm': 3.6673073768615723, 'learning_rate': 6.627555260454403e-07, 'epoch': 0.43}
{'loss': 1.2014, 'grad_norm': 3.046103000640869, 'learning_rate': 6.576067446246262e-07, 'epoch': 0.43}
{'loss': 1.1898, 'grad_norm': 3.007765054702759, 'learning_rate': 6.524393391343852e-07, 'epoch': 0.43}
{'loss': 1.1712, 'grad_norm': 3.178866386413574, 'learning_rate': 6.472539201965457e-07, 'epoch': 0.44}
{'loss': 1.3789, 'grad_norm': 3.3001039028167725, 'learning_rate': 6.42051100561549e-07, 'epoch': 0.44}
{'loss': 1.2593, 'grad_norm': 2.877596855163574, 'learning_rate': 6.368314950360415e-07, 'epoch': 0.44}
{'loss': 1.2268, 'grad_norm': 3.1111364364624023, 'learning_rate': 6.31595720410224e-07, 'epoch': 0.45}
{'loss': 1.2861, 'grad_norm': 3.300835609436035, 'learning_rate': 6.263443953849674e-07, 'epoch': 0.45}
{'loss': 1.3588, 'grad_norm': 3.594808578491211, 'learning_rate': 6.210781404987015e-07, 'epoch': 0.45}
{'loss': 1.1617, 'grad_norm': 2.894561290740967, 'learning_rate': 6.157975780540876e-07, 'epoch': 0.45}
{'loss': 1.27, 'grad_norm': 3.044809103012085, 'learning_rate': 6.105033320444824e-07, 'epoch': 0.46}
{'loss': 1.1837, 'grad_norm': 3.4283030033111572, 'learning_rate': 6.051960280802014e-07, 'epoch': 0.46}
{'loss': 1.3453, 'grad_norm': 3.499051809310913, 'learning_rate': 5.99876293314592e-07, 'epoch': 0.46}
{'loss': 1.2517, 'grad_norm': 3.09317946434021, 'learning_rate': 5.945447563699247e-07, 'epoch': 0.47}
{'loss': 1.2048, 'grad_norm': 2.881474018096924, 'learning_rate': 5.892020472631092e-07, 'epoch': 0.47}
{'loss': 1.2249, 'grad_norm': 3.438413381576538, 'learning_rate': 5.838487973312472e-07, 'epoch': 0.47}
{'loss': 1.1859, 'grad_norm': 6.250654220581055, 'learning_rate': 5.784856391570279e-07, 'epoch': 0.48}
{'loss': 1.2425, 'grad_norm': 3.039231061935425, 'learning_rate': 5.731132064939777e-07, 'epoch': 0.48}
{'loss': 1.2633, 'grad_norm': 2.9789047241210938, 'learning_rate': 5.677321341915707e-07, 'epoch': 0.48}
{'loss': 1.2236, 'grad_norm': 3.883596181869507, 'learning_rate': 5.623430581202091e-07, 'epoch': 0.49}
{'loss': 1.3328, 'grad_norm': 3.5634677410125732, 'learning_rate': 5.569466150960851e-07, 'epoch': 0.49}
{'loss': 1.1739, 'grad_norm': 17.832250595092773, 'learning_rate': 5.515434428059279e-07, 'epoch': 0.49}
{'loss': 1.2245, 'grad_norm': 4.167012691497803, 'learning_rate': 5.46134179731651e-07, 'epoch': 0.5}
{'loss': 1.3842, 'grad_norm': 3.326709270477295, 'learning_rate': 5.407194650749033e-07, 'epoch': 0.5}
{'loss': 1.429, 'grad_norm': 3.4484381675720215, 'learning_rate': 5.35299938681536e-07, 'epoch': 0.5}
{'loss': 1.2395, 'grad_norm': 2.978512763977051, 'learning_rate': 5.29876240965994e-07, 'epoch': 0.51}
{'loss': 1.027, 'grad_norm': 2.732102870941162, 'learning_rate': 5.244490128356381e-07, 'epoch': 0.51}
{'loss': 1.3471, 'grad_norm': 3.308736801147461, 'learning_rate': 5.190188956150114e-07, 'epoch': 0.51}
{'loss': 1.2203, 'grad_norm': 3.8242342472076416, 'learning_rate': 5.135865309700556e-07, 'epoch': 0.52}
{'loss': 1.2244, 'grad_norm': 4.0487589836120605, 'learning_rate': 5.081525608322847e-07, 'epoch': 0.52}
{'loss': 1.4001, 'grad_norm': 3.216517686843872, 'learning_rate': 5.027176273229317e-07, 'epoch': 0.52}
{'loss': 1.0961, 'grad_norm': 3.3248376846313477, 'learning_rate': 4.972823726770684e-07, 'epoch': 0.53}
{'loss': 1.2758, 'grad_norm': 3.960294485092163, 'learning_rate': 4.918474391677154e-07, 'epoch': 0.53}
{'loss': 1.2916, 'grad_norm': 2.9835920333862305, 'learning_rate': 4.864134690299445e-07, 'epoch': 0.53}
{'loss': 1.0867, 'grad_norm': 2.972463369369507, 'learning_rate': 4.809811043849886e-07, 'epoch': 0.54}
{'loss': 1.0941, 'grad_norm': 2.916902780532837, 'learning_rate': 4.7555098716436206e-07, 'epoch': 0.54}
{'loss': 1.4162, 'grad_norm': 4.211612224578857, 'learning_rate': 4.7012375903400626e-07, 'epoch': 0.54}
{'loss': 1.2637, 'grad_norm': 2.7946555614471436, 'learning_rate': 4.64700061318464e-07, 'epoch': 0.55}
{'loss': 1.1392, 'grad_norm': 3.5575966835021973, 'learning_rate': 4.592805349250968e-07, 'epoch': 0.55}
{'loss': 1.3428, 'grad_norm': 3.947209358215332, 'learning_rate': 4.5386582026834904e-07, 'epoch': 0.55}
{'loss': 1.2773, 'grad_norm': 5.414252758026123, 'learning_rate': 4.484565571940722e-07, 'epoch': 0.56}
{'loss': 1.1809, 'grad_norm': 4.60446310043335, 'learning_rate': 4.4305338490391495e-07, 'epoch': 0.56}
{'loss': 1.0995, 'grad_norm': 2.8627052307128906, 'learning_rate': 4.376569418797908e-07, 'epoch': 0.56}
{'loss': 1.1235, 'grad_norm': 7.755227088928223, 'learning_rate': 4.322678658084294e-07, 'epoch': 0.57}
{'loss': 1.3056, 'grad_norm': 3.0870492458343506, 'learning_rate': 4.2688679350602224e-07, 'epoch': 0.57}
{'loss': 1.1292, 'grad_norm': 3.3369743824005127, 'learning_rate': 4.2151436084297217e-07, 'epoch': 0.57}
{'loss': 1.363, 'grad_norm': 3.0247066020965576, 'learning_rate': 4.1615120266875273e-07, 'epoch': 0.58}
{'loss': 1.0717, 'grad_norm': 3.28586483001709, 'learning_rate': 4.107979527368908e-07, 'epoch': 0.58}
{'loss': 1.1107, 'grad_norm': 3.100275754928589, 'learning_rate': 4.054552436300752e-07, 'epoch': 0.58}
{'loss': 1.1764, 'grad_norm': 3.5937812328338623, 'learning_rate': 4.0012370668540806e-07, 'epoch': 0.59}
{'loss': 1.3239, 'grad_norm': 3.9771525859832764, 'learning_rate': 3.948039719197987e-07, 'epoch': 0.59}
{'loss': 1.2561, 'grad_norm': 3.140878915786743, 'learning_rate': 3.8949666795551766e-07, 'epoch': 0.59}
{'loss': 1.3348, 'grad_norm': 5.429477214813232, 'learning_rate': 3.8420242194591235e-07, 'epoch': 0.6}
{'loss': 1.1754, 'grad_norm': 2.828946113586426, 'learning_rate': 3.789218595012986e-07, 'epoch': 0.6}
{'loss': 1.1643, 'grad_norm': 3.3171889781951904, 'learning_rate': 3.7365560461503265e-07, 'epoch': 0.6}
{'loss': 1.1591, 'grad_norm': 3.249598741531372, 'learning_rate': 3.6840427958977607e-07, 'epoch': 0.61}
{'loss': 1.2084, 'grad_norm': 3.8822555541992188, 'learning_rate': 3.6316850496395855e-07, 'epoch': 0.61}
{'loss': 1.3291, 'grad_norm': 10.144576072692871, 'learning_rate': 3.579488994384511e-07, 'epoch': 0.61}
{'loss': 1.1507, 'grad_norm': 3.4102001190185547, 'learning_rate': 3.5274607980345426e-07, 'epoch': 0.62}
{'loss': 1.0884, 'grad_norm': 2.95182466506958, 'learning_rate': 3.47560660865615e-07, 'epoch': 0.62}
{'loss': 1.2963, 'grad_norm': 4.459776401519775, 'learning_rate': 3.4239325537537386e-07, 'epoch': 0.62}
{'loss': 1.1344, 'grad_norm': 2.885420083999634, 'learning_rate': 3.372444739545598e-07, 'epoch': 0.63}
{'loss': 1.3187, 'grad_norm': 3.0629122257232666, 'learning_rate': 3.321149250242328e-07, 'epoch': 0.63}
{'loss': 1.1366, 'grad_norm': 2.9586985111236572, 'learning_rate': 3.2700521473278887e-07, 'epoch': 0.63}
{'loss': 1.3158, 'grad_norm': 3.0550596714019775, 'learning_rate': 3.2191594688433154e-07, 'epoch': 0.64}
{'loss': 1.251, 'grad_norm': 5.656479358673096, 'learning_rate': 3.1684772286732307e-07, 'epoch': 0.64}
{'loss': 1.2328, 'grad_norm': 3.187242269515991, 'learning_rate': 3.1180114158351854e-07, 'epoch': 0.64}
{'loss': 1.1354, 'grad_norm': 2.893296480178833, 'learning_rate': 3.067767993771949e-07, 'epoch': 0.64}
{'loss': 1.2466, 'grad_norm': 3.498905658721924, 'learning_rate': 3.017752899646828e-07, 'epoch': 0.65}
{'loss': 1.371, 'grad_norm': 3.9797418117523193, 'learning_rate': 2.967972043642077e-07, 'epoch': 0.65}
{'loss': 1.2251, 'grad_norm': 5.956329822540283, 'learning_rate': 2.918431308260508e-07, 'epoch': 0.65}
{'loss': 1.3089, 'grad_norm': 5.102209568023682, 'learning_rate': 2.869136547630364e-07, 'epoch': 0.66}
{'loss': 1.1075, 'grad_norm': 2.9061129093170166, 'learning_rate': 2.8200935868135544e-07, 'epoch': 0.66}
{'loss': 1.2129, 'grad_norm': 3.0654096603393555, 'learning_rate': 2.771308221117309e-07, 'epoch': 0.66}
{'loss': 1.2266, 'grad_norm': 3.5022668838500977, 'learning_rate': 2.722786215409372e-07, 'epoch': 0.67}
{'loss': 1.1958, 'grad_norm': 298.3020324707031, 'learning_rate': 2.6745333034367625e-07, 'epoch': 0.67}
{'loss': 1.1952, 'grad_norm': 10.57701587677002, 'learning_rate': 2.6265551871482507e-07, 'epoch': 0.67}
{'loss': 1.3179, 'grad_norm': 3.2817976474761963, 'learning_rate': 2.5788575360205465e-07, 'epoch': 0.68}
{'loss': 1.3378, 'grad_norm': 3.009528636932373, 'learning_rate': 2.531445986388369e-07, 'epoch': 0.68}
{'loss': 1.1631, 'grad_norm': 2.9963126182556152, 'learning_rate': 2.4843261407783964e-07, 'epoch': 0.68}
{'loss': 1.2175, 'grad_norm': 3.0978572368621826, 'learning_rate': 2.4375035672472395e-07, 'epoch': 0.69}
{'loss': 1.0711, 'grad_norm': 3.422581672668457, 'learning_rate': 2.3909837987234675e-07, 'epoch': 0.69}
{'loss': 1.3214, 'grad_norm': 3.805159568786621, 'learning_rate': 2.3447723323538e-07, 'epoch': 0.69}
{'loss': 1.313, 'grad_norm': 4.027999401092529, 'learning_rate': 2.2988746288535093e-07, 'epoch': 0.7}
{'loss': 1.1789, 'grad_norm': 3.769169330596924, 'learning_rate': 2.2532961118611525e-07, 'epoch': 0.7}
{'loss': 1.103, 'grad_norm': 3.0295968055725098, 'learning_rate': 2.2080421672976567e-07, 'epoch': 0.7}
{'loss': 1.2021, 'grad_norm': 9.24472427368164, 'learning_rate': 2.1631181427298945e-07, 'epoch': 0.71}
{'loss': 1.1903, 'grad_norm': 3.176633834838867, 'learning_rate': 2.1185293467387494e-07, 'epoch': 0.71}
{'loss': 1.1623, 'grad_norm': 2.9442834854125977, 'learning_rate': 2.074281048291831e-07, 'epoch': 0.71}
{'loss': 1.2601, 'grad_norm': 3.288151264190674, 'learning_rate': 2.0303784761208453e-07, 'epoch': 0.72}
{'loss': 1.2056, 'grad_norm': 4.352603435516357, 'learning_rate': 1.9868268181037184e-07, 'epoch': 0.72}
{'loss': 1.267, 'grad_norm': 3.084695339202881, 'learning_rate': 1.9436312206515692e-07, 'epoch': 0.72}
{'loss': 1.216, 'grad_norm': 3.2055246829986572, 'learning_rate': 1.9007967881005587e-07, 'epoch': 0.73}
{'loss': 1.1762, 'grad_norm': 6.746618747711182, 'learning_rate': 1.858328582108727e-07, 'epoch': 0.73}
{'loss': 1.1083, 'grad_norm': 3.027492046356201, 'learning_rate': 1.8162316210578572e-07, 'epoch': 0.73}
{'loss': 1.2155, 'grad_norm': 4.216857433319092, 'learning_rate': 1.7745108794604773e-07, 'epoch': 0.74}
{'loss': 1.1295, 'grad_norm': 3.1286051273345947, 'learning_rate': 1.7331712873720234e-07, 'epoch': 0.74}
{'loss': 1.0434, 'grad_norm': 3.3746771812438965, 'learning_rate': 1.692217729808268e-07, 'epoch': 0.74}
{'loss': 1.0614, 'grad_norm': 3.220085859298706, 'learning_rate': 1.6516550461680623e-07, 'epoch': 0.75}
{'loss': 1.3108, 'grad_norm': 3.5444209575653076, 'learning_rate': 1.6114880296614842e-07, 'epoch': 0.75}
{'loss': 1.3463, 'grad_norm': 4.8230719566345215, 'learning_rate': 1.5717214267434232e-07, 'epoch': 0.75}
{'loss': 1.4718, 'grad_norm': 5.327930450439453, 'learning_rate': 1.5323599365527118e-07, 'epoch': 0.76}
{'loss': 1.2053, 'grad_norm': 2.9805455207824707, 'learning_rate': 1.4934082103568306e-07, 'epoch': 0.76}
{'loss': 1.1829, 'grad_norm': 2.8487751483917236, 'learning_rate': 1.4548708510022822e-07, 'epoch': 0.76}
{'loss': 1.1883, 'grad_norm': 3.207792043685913, 'learning_rate': 1.4167524123706743e-07, 'epoch': 0.77}
{'loss': 1.3353, 'grad_norm': 3.298297643661499, 'learning_rate': 1.3790573988406072e-07, 'epoch': 0.77}
{'loss': 1.2946, 'grad_norm': 3.8264191150665283, 'learning_rate': 1.3417902647553948e-07, 'epoch': 0.77}
{'loss': 1.3161, 'grad_norm': 3.5978944301605225, 'learning_rate': 1.304955413896705e-07, 'epoch': 0.78}
{'loss': 1.3894, 'grad_norm': 3.124838352203369, 'learning_rate': 1.2685571989641697e-07, 'epoch': 0.78}
{'loss': 1.3715, 'grad_norm': 3.0756006240844727, 'learning_rate': 1.2325999210610422e-07, 'epoch': 0.78}
{'loss': 1.1519, 'grad_norm': 3.5528833866119385, 'learning_rate': 1.1970878291859421e-07, 'epoch': 0.79}
{'loss': 1.279, 'grad_norm': 3.335352897644043, 'learning_rate': 1.1620251197307535e-07, 'epoch': 0.79}
{'loss': 1.0994, 'grad_norm': 3.487581729888916, 'learning_rate': 1.127415935984759e-07, 'epoch': 0.79}
{'loss': 1.2787, 'grad_norm': 3.8471553325653076, 'learning_rate': 1.0932643676450204e-07, 'epoch': 0.8}
{'loss': 1.2314, 'grad_norm': 13.460590362548828, 'learning_rate': 1.0595744503331206e-07, 'epoch': 0.8}
{'loss': 1.3076, 'grad_norm': 2.977289915084839, 'learning_rate': 1.0263501651182704e-07, 'epoch': 0.8}
{'loss': 1.2413, 'grad_norm': 2.7671091556549072, 'learning_rate': 9.935954380468859e-08, 'epoch': 0.81}
{'loss': 1.1315, 'grad_norm': 3.334303379058838, 'learning_rate': 9.613141396786461e-08, 'epoch': 0.81}
{'loss': 1.2757, 'grad_norm': 3.177365303039551, 'learning_rate': 9.295100846291237e-08, 'epoch': 0.81}
{'loss': 1.1837, 'grad_norm': 3.373189687728882, 'learning_rate': 8.981870311190098e-08, 'epoch': 0.82}
{'loss': 1.2222, 'grad_norm': 3.040625810623169, 'learning_rate': 8.673486805300262e-08, 'epoch': 0.82}
{'loss': 1.2963, 'grad_norm': 3.3586108684539795, 'learning_rate': 8.369986769675269e-08, 'epoch': 0.82}
{'loss': 1.1269, 'grad_norm': 3.02781081199646, 'learning_rate': 8.071406068298925e-08, 'epoch': 0.82}
{'loss': 1.1258, 'grad_norm': 3.0838778018951416, 'learning_rate': 7.77777998384726e-08, 'epoch': 0.83}
{'loss': 1.1878, 'grad_norm': 2.945072650909424, 'learning_rate': 7.4891432135193e-08, 'epoch': 0.83}
{'loss': 1.283, 'grad_norm': 3.485161542892456, 'learning_rate': 7.205529864936882e-08, 'epoch': 0.83}
{'loss': 1.2003, 'grad_norm': 37.79732131958008, 'learning_rate': 6.926973452114337e-08, 'epoch': 0.84}
{'loss': 1.1467, 'grad_norm': 2.835801839828491, 'learning_rate': 6.653506891498118e-08, 'epoch': 0.84}
{'loss': 1.3224, 'grad_norm': 2.93381667137146, 'learning_rate': 6.38516249807719e-08, 'epoch': 0.84}
{'loss': 1.2295, 'grad_norm': 3.025986671447754, 'learning_rate': 6.121971981564367e-08, 'epoch': 0.85}
{'loss': 1.2758, 'grad_norm': 3.6108365058898926, 'learning_rate': 5.8639664426493265e-08, 'epoch': 0.85}
{'loss': 1.1532, 'grad_norm': 3.4850428104400635, 'learning_rate': 5.611176369323412e-08, 'epoch': 0.85}
{'loss': 1.0116, 'grad_norm': 2.7075772285461426, 'learning_rate': 5.363631633277005e-08, 'epoch': 0.86}
{'loss': 1.3772, 'grad_norm': 3.1127171516418457, 'learning_rate': 5.121361486369624e-08, 'epoch': 0.86}
{'loss': 1.1181, 'grad_norm': 2.836528778076172, 'learning_rate': 4.884394557173249e-08, 'epoch': 0.86}
{'loss': 1.3707, 'grad_norm': 2.9540133476257324, 'learning_rate': 4.6527588475894165e-08, 'epoch': 0.87}
{'loss': 1.3523, 'grad_norm': 2.932204246520996, 'learning_rate': 4.426481729540204e-08, 'epoch': 0.87}
{'loss': 1.1536, 'grad_norm': 2.933830976486206, 'learning_rate': 4.2055899417338335e-08, 'epoch': 0.87}
{'loss': 1.1798, 'grad_norm': 3.8139150142669678, 'learning_rate': 3.990109586504964e-08, 'epoch': 0.88}
{'loss': 1.2826, 'grad_norm': 3.118446111679077, 'learning_rate': 3.780066126730241e-08, 'epoch': 0.88}
{'loss': 1.3075, 'grad_norm': 3.3750360012054443, 'learning_rate': 3.5754843828193715e-08, 'epoch': 0.88}
{'loss': 1.1402, 'grad_norm': 3.133122682571411, 'learning_rate': 3.376388529782215e-08, 'epoch': 0.89}
{'loss': 1.1601, 'grad_norm': 2.9171905517578125, 'learning_rate': 3.182802094371989e-08, 'epoch': 0.89}
{'loss': 1.219, 'grad_norm': 2.8895163536071777, 'learning_rate': 2.9947479523052547e-08, 'epoch': 0.89}
{'loss': 1.0613, 'grad_norm': 2.7783520221710205, 'learning_rate': 2.812248325558625e-08, 'epoch': 0.9}
{'loss': 1.5164, 'grad_norm': 3.164590358734131, 'learning_rate': 2.6353247797429534e-08, 'epoch': 0.9}
{'loss': 1.3161, 'grad_norm': 2.969759941101074, 'learning_rate': 2.4639982215548747e-08, 'epoch': 0.9}
{'loss': 1.0106, 'grad_norm': 3.230570077896118, 'learning_rate': 2.2982888963063774e-08, 'epoch': 0.91}
{'loss': 1.0868, 'grad_norm': 2.904386281967163, 'learning_rate': 2.1382163855324098e-08, 'epoch': 0.91}
{'loss': 1.2093, 'grad_norm': 3.121643304824829, 'learning_rate': 1.9837996046769835e-08, 'epoch': 0.91}
{'loss': 1.112, 'grad_norm': 5.106141090393066, 'learning_rate': 1.8350568008579704e-08, 'epoch': 0.92}
{'loss': 1.1587, 'grad_norm': 3.3689889907836914, 'learning_rate': 1.692005550710901e-08, 'epoch': 0.92}
{'loss': 1.2405, 'grad_norm': 3.520055055618286, 'learning_rate': 1.5546627583119087e-08, 'epoch': 0.92}
{'loss': 1.2926, 'grad_norm': 2.8874332904815674, 'learning_rate': 1.4230446531802998e-08, 'epoch': 0.93}
{'loss': 1.3771, 'grad_norm': 3.2267956733703613, 'learning_rate': 1.2971667883606652e-08, 'epoch': 0.93}
{'loss': 1.2757, 'grad_norm': 3.723597526550293, 'learning_rate': 1.17704403858504e-08, 'epoch': 0.93}
{'loss': 1.2794, 'grad_norm': 2.9847731590270996, 'learning_rate': 1.0626905985151868e-08, 'epoch': 0.94}
{'loss': 1.2926, 'grad_norm': 3.0500481128692627, 'learning_rate': 9.541199810652379e-09, 'epoch': 0.94}
{'loss': 1.3049, 'grad_norm': 3.1047933101654053, 'learning_rate': 8.513450158049106e-09, 'epoch': 0.94}
{'loss': 1.2047, 'grad_norm': 8.0750150680542, 'learning_rate': 7.543778474434436e-09, 'epoch': 0.95}
{'loss': 1.2411, 'grad_norm': 20.354944229125977, 'learning_rate': 6.632299343945102e-09, 'epoch': 0.95}
{'loss': 1.1676, 'grad_norm': 3.3517227172851562, 'learning_rate': 5.779120474221521e-09, 'epoch': 0.95}
{'loss': 1.3394, 'grad_norm': 3.138608932495117, 'learning_rate': 4.984342683680809e-09, 'epoch': 0.96}
{'loss': 1.1916, 'grad_norm': 2.805177688598633, 'learning_rate': 4.248059889602862e-09, 'epoch': 0.96}
{'loss': 1.287, 'grad_norm': 2.898932933807373, 'learning_rate': 3.570359097032516e-09, 'epoch': 0.96}
{'loss': 1.2803, 'grad_norm': 3.200305938720703, 'learning_rate': 2.9513203884981576e-09, 'epoch': 0.97}
{'loss': 1.0453, 'grad_norm': 3.128432035446167, 'learning_rate': 2.3910169145487935e-09, 'epoch': 0.97}
{'loss': 1.3274, 'grad_norm': 3.276273250579834, 'learning_rate': 1.889514885109689e-09, 'epoch': 0.97}
{'loss': 1.2561, 'grad_norm': 21.588499069213867, 'learning_rate': 1.44687356165879e-09, 'epoch': 0.98}
{'loss': 1.2838, 'grad_norm': 3.395179271697998, 'learning_rate': 1.0631452502237736e-09, 'epoch': 0.98}
{'loss': 1.372, 'grad_norm': 5.131496906280518, 'learning_rate': 7.383752952010991e-10, 'epoch': 0.98}
{'loss': 1.1555, 'grad_norm': 6.590707302093506, 'learning_rate': 4.72602073997741e-10, 'epoch': 0.99}
{'loss': 1.0965, 'grad_norm': 4.978947162628174, 'learning_rate': 2.6585699249642714e-10, 'epoch': 0.99}
{'loss': 1.1876, 'grad_norm': 4.091005802154541, 'learning_rate': 1.181644813441074e-10, 'epoch': 0.99}
{'loss': 1.1217, 'grad_norm': 2.9265706539154053, 'learning_rate': 2.954199306537397e-11, 'epoch': 1.0}
{'loss': 1.1108, 'grad_norm': 2.7777504920959473, 'learning_rate': 0.0, 'epoch': 1.0}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-305/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-305/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-305/model.safetensors.index.json.
2024-12-23 01:45:56,096 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-305/pytorch_model_fsdp.bin
2024-12-23 01:46:43,697 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-305/pytorch_model_fsdp.bin
2024-12-23 01:47:09,782 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-305/optimizer.bin
2024-12-23 01:48:50,582 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-305/optimizer.bin
Saving model checkpoint to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-305
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-305/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-305/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-305/model.safetensors.index.json.
2024-12-23 01:50:50,157 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-305/pytorch_model_fsdp.bin
2024-12-23 01:51:37,069 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-305/pytorch_model_fsdp.bin
2024-12-23 01:52:07,732 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-305/optimizer.bin
2024-12-23 01:53:53,899 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-305/optimizer.bin


Training completed. Do not forget to share your model on huggingface.co/models =)


100%|██████████| 305/305 [22:16<00:00,  4.38s/it]
{'train_runtime': 1339.5964, 'train_samples_per_second': 1.824, 'train_steps_per_second': 0.228, 'train_loss': 1.265888840644086, 'epoch': 1.0}
Saving model checkpoint to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.02-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/model.safetensors.index.json.
