                                                                                                                                                                                               
{'loss': 1.6821, 'grad_norm': 46.57070541381836, 'learning_rate': 3.448275862068965e-08, 'epoch': 0.01}
{'loss': 1.9108, 'grad_norm': 256.8217468261719, 'learning_rate': 6.89655172413793e-08, 'epoch': 0.01}
{'loss': 1.6416, 'grad_norm': 58.550926208496094, 'learning_rate': 1.0344827586206897e-07, 'epoch': 0.02}
{'loss': 1.4557, 'grad_norm': 42.01811599731445, 'learning_rate': 1.379310344827586e-07, 'epoch': 0.02}
{'loss': 1.5728, 'grad_norm': 66.42259216308594, 'learning_rate': 1.7241379310344828e-07, 'epoch': 0.03}
{'loss': 1.5197, 'grad_norm': 49.94330596923828, 'learning_rate': 2.0689655172413793e-07, 'epoch': 0.03}
{'loss': 2.0179, 'grad_norm': 37911.58984375, 'learning_rate': 2.413793103448276e-07, 'epoch': 0.04}
{'loss': 1.6379, 'grad_norm': 30.134342193603516, 'learning_rate': 2.758620689655172e-07, 'epoch': 0.04}
{'loss': 1.6835, 'grad_norm': 23.49114990234375, 'learning_rate': 3.103448275862069e-07, 'epoch': 0.05}
{'loss': 1.5426, 'grad_norm': 101.90371704101562, 'learning_rate': 3.4482758620689656e-07, 'epoch': 0.05}
{'loss': 1.8327, 'grad_norm': 3826.79931640625, 'learning_rate': 3.793103448275862e-07, 'epoch': 0.06}
{'loss': 1.5456, 'grad_norm': 1552.74267578125, 'learning_rate': 4.1379310344827586e-07, 'epoch': 0.06}
{'loss': 1.8313, 'grad_norm': 83.5835189819336, 'learning_rate': 4.482758620689655e-07, 'epoch': 0.07}
{'loss': 1.7039, 'grad_norm': 72.2718734741211, 'learning_rate': 4.827586206896552e-07, 'epoch': 0.07}
{'loss': 1.6567, 'grad_norm': 10.258951187133789, 'learning_rate': 5.172413793103448e-07, 'epoch': 0.08}
{'loss': 1.6626, 'grad_norm': 12.08481502532959, 'learning_rate': 5.517241379310344e-07, 'epoch': 0.08}
{'loss': 1.8342, 'grad_norm': 31.093774795532227, 'learning_rate': 5.86206896551724e-07, 'epoch': 0.09}
{'loss': 1.3487, 'grad_norm': 25.613304138183594, 'learning_rate': 6.206896551724138e-07, 'epoch': 0.09}
{'loss': 1.374, 'grad_norm': 14.675816535949707, 'learning_rate': 6.551724137931034e-07, 'epoch': 0.1}
{'loss': 1.7792, 'grad_norm': 11.814454078674316, 'learning_rate': 6.896551724137931e-07, 'epoch': 0.1}
{'loss': 1.4544, 'grad_norm': 12.85847282409668, 'learning_rate': 7.241379310344827e-07, 'epoch': 0.11}
{'loss': 1.3954, 'grad_norm': 8.467046737670898, 'learning_rate': 7.586206896551724e-07, 'epoch': 0.11}
{'loss': 1.4521, 'grad_norm': 6.1080756187438965, 'learning_rate': 7.931034482758621e-07, 'epoch': 0.12}
{'loss': 1.6777, 'grad_norm': 7.779438018798828, 'learning_rate': 8.275862068965517e-07, 'epoch': 0.12}
{'loss': 1.5426, 'grad_norm': 6.9386887550354, 'learning_rate': 8.620689655172412e-07, 'epoch': 0.13}
{'loss': 1.6096, 'grad_norm': 12.281058311462402, 'learning_rate': 8.96551724137931e-07, 'epoch': 0.14}
{'loss': 1.4955, 'grad_norm': 7.840822696685791, 'learning_rate': 9.310344827586206e-07, 'epoch': 0.14}
{'loss': 1.4772, 'grad_norm': 7.4945149421691895, 'learning_rate': 9.655172413793103e-07, 'epoch': 0.15}
{'loss': 1.491, 'grad_norm': 7.427649021148682, 'learning_rate': 1e-06, 'epoch': 0.15}
{'loss': 1.4156, 'grad_norm': 7.334278106689453, 'learning_rate': 9.9999175360929e-07, 'epoch': 0.16}
{'loss': 1.245, 'grad_norm': 5.0439066886901855, 'learning_rate': 9.999670147091728e-07, 'epoch': 0.16}
{'loss': 1.2917, 'grad_norm': 4.0731000900268555, 'learning_rate': 9.99925784115674e-07, 'epoch': 0.17}
{'loss': 1.3415, 'grad_norm': 4.886416435241699, 'learning_rate': 9.998680631888088e-07, 'epoch': 0.17}
{'loss': 1.4673, 'grad_norm': 6.498992919921875, 'learning_rate': 9.997938538325338e-07, 'epoch': 0.18}
{'loss': 1.3206, 'grad_norm': 28.26813316345215, 'learning_rate': 9.997031584946869e-07, 'epoch': 0.18}
{'loss': 1.525, 'grad_norm': 7.043696880340576, 'learning_rate': 9.995959801669042e-07, 'epoch': 0.19}
{'loss': 1.1448, 'grad_norm': 3.6607871055603027, 'learning_rate': 9.994723223845238e-07, 'epoch': 0.19}
{'loss': 1.4705, 'grad_norm': 6.914452075958252, 'learning_rate': 9.99332189226467e-07, 'epoch': 0.2}
{'loss': 1.3222, 'grad_norm': 7.0291218757629395, 'learning_rate': 9.99175585315105e-07, 'epoch': 0.2}
{'loss': 1.3258, 'grad_norm': 8.80362606048584, 'learning_rate': 9.990025158161059e-07, 'epoch': 0.21}
{'loss': 1.4464, 'grad_norm': 3.4637155532836914, 'learning_rate': 9.988129864382643e-07, 'epoch': 0.21}
{'loss': 1.3953, 'grad_norm': 5.992854118347168, 'learning_rate': 9.986070034333138e-07, 'epoch': 0.22}
{'loss': 1.2248, 'grad_norm': 3.865837574005127, 'learning_rate': 9.983845735957194e-07, 'epoch': 0.22}
{'loss': 1.4512, 'grad_norm': 4.635756015777588, 'learning_rate': 9.981457042624549e-07, 'epoch': 0.23}
{'loss': 1.3246, 'grad_norm': 5.0671772956848145, 'learning_rate': 9.978904033127591e-07, 'epoch': 0.23}
{'loss': 1.4287, 'grad_norm': 3.9247379302978516, 'learning_rate': 9.976186791678782e-07, 'epoch': 0.24}
{'loss': 1.2867, 'grad_norm': 14.09158992767334, 'learning_rate': 9.973305407907855e-07, 'epoch': 0.24}
{'loss': 1.169, 'grad_norm': 16.703542709350586, 'learning_rate': 9.97025997685888e-07, 'epoch': 0.25}
{'loss': 1.2449, 'grad_norm': 5.556532859802246, 'learning_rate': 9.96705059898711e-07, 'epoch': 0.25}
{'loss': 1.5672, 'grad_norm': 9.493025779724121, 'learning_rate': 9.963677380155682e-07, 'epoch': 0.26}
{'loss': 1.413, 'grad_norm': 4.232003688812256, 'learning_rate': 9.960140431632121e-07, 'epoch': 0.26}
{'loss': 1.2214, 'grad_norm': 4.766043186187744, 'learning_rate': 9.95643987008466e-07, 'epoch': 0.27}
{'loss': 1.2299, 'grad_norm': 3.681328296661377, 'learning_rate': 9.952575817578406e-07, 'epoch': 0.28}
{'loss': 1.3242, 'grad_norm': 3.084237575531006, 'learning_rate': 9.948548401571306e-07, 'epoch': 0.28}
{'loss': 1.2907, 'grad_norm': 3.0995121002197266, 'learning_rate': 9.944357754909945e-07, 'epoch': 0.29}
{'loss': 1.2731, 'grad_norm': 3.214278221130371, 'learning_rate': 9.940004015825158e-07, 'epoch': 0.29}
{'loss': 1.587, 'grad_norm': 3.504159927368164, 'learning_rate': 9.935487327927486e-07, 'epoch': 0.3}
{'loss': 1.149, 'grad_norm': 2.7827887535095215, 'learning_rate': 9.930807840202416e-07, 'epoch': 0.3}
{'loss': 1.4369, 'grad_norm': 3.735412359237671, 'learning_rate': 9.925965707005484e-07, 'epoch': 0.31}
{'loss': 1.3257, 'grad_norm': 21.431983947753906, 'learning_rate': 9.920961088057183e-07, 'epoch': 0.31}
{'loss': 1.2675, 'grad_norm': 3.1108009815216064, 'learning_rate': 9.91579414843768e-07, 'epoch': 0.32}
{'loss': 1.3597, 'grad_norm': 4.529441833496094, 'learning_rate': 9.910465058581394e-07, 'epoch': 0.32}
{'loss': 1.2478, 'grad_norm': 4.407990455627441, 'learning_rate': 9.904973994271347e-07, 'epoch': 0.33}
{'loss': 1.2034, 'grad_norm': 2.938659191131592, 'learning_rate': 9.899321136633388e-07, 'epoch': 0.33}
{'loss': 1.2524, 'grad_norm': 3.6137802600860596, 'learning_rate': 9.89350667213021e-07, 'epoch': 0.34}
{'loss': 1.4143, 'grad_norm': 4.0627522468566895, 'learning_rate': 9.887530792555192e-07, 'epoch': 0.34}
{'loss': 1.356, 'grad_norm': 5.5667314529418945, 'learning_rate': 9.88139369502609e-07, 'epoch': 0.35}
{'loss': 1.2393, 'grad_norm': 4.059671878814697, 'learning_rate': 9.875095581978519e-07, 'epoch': 0.35}
{'loss': 1.3843, 'grad_norm': 3.5095508098602295, 'learning_rate': 9.868636661159283e-07, 'epoch': 0.36}
{'loss': 1.3317, 'grad_norm': 6.569072723388672, 'learning_rate': 9.86201714561952e-07, 'epoch': 0.36}
{'loss': 1.245, 'grad_norm': 3.8530075550079346, 'learning_rate': 9.855237253707674e-07, 'epoch': 0.37}
{'loss': 1.4518, 'grad_norm': 11.56041431427002, 'learning_rate': 9.848297209062296e-07, 'epoch': 0.37}
{'loss': 1.3929, 'grad_norm': 39.152000427246094, 'learning_rate': 9.84119724060467e-07, 'epoch': 0.38}
{'loss': 1.3694, 'grad_norm': 3.7347915172576904, 'learning_rate': 9.833937582531244e-07, 'epoch': 0.38}
{'loss': 1.1809, 'grad_norm': 2.759338140487671, 'learning_rate': 9.82651847430593e-07, 'epoch': 0.39}
{'loss': 1.1916, 'grad_norm': 2.9273369312286377, 'learning_rate': 9.818940160652192e-07, 'epoch': 0.39}
{'loss': 1.2202, 'grad_norm': 3.4827587604522705, 'learning_rate': 9.811202891544965e-07, 'epoch': 0.4}
{'loss': 1.3311, 'grad_norm': 3.1446237564086914, 'learning_rate': 9.803306922202427e-07, 'epoch': 0.41}
{'loss': 1.2479, 'grad_norm': 3.255507469177246, 'learning_rate': 9.79525251307757e-07, 'epoch': 0.41}
{'loss': 1.3793, 'grad_norm': 3.423973560333252, 'learning_rate': 9.787039929849616e-07, 'epoch': 0.42}
{'loss': 1.3775, 'grad_norm': 3.9684066772460938, 'learning_rate': 9.778669443415243e-07, 'epoch': 0.42}
{'loss': 1.242, 'grad_norm': 3.0444562435150146, 'learning_rate': 9.770141329879656e-07, 'epoch': 0.43}
{'loss': 1.195, 'grad_norm': 3.189236879348755, 'learning_rate': 9.761455870547481e-07, 'epoch': 0.43}
{'loss': 1.2461, 'grad_norm': 3.2873451709747314, 'learning_rate': 9.752613351913484e-07, 'epoch': 0.44}
{'loss': 1.5006, 'grad_norm': 6.817355632781982, 'learning_rate': 9.743614065653118e-07, 'epoch': 0.44}
{'loss': 1.219, 'grad_norm': 3.121185541152954, 'learning_rate': 9.734458308612905e-07, 'epoch': 0.45}
{'loss': 1.4638, 'grad_norm': 4.521024703979492, 'learning_rate': 9.725146382800642e-07, 'epoch': 0.45}
{'loss': 1.4948, 'grad_norm': 3.782473564147949, 'learning_rate': 9.715678595375448e-07, 'epoch': 0.46}
{'loss': 1.0836, 'grad_norm': 20.24805450439453, 'learning_rate': 9.706055258637617e-07, 'epoch': 0.46}
{'loss': 1.4189, 'grad_norm': 3.0501468181610107, 'learning_rate': 9.696276690018329e-07, 'epoch': 0.47}
{'loss': 1.4205, 'grad_norm': 4.81381368637085, 'learning_rate': 9.686343212069172e-07, 'epoch': 0.47}
{'loss': 1.2216, 'grad_norm': 3.854825258255005, 'learning_rate': 9.676255152451506e-07, 'epoch': 0.48}
{'loss': 1.2232, 'grad_norm': 28.250207901000977, 'learning_rate': 9.66601284392566e-07, 'epoch': 0.48}
{'loss': 1.3153, 'grad_norm': 4.5061354637146, 'learning_rate': 9.655616624339944e-07, 'epoch': 0.49}
{'loss': 1.2097, 'grad_norm': 4.094045162200928, 'learning_rate': 9.645066836619508e-07, 'epoch': 0.49}
{'loss': 1.1769, 'grad_norm': 2.949112892150879, 'learning_rate': 9.634363828755043e-07, 'epoch': 0.5}
{'loss': 1.1789, 'grad_norm': 6.076708793640137, 'learning_rate': 9.623507953791286e-07, 'epoch': 0.5}
{'loss': 1.1176, 'grad_norm': 2.8253173828125, 'learning_rate': 9.612499569815381e-07, 'epoch': 0.51}
{'loss': 1.2958, 'grad_norm': 4.621277332305908, 'learning_rate': 9.601339039945073e-07, 'epoch': 0.51}
{'loss': 1.0936, 'grad_norm': 3.4919567108154297, 'learning_rate': 9.590026732316719e-07, 'epoch': 0.52}
{'loss': 1.1362, 'grad_norm': 2.727917194366455, 'learning_rate': 9.578563020073152e-07, 'epoch': 0.52}
{'loss': 1.4972, 'grad_norm': 4.603295803070068, 'learning_rate': 9.566948281351373e-07, 'epoch': 0.53}
{'loss': 1.2396, 'grad_norm': 5.0172529220581055, 'learning_rate': 9.555182899270078e-07, 'epoch': 0.54}
{'loss': 1.1586, 'grad_norm': 3.0731441974639893, 'learning_rate': 9.543267261917014e-07, 'epoch': 0.54}
{'loss': 1.3944, 'grad_norm': 5.53081750869751, 'learning_rate': 9.531201762336189e-07, 'epoch': 0.55}
{'loss': 1.3622, 'grad_norm': 5.04905891418457, 'learning_rate': 9.518986798514897e-07, 'epoch': 0.55}
{'loss': 1.3164, 'grad_norm': 3.677827835083008, 'learning_rate': 9.506622773370594e-07, 'epoch': 0.56}
{'loss': 1.0792, 'grad_norm': 11.80424690246582, 'learning_rate': 9.494110094737607e-07, 'epoch': 0.56}
{'loss': 1.2582, 'grad_norm': 4.758086204528809, 'learning_rate': 9.481449175353684e-07, 'epoch': 0.57}
{'loss': 1.2294, 'grad_norm': 3.64955997467041, 'learning_rate': 9.468640432846378e-07, 'epoch': 0.57}
{'loss': 1.2546, 'grad_norm': 4.737800121307373, 'learning_rate': 9.455684289719269e-07, 'epoch': 0.58}
{'loss': 1.026, 'grad_norm': 8.72651195526123, 'learning_rate': 9.442581173338031e-07, 'epoch': 0.58}
{'loss': 1.2639, 'grad_norm': 4.01177453994751, 'learning_rate': 9.429331515916332e-07, 'epoch': 0.59}
{'loss': 1.317, 'grad_norm': 3.734549045562744, 'learning_rate': 9.415935754501581e-07, 'epoch': 0.59}
{'loss': 1.2704, 'grad_norm': 3.304637908935547, 'learning_rate': 9.402394330960505e-07, 'epoch': 0.6}
{'loss': 1.3039, 'grad_norm': 4.433284759521484, 'learning_rate': 9.388707691964584e-07, 'epoch': 0.6}
{'loss': 1.2849, 'grad_norm': 4.112362861633301, 'learning_rate': 9.374876288975307e-07, 'epoch': 0.61}
{'loss': 1.362, 'grad_norm': 4.040014266967773, 'learning_rate': 9.360900578229286e-07, 'epoch': 0.61}
{'loss': 1.356, 'grad_norm': 2.7929317951202393, 'learning_rate': 9.346781020723207e-07, 'epoch': 0.62}
{'loss': 1.231, 'grad_norm': 3.6272401809692383, 'learning_rate': 9.332518082198623e-07, 'epoch': 0.62}
{'loss': 1.2621, 'grad_norm': 4.041128158569336, 'learning_rate': 9.318112233126587e-07, 'epoch': 0.63}
{'loss': 1.4066, 'grad_norm': 3.642258644104004, 'learning_rate': 9.303563948692139e-07, 'epoch': 0.63}
{'loss': 1.3395, 'grad_norm': 6.999719142913818, 'learning_rate': 9.28887370877863e-07, 'epoch': 0.64}
{'loss': 1.0939, 'grad_norm': 5.529079437255859, 'learning_rate': 9.27404199795189e-07, 'epoch': 0.64}
{'loss': 1.1843, 'grad_norm': 3.6711058616638184, 'learning_rate': 9.259069305444252e-07, 'epoch': 0.65}
{'loss': 1.4574, 'grad_norm': 4.2256927490234375, 'learning_rate': 9.243956125138401e-07, 'epoch': 0.65}
{'loss': 1.1634, 'grad_norm': 3.052406072616577, 'learning_rate': 9.228702955551099e-07, 'epoch': 0.66}
{'loss': 1.3135, 'grad_norm': 6.947488307952881, 'learning_rate': 9.21331029981673e-07, 'epoch': 0.66}
{'loss': 1.2878, 'grad_norm': 3.191929340362549, 'learning_rate': 9.197778665670706e-07, 'epoch': 0.67}
{'loss': 1.3624, 'grad_norm': 3.376558780670166, 'learning_rate': 9.18210856543272e-07, 'epoch': 0.68}
{'loss': 1.2259, 'grad_norm': 3.2468273639678955, 'learning_rate': 9.166300515989849e-07, 'epoch': 0.68}
{'loss': 1.2569, 'grad_norm': 6.734725475311279, 'learning_rate': 9.150355038779502e-07, 'epoch': 0.69}
{'loss': 1.2046, 'grad_norm': 3.0243358612060547, 'learning_rate': 9.134272659772219e-07, 'epoch': 0.69}
{'loss': 1.2679, 'grad_norm': 21.075733184814453, 'learning_rate': 9.118053909454324e-07, 'epoch': 0.7}
{'loss': 1.1132, 'grad_norm': 3.5374698638916016, 'learning_rate': 9.101699322810423e-07, 'epoch': 0.7}
{'loss': 1.2381, 'grad_norm': 3.1947176456451416, 'learning_rate': 9.085209439305764e-07, 'epoch': 0.71}
{'loss': 1.3958, 'grad_norm': 11.95966911315918, 'learning_rate': 9.068584802868433e-07, 'epoch': 0.71}
{'loss': 1.1615, 'grad_norm': 9.01252555847168, 'learning_rate': 9.051825961871422e-07, 'epoch': 0.72}
{'loss': 1.4354, 'grad_norm': 7.225163459777832, 'learning_rate': 9.034933469114532e-07, 'epoch': 0.72}
{'loss': 1.2849, 'grad_norm': 3.914199113845825, 'learning_rate': 9.017907881806145e-07, 'epoch': 0.73}
{'loss': 1.2877, 'grad_norm': 4.0401506423950195, 'learning_rate': 9.000749761544841e-07, 'epoch': 0.73}
{'loss': 1.2715, 'grad_norm': 3.8905553817749023, 'learning_rate': 8.983459674300875e-07, 'epoch': 0.74}
{'loss': 1.3225, 'grad_norm': 13.227585792541504, 'learning_rate': 8.966038190397507e-07, 'epoch': 0.74}
{'loss': 1.3027, 'grad_norm': 10.078007698059082, 'learning_rate': 8.948485884492185e-07, 'epoch': 0.75}
{'loss': 1.1578, 'grad_norm': 3.469434976577759, 'learning_rate': 8.930803335557602e-07, 'epoch': 0.75}
{'loss': 1.2125, 'grad_norm': 3.2031259536743164, 'learning_rate': 8.912991126862586e-07, 'epoch': 0.76}
{'loss': 1.1128, 'grad_norm': 2.9819839000701904, 'learning_rate': 8.895049845952867e-07, 'epoch': 0.76}
{'loss': 1.0923, 'grad_norm': 2.8176820278167725, 'learning_rate': 8.876980084631692e-07, 'epoch': 0.77}
{'loss': 1.2455, 'grad_norm': 5.588197708129883, 'learning_rate': 8.858782438940311e-07, 'epoch': 0.77}
{'loss': 1.3168, 'grad_norm': 3.2936973571777344, 'learning_rate': 8.840457509138306e-07, 'epoch': 0.78}
{'loss': 1.349, 'grad_norm': 3.8232412338256836, 'learning_rate': 8.822005899683804e-07, 'epoch': 0.78}
{'loss': 1.216, 'grad_norm': 3.202100992202759, 'learning_rate': 8.803428219213526e-07, 'epoch': 0.79}
{'loss': 1.2902, 'grad_norm': 13.206293106079102, 'learning_rate': 8.784725080522721e-07, 'epoch': 0.79}
{'loss': 1.1545, 'grad_norm': 3.5768821239471436, 'learning_rate': 8.765897100544943e-07, 'epoch': 0.8}
{'loss': 1.2661, 'grad_norm': 4.446896553039551, 'learning_rate': 8.74694490033171e-07, 'epoch': 0.81}
{'loss': 1.1741, 'grad_norm': 9.054865837097168, 'learning_rate': 8.727869105032013e-07, 'epoch': 0.81}
{'loss': 1.4077, 'grad_norm': 4.1237006187438965, 'learning_rate': 8.708670343871696e-07, 'epoch': 0.82}
{'loss': 1.0988, 'grad_norm': 2.852790594100952, 'learning_rate': 8.6893492501327e-07, 'epoch': 0.82}
{'loss': 1.2293, 'grad_norm': 3.3745758533477783, 'learning_rate': 8.669906461132181e-07, 'epoch': 0.83}
{'loss': 1.1745, 'grad_norm': 3.1906991004943848, 'learning_rate': 8.650342618201473e-07, 'epoch': 0.83}
{'loss': 1.3663, 'grad_norm': 5.319756507873535, 'learning_rate': 8.630658366664951e-07, 'epoch': 0.84}
{'loss': 1.3259, 'grad_norm': 6.553550720214844, 'learning_rate': 8.610854355818727e-07, 'epoch': 0.84}
{'loss': 1.2309, 'grad_norm': 4.146312713623047, 'learning_rate': 8.590931238909245e-07, 'epoch': 0.85}
{'loss': 1.4788, 'grad_norm': 6.093204498291016, 'learning_rate': 8.570889673111732e-07, 'epoch': 0.85}
{'loss': 1.217, 'grad_norm': 3.2607553005218506, 'learning_rate': 8.550730319508515e-07, 'epoch': 0.86}
{'loss': 0.9955, 'grad_norm': 2.6925253868103027, 'learning_rate': 8.530453843067221e-07, 'epoch': 0.86}
{'loss': 1.2596, 'grad_norm': 3.3414113521575928, 'learning_rate': 8.510060912618835e-07, 'epoch': 0.87}
{'loss': 1.2256, 'grad_norm': 3.8347971439361572, 'learning_rate': 8.489552200835648e-07, 'epoch': 0.87}
{'loss': 1.2367, 'grad_norm': 3.509352207183838, 'learning_rate': 8.468928384209059e-07, 'epoch': 0.88}
{'loss': 1.2258, 'grad_norm': 3.7916414737701416, 'learning_rate': 8.448190143027268e-07, 'epoch': 0.88}
{'loss': 1.3833, 'grad_norm': 3.5053508281707764, 'learning_rate': 8.427338161352835e-07, 'epoch': 0.89}
{'loss': 1.1291, 'grad_norm': 3.308824062347412, 'learning_rate': 8.406373127000109e-07, 'epoch': 0.89}
{'loss': 1.2834, 'grad_norm': 2.7527499198913574, 'learning_rate': 8.385295731512549e-07, 'epoch': 0.9}
{'loss': 1.065, 'grad_norm': 2.8514821529388428, 'learning_rate': 8.36410667013991e-07, 'epoch': 0.9}
{'loss': 1.262, 'grad_norm': 2.9046170711517334, 'learning_rate': 8.342806641815303e-07, 'epoch': 0.91}
{'loss': 1.1192, 'grad_norm': 2.882650136947632, 'learning_rate': 8.321396349132156e-07, 'epoch': 0.91}
{'loss': 1.2112, 'grad_norm': 3.8383548259735107, 'learning_rate': 8.299876498321022e-07, 'epoch': 0.92}
{'loss': 1.1425, 'grad_norm': 3.338510036468506, 'learning_rate': 8.27824779922629e-07, 'epoch': 0.92}
{'loss': 1.3379, 'grad_norm': 6.486880779266357, 'learning_rate': 8.256510965282774e-07, 'epoch': 0.93}
{'loss': 1.267, 'grad_norm': 4.261053562164307, 'learning_rate': 8.234666713492178e-07, 'epoch': 0.94}
{'loss': 1.4065, 'grad_norm': 3.76436710357666, 'learning_rate': 8.21271576439944e-07, 'epoch': 0.94}
{'loss': 1.2032, 'grad_norm': 4.755762100219727, 'learning_rate': 8.190658842068972e-07, 'epoch': 0.95}
{'loss': 1.2093, 'grad_norm': 3.44050669670105, 'learning_rate': 8.168496674060769e-07, 'epoch': 0.95}
{'loss': 1.1721, 'grad_norm': 4.195155143737793, 'learning_rate': 8.146229991406421e-07, 'epoch': 0.96}
{'loss': 1.1734, 'grad_norm': 2.7375259399414062, 'learning_rate': 8.123859528584984e-07, 'epoch': 0.96}
{'loss': 1.1263, 'grad_norm': 10.448256492614746, 'learning_rate': 8.101386023498767e-07, 'epoch': 0.97}
{'loss': 1.339, 'grad_norm': 4.330097198486328, 'learning_rate': 8.078810217448985e-07, 'epoch': 0.97}
{'loss': 1.2332, 'grad_norm': 2.8082494735717773, 'learning_rate': 8.056132855111304e-07, 'epoch': 0.98}
{'loss': 1.2417, 'grad_norm': 4.089682579040527, 'learning_rate': 8.033354684511286e-07, 'epoch': 0.98}
{'loss': 1.2951, 'grad_norm': 2.977509021759033, 'learning_rate': 8.010476456999711e-07, 'epoch': 0.99}
{'loss': 1.1768, 'grad_norm': 3.0750067234039307, 'learning_rate': 7.987498927227787e-07, 'epoch': 0.99}
{'loss': 1.2076, 'grad_norm': 3.6620535850524902, 'learning_rate': 7.964422853122268e-07, 'epoch': 1.0}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-192/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-192/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-192/model.safetensors.index.json.
2025-01-02 23:37:40,287 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-192/pytorch_model_fsdp.bin
2025-01-02 23:38:22,035 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-192/pytorch_model_fsdp.bin
2025-01-02 23:38:54,451 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-192/optimizer.bin
2025-01-02 23:40:17,683 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-192/optimizer.bin
                                                                                                                                                                                               
{'loss': 1.1267, 'grad_norm': 4.277429580688477, 'learning_rate': 7.941248995860445e-07, 'epoch': 1.0}
{'loss': 1.3562, 'grad_norm': 3.7366549968719482, 'learning_rate': 7.917978119845044e-07, 'epoch': 1.01}
{'loss': 1.2754, 'grad_norm': 2.839938163757324, 'learning_rate': 7.894610992679007e-07, 'epoch': 1.01}
{'loss': 0.9968, 'grad_norm': 3.392704963684082, 'learning_rate': 7.871148385140178e-07, 'epoch': 1.02}
{'loss': 1.2956, 'grad_norm': 4.209273815155029, 'learning_rate': 7.847591071155871e-07, 'epoch': 1.02}
{'loss': 1.2148, 'grad_norm': 4.810611248016357, 'learning_rate': 7.823939827777344e-07, 'epoch': 1.03}
{'loss': 1.1388, 'grad_norm': 9.83618450164795, 'learning_rate': 7.800195435154178e-07, 'epoch': 1.03}
{'loss': 1.0814, 'grad_norm': 2.7317750453948975, 'learning_rate': 7.776358676508521e-07, 'epoch': 1.04}
{'loss': 1.1185, 'grad_norm': 3.2348289489746094, 'learning_rate': 7.752430338109277e-07, 'epoch': 1.04}
{'loss': 1.0631, 'grad_norm': 17.271955490112305, 'learning_rate': 7.728411209246155e-07, 'epoch': 1.05}
{'loss': 1.2426, 'grad_norm': 3.0106029510498047, 'learning_rate': 7.704302082203639e-07, 'epoch': 1.05}
{'loss': 1.1981, 'grad_norm': 2.8703548908233643, 'learning_rate': 7.680103752234857e-07, 'epoch': 1.06}
{'loss': 1.1356, 'grad_norm': 4.994484901428223, 'learning_rate': 7.655817017535339e-07, 'epoch': 1.06}
{'loss': 1.2741, 'grad_norm': 2.8456311225891113, 'learning_rate': 7.631442679216702e-07, 'epoch': 1.07}
{'loss': 1.0924, 'grad_norm': 2.934607744216919, 'learning_rate': 7.60698154128021e-07, 'epoch': 1.08}
{'loss': 0.9724, 'grad_norm': 3.94438099861145, 'learning_rate': 7.582434410590268e-07, 'epoch': 1.08}
{'loss': 1.2969, 'grad_norm': 2.7251675128936768, 'learning_rate': 7.557802096847799e-07, 'epoch': 1.09}
{'loss': 1.2025, 'grad_norm': 11.453722953796387, 'learning_rate': 7.533085412563534e-07, 'epoch': 1.09}
{'loss': 1.2096, 'grad_norm': 15.699295043945312, 'learning_rate': 7.508285173031215e-07, 'epoch': 1.1}
{'loss': 1.1685, 'grad_norm': 2.94669246673584, 'learning_rate': 7.483402196300704e-07, 'epoch': 1.1}
{'loss': 1.3207, 'grad_norm': 3.3193349838256836, 'learning_rate': 7.458437303150994e-07, 'epoch': 1.11}
{'loss': 1.1084, 'grad_norm': 2.839315414428711, 'learning_rate': 7.433391317063133e-07, 'epoch': 1.11}
{'loss': 1.2642, 'grad_norm': 3.5524790287017822, 'learning_rate': 7.408265064193071e-07, 'epoch': 1.12}
{'loss': 1.2422, 'grad_norm': 5.830555438995361, 'learning_rate': 7.383059373344401e-07, 'epoch': 1.12}
{'loss': 1.215, 'grad_norm': 35.00584411621094, 'learning_rate': 7.357775075941024e-07, 'epoch': 1.13}
{'loss': 1.1903, 'grad_norm': 3.7051212787628174, 'learning_rate': 7.332413005999717e-07, 'epoch': 1.13}
{'loss': 1.232, 'grad_norm': 3.5981225967407227, 'learning_rate': 7.306974000102634e-07, 'epoch': 1.14}
{'loss': 1.1673, 'grad_norm': 64.72980499267578, 'learning_rate': 7.281458897369705e-07, 'epoch': 1.14}
{'loss': 1.2865, 'grad_norm': 5.173858165740967, 'learning_rate': 7.25586853943095e-07, 'epoch': 1.15}
{'loss': 1.0237, 'grad_norm': 3.6275458335876465, 'learning_rate': 7.230203770398732e-07, 'epoch': 1.15}
{'loss': 1.2346, 'grad_norm': 14.07624626159668, 'learning_rate': 7.204465436839902e-07, 'epoch': 1.16}
{'loss': 1.1664, 'grad_norm': 8.707479476928711, 'learning_rate': 7.178654387747877e-07, 'epoch': 1.16}
{'loss': 1.2979, 'grad_norm': 4.607693195343018, 'learning_rate': 7.152771474514642e-07, 'epoch': 1.17}
{'loss': 1.0669, 'grad_norm': 2.7406914234161377, 'learning_rate': 7.126817550902655e-07, 'epoch': 1.17}
{'loss': 1.2368, 'grad_norm': 3.0463948249816895, 'learning_rate': 7.100793473016698e-07, 'epoch': 1.18}
{'loss': 1.2437, 'grad_norm': 4.181171894073486, 'learning_rate': 7.074700099275622e-07, 'epoch': 1.18}
{'loss': 1.2359, 'grad_norm': 37.339439392089844, 'learning_rate': 7.04853829038405e-07, 'epoch': 1.19}
{'loss': 1.1099, 'grad_norm': 3.3173272609710693, 'learning_rate': 7.022308909303974e-07, 'epoch': 1.19}
{'loss': 1.3345, 'grad_norm': 3.8682973384857178, 'learning_rate': 6.996012821226288e-07, 'epoch': 1.2}
{'loss': 1.2791, 'grad_norm': 3.238081932067871, 'learning_rate': 6.969650893542261e-07, 'epoch': 1.21}
{'loss': 1.1947, 'grad_norm': 5.027559280395508, 'learning_rate': 6.943223995814913e-07, 'epoch': 1.21}
{'loss': 1.1223, 'grad_norm': 2.9019596576690674, 'learning_rate': 6.916732999750343e-07, 'epoch': 1.22}
{'loss': 1.4363, 'grad_norm': 4.0146026611328125, 'learning_rate': 6.890178779168963e-07, 'epoch': 1.22}
{'loss': 1.2727, 'grad_norm': 3.247177839279175, 'learning_rate': 6.863562209976685e-07, 'epoch': 1.23}
{'loss': 1.1293, 'grad_norm': 4.461345672607422, 'learning_rate': 6.836884170136025e-07, 'epoch': 1.23}
{'loss': 1.2982, 'grad_norm': 3.628070831298828, 'learning_rate': 6.810145539637145e-07, 'epoch': 1.24}
{'loss': 1.1755, 'grad_norm': 3.275245189666748, 'learning_rate': 6.783347200468817e-07, 'epoch': 1.24}
{'loss': 1.1346, 'grad_norm': 11.224125862121582, 'learning_rate': 6.756490036589345e-07, 'epoch': 1.25}
{'loss': 1.2338, 'grad_norm': 2.7767529487609863, 'learning_rate': 6.729574933897396e-07, 'epoch': 1.25}
{'loss': 1.2496, 'grad_norm': 2.917978525161743, 'learning_rate': 6.702602780202778e-07, 'epoch': 1.26}
{'loss': 1.0293, 'grad_norm': 2.791768789291382, 'learning_rate': 6.675574465197165e-07, 'epoch': 1.26}
{'loss': 1.2281, 'grad_norm': 3.552098274230957, 'learning_rate': 6.64849088042474e-07, 'epoch': 1.27}
{'loss': 1.1574, 'grad_norm': 8.178768157958984, 'learning_rate': 6.621352919252788e-07, 'epoch': 1.27}
{'loss': 1.1994, 'grad_norm': 3.3700039386749268, 'learning_rate': 6.594161476842233e-07, 'epoch': 1.28}
{'loss': 1.1548, 'grad_norm': 3.6450119018554688, 'learning_rate': 6.566917450118108e-07, 'epoch': 1.28}
{'loss': 1.2029, 'grad_norm': 3.0109949111938477, 'learning_rate': 6.53962173773997e-07, 'epoch': 1.29}
{'loss': 1.2164, 'grad_norm': 2.7633216381073, 'learning_rate': 6.512275240072252e-07, 'epoch': 1.29}
{'loss': 1.2522, 'grad_norm': 2.717921495437622, 'learning_rate': 6.484878859154574e-07, 'epoch': 1.3}
{'loss': 1.2087, 'grad_norm': 9.184111595153809, 'learning_rate': 6.457433498671978e-07, 'epoch': 1.3}
{'loss': 1.3291, 'grad_norm': 8.760847091674805, 'learning_rate': 6.429940063925127e-07, 'epoch': 1.31}
{'loss': 1.2365, 'grad_norm': 3.2810451984405518, 'learning_rate': 6.402399461800442e-07, 'epoch': 1.31}
{'loss': 1.0983, 'grad_norm': 3.0836551189422607, 'learning_rate': 6.374812600740187e-07, 'epoch': 1.32}
{'loss': 1.0659, 'grad_norm': 2.7913687229156494, 'learning_rate': 6.347180390712497e-07, 'epoch': 1.32}
{'loss': 1.1331, 'grad_norm': 3.4333863258361816, 'learning_rate': 6.319503743181371e-07, 'epoch': 1.33}
{'loss': 1.0569, 'grad_norm': 2.748551845550537, 'learning_rate': 6.291783571076611e-07, 'epoch': 1.34}
{'loss': 1.1814, 'grad_norm': 3.4119184017181396, 'learning_rate': 6.26402078876369e-07, 'epoch': 1.34}
{'loss': 1.1775, 'grad_norm': 3.3016934394836426, 'learning_rate': 6.236216312013614e-07, 'epoch': 1.35}
{'loss': 1.236, 'grad_norm': 2.9513556957244873, 'learning_rate': 6.208371057972694e-07, 'epoch': 1.35}
{'loss': 1.1405, 'grad_norm': 8.380009651184082, 'learning_rate': 6.18048594513231e-07, 'epoch': 1.36}
{'loss': 1.0957, 'grad_norm': 3.1320769786834717, 'learning_rate': 6.1525618932986e-07, 'epoch': 1.36}
{'loss': 1.1887, 'grad_norm': 3.2810781002044678, 'learning_rate': 6.124599823562134e-07, 'epoch': 1.37}
{'loss': 1.1976, 'grad_norm': 175.60931396484375, 'learning_rate': 6.096600658267518e-07, 'epoch': 1.37}
{'loss': 1.1506, 'grad_norm': 2.853159189224243, 'learning_rate': 6.068565320982981e-07, 'epoch': 1.38}
{'loss': 1.1342, 'grad_norm': 3.8816781044006348, 'learning_rate': 6.0404947364699e-07, 'epoch': 1.38}
{'loss': 1.1846, 'grad_norm': 30.348678588867188, 'learning_rate': 6.012389830652306e-07, 'epoch': 1.39}
{'loss': 1.0705, 'grad_norm': 2.8168246746063232, 'learning_rate': 5.984251530586336e-07, 'epoch': 1.39}
{'loss': 1.2446, 'grad_norm': 2.882720470428467, 'learning_rate': 5.956080764429653e-07, 'epoch': 1.4}
{'loss': 1.1251, 'grad_norm': 2.7537505626678467, 'learning_rate': 5.927878461410836e-07, 'epoch': 1.4}
{'loss': 1.435, 'grad_norm': 3.591732978820801, 'learning_rate': 5.899645551798725e-07, 'epoch': 1.41}
{'loss': 1.259, 'grad_norm': 5.7783613204956055, 'learning_rate': 5.871382966871728e-07, 'epoch': 1.41}
{'loss': 1.1449, 'grad_norm': 2.779329776763916, 'learning_rate': 5.843091638887124e-07, 'epoch': 1.42}
{'loss': 1.1212, 'grad_norm': 3.6608059406280518, 'learning_rate': 5.814772501050286e-07, 'epoch': 1.42}
{'loss': 1.1389, 'grad_norm': 3.486745834350586, 'learning_rate': 5.786426487483914e-07, 'epoch': 1.43}
{'loss': 1.276, 'grad_norm': 6.384978771209717, 'learning_rate': 5.758054533197222e-07, 'epoch': 1.43}
{'loss': 1.1961, 'grad_norm': 2.868448495864868, 'learning_rate': 5.729657574055089e-07, 'epoch': 1.44}
{'loss': 1.2187, 'grad_norm': 3.202514886856079, 'learning_rate': 5.701236546747197e-07, 'epoch': 1.44}
{'loss': 1.0971, 'grad_norm': 2.8813772201538086, 'learning_rate': 5.672792388757127e-07, 'epoch': 1.45}
{'loss': 1.2068, 'grad_norm': 18.524063110351562, 'learning_rate': 5.644326038331439e-07, 'epoch': 1.45}
{'loss': 1.1864, 'grad_norm': 3.448075771331787, 'learning_rate': 5.615838434448725e-07, 'epoch': 1.46}
{'loss': 1.2223, 'grad_norm': 2.8722574710845947, 'learning_rate': 5.587330516788633e-07, 'epoch': 1.46}
{'loss': 1.0993, 'grad_norm': 2.744317054748535, 'learning_rate': 5.558803225700872e-07, 'epoch': 1.47}
{'loss': 1.2249, 'grad_norm': 3.0494349002838135, 'learning_rate': 5.530257502174196e-07, 'epoch': 1.48}
{'loss': 1.0466, 'grad_norm': 2.9543652534484863, 'learning_rate': 5.501694287805361e-07, 'epoch': 1.48}
{'loss': 1.064, 'grad_norm': 3.027522563934326, 'learning_rate': 5.473114524768068e-07, 'epoch': 1.49}
{'loss': 1.1865, 'grad_norm': 3.743786573410034, 'learning_rate': 5.444519155781889e-07, 'epoch': 1.49}
{'loss': 1.1743, 'grad_norm': 3.005840539932251, 'learning_rate': 5.415909124081163e-07, 'epoch': 1.5}
{'loss': 1.1462, 'grad_norm': 2.909703254699707, 'learning_rate': 5.387285373383892e-07, 'epoch': 1.5}
{'loss': 1.1899, 'grad_norm': 3.1440584659576416, 'learning_rate': 5.358648847860598e-07, 'epoch': 1.51}
{'loss': 1.0654, 'grad_norm': 3.1325197219848633, 'learning_rate': 5.330000492103198e-07, 'epoch': 1.51}
{'loss': 1.2702, 'grad_norm': 2.9014363288879395, 'learning_rate': 5.301341251093827e-07, 'epoch': 1.52}
{'loss': 1.2244, 'grad_norm': 17.5218448638916, 'learning_rate': 5.272672070173682e-07, 'epoch': 1.52}
{'loss': 0.9849, 'grad_norm': 12.74306583404541, 'learning_rate': 5.243993895011833e-07, 'epoch': 1.53}
{'loss': 1.2234, 'grad_norm': 3.8727078437805176, 'learning_rate': 5.215307671574027e-07, 'epoch': 1.53}
{'loss': 1.0995, 'grad_norm': 5.293569087982178, 'learning_rate': 5.18661434609149e-07, 'epoch': 1.54}
{'loss': 1.1762, 'grad_norm': 3.89494252204895, 'learning_rate': 5.157914865029715e-07, 'epoch': 1.54}
{'loss': 1.1725, 'grad_norm': 2.951212167739868, 'learning_rate': 5.129210175057236e-07, 'epoch': 1.55}
{'loss': 0.997, 'grad_norm': 2.712071180343628, 'learning_rate': 5.100501223014407e-07, 'epoch': 1.55}
{'loss': 1.2106, 'grad_norm': 3.132627010345459, 'learning_rate': 5.07178895588217e-07, 'epoch': 1.56}
{'loss': 1.2868, 'grad_norm': 3.3958353996276855, 'learning_rate': 5.04307432075082e-07, 'epoch': 1.56}
{'loss': 1.2876, 'grad_norm': 2.615741729736328, 'learning_rate': 5.014358264788755e-07, 'epoch': 1.57}
{'loss': 1.1682, 'grad_norm': 2.7375192642211914, 'learning_rate': 4.985641735211245e-07, 'epoch': 1.57}
{'loss': 1.2045, 'grad_norm': 3.4108874797821045, 'learning_rate': 4.95692567924918e-07, 'epoch': 1.58}
{'loss': 1.1494, 'grad_norm': 2.829078435897827, 'learning_rate': 4.928211044117829e-07, 'epoch': 1.58}
{'loss': 1.1639, 'grad_norm': 3.1021456718444824, 'learning_rate': 4.899498776985593e-07, 'epoch': 1.59}
{'loss': 1.0764, 'grad_norm': 3.1284749507904053, 'learning_rate': 4.870789824942765e-07, 'epoch': 1.59}
{'loss': 1.2583, 'grad_norm': 3.2375388145446777, 'learning_rate': 4.842085134970286e-07, 'epoch': 1.6}
{'loss': 1.1335, 'grad_norm': 2.920779228210449, 'learning_rate': 4.813385653908509e-07, 'epoch': 1.61}
{'loss': 1.2272, 'grad_norm': 2.9158737659454346, 'learning_rate': 4.784692328425973e-07, 'epoch': 1.61}
{'loss': 1.2442, 'grad_norm': 3.7458982467651367, 'learning_rate': 4.756006104988167e-07, 'epoch': 1.62}
{'loss': 1.136, 'grad_norm': 3.815068483352661, 'learning_rate': 4.727327929826318e-07, 'epoch': 1.62}
{'loss': 1.2152, 'grad_norm': 19.11240577697754, 'learning_rate': 4.698658748906174e-07, 'epoch': 1.63}
{'loss': 1.1974, 'grad_norm': 2.9206924438476562, 'learning_rate': 4.6699995078968026e-07, 'epoch': 1.63}
{'loss': 1.0614, 'grad_norm': 3.7864151000976562, 'learning_rate': 4.6413511521394023e-07, 'epoch': 1.64}
{'loss': 1.27, 'grad_norm': 2.869920253753662, 'learning_rate': 4.6127146266161083e-07, 'epoch': 1.64}
{'loss': 1.2661, 'grad_norm': 5.057127475738525, 'learning_rate': 4.5840908759188355e-07, 'epoch': 1.65}
{'loss': 1.1583, 'grad_norm': 3.510085344314575, 'learning_rate': 4.5554808442181104e-07, 'epoch': 1.65}
{'loss': 1.2539, 'grad_norm': 3.138429641723633, 'learning_rate': 4.5268854752319323e-07, 'epoch': 1.66}
{'loss': 1.1703, 'grad_norm': 4.074321746826172, 'learning_rate': 4.498305712194641e-07, 'epoch': 1.66}
{'loss': 1.2584, 'grad_norm': 3.3026418685913086, 'learning_rate': 4.469742497825804e-07, 'epoch': 1.67}
{'loss': 1.025, 'grad_norm': 2.629364490509033, 'learning_rate': 4.4411967742991287e-07, 'epoch': 1.67}
{'loss': 1.2957, 'grad_norm': 4.024012088775635, 'learning_rate': 4.412669483211367e-07, 'epoch': 1.68}
{'loss': 1.1731, 'grad_norm': 14.255266189575195, 'learning_rate': 4.3841615655512756e-07, 'epoch': 1.68}
{'loss': 1.1626, 'grad_norm': 10.47287368774414, 'learning_rate': 4.3556739616685607e-07, 'epoch': 1.69}
{'loss': 1.2283, 'grad_norm': 3.0416181087493896, 'learning_rate': 4.3272076112428745e-07, 'epoch': 1.69}
{'loss': 1.1504, 'grad_norm': 3.3209242820739746, 'learning_rate': 4.2987634532528046e-07, 'epoch': 1.7}
{'loss': 1.2399, 'grad_norm': 5.097592830657959, 'learning_rate': 4.2703424259449104e-07, 'epoch': 1.7}
{'loss': 1.117, 'grad_norm': 13.293797492980957, 'learning_rate': 4.2419454668027785e-07, 'epoch': 1.71}
{'loss': 1.2876, 'grad_norm': 3.0472991466522217, 'learning_rate': 4.213573512516085e-07, 'epoch': 1.71}
{'loss': 1.0795, 'grad_norm': 2.8810272216796875, 'learning_rate': 4.1852274989497145e-07, 'epoch': 1.72}
{'loss': 1.0202, 'grad_norm': 3.118659019470215, 'learning_rate': 4.1569083611128753e-07, 'epoch': 1.72}
{'loss': 1.0748, 'grad_norm': 42.049930572509766, 'learning_rate': 4.128617033128271e-07, 'epoch': 1.73}
{'loss': 1.1877, 'grad_norm': 3.5266265869140625, 'learning_rate': 4.1003544482012777e-07, 'epoch': 1.74}
{'loss': 1.4322, 'grad_norm': 2.9031569957733154, 'learning_rate': 4.072121538589164e-07, 'epoch': 1.74}
{'loss': 1.1789, 'grad_norm': 2.7217724323272705, 'learning_rate': 4.043919235570347e-07, 'epoch': 1.75}
{'loss': 1.0265, 'grad_norm': 3.0363476276397705, 'learning_rate': 4.015748469413664e-07, 'epoch': 1.75}
{'loss': 1.2327, 'grad_norm': 4.548647880554199, 'learning_rate': 3.9876101693476945e-07, 'epoch': 1.76}
{'loss': 1.1804, 'grad_norm': 3.0480923652648926, 'learning_rate': 3.9595052635301e-07, 'epoch': 1.76}
{'loss': 1.1455, 'grad_norm': 4.116305828094482, 'learning_rate': 3.931434679017019e-07, 'epoch': 1.77}
{'loss': 1.2881, 'grad_norm': 3.382359027862549, 'learning_rate': 3.903399341732482e-07, 'epoch': 1.77}
{'loss': 1.282, 'grad_norm': 3.876830577850342, 'learning_rate': 3.8754001764378665e-07, 'epoch': 1.78}
{'loss': 1.168, 'grad_norm': 3.0500223636627197, 'learning_rate': 3.8474381067014e-07, 'epoch': 1.78}
{'loss': 1.2688, 'grad_norm': 2.8627257347106934, 'learning_rate': 3.81951405486769e-07, 'epoch': 1.79}
{'loss': 1.2587, 'grad_norm': 3.970545530319214, 'learning_rate': 3.7916289420273064e-07, 'epoch': 1.79}
{'loss': 1.1226, 'grad_norm': 2.917304277420044, 'learning_rate': 3.7637836879863856e-07, 'epoch': 1.8}
{'loss': 1.1624, 'grad_norm': 2.7189624309539795, 'learning_rate': 3.7359792112363085e-07, 'epoch': 1.8}
{'loss': 1.0606, 'grad_norm': 2.8319389820098877, 'learning_rate': 3.708216428923391e-07, 'epoch': 1.81}
{'loss': 1.1005, 'grad_norm': 2.6038520336151123, 'learning_rate': 3.680496256818628e-07, 'epoch': 1.81}
{'loss': 1.1768, 'grad_norm': 3.185816526412964, 'learning_rate': 3.652819609287504e-07, 'epoch': 1.82}
{'loss': 1.3447, 'grad_norm': 6.002818584442139, 'learning_rate': 3.6251873992598126e-07, 'epoch': 1.82}
{'loss': 1.2662, 'grad_norm': 11.566959381103516, 'learning_rate': 3.5976005381995565e-07, 'epoch': 1.83}
{'loss': 1.1537, 'grad_norm': 3.2262368202209473, 'learning_rate': 3.570059936074871e-07, 'epoch': 1.83}
{'loss': 1.0896, 'grad_norm': 4.65278959274292, 'learning_rate': 3.5425665013280213e-07, 'epoch': 1.84}
{'loss': 1.2824, 'grad_norm': 2.6448092460632324, 'learning_rate': 3.515121140845427e-07, 'epoch': 1.84}
{'loss': 1.3347, 'grad_norm': 3.236508369445801, 'learning_rate': 3.487724759927747e-07, 'epoch': 1.85}
{'loss': 1.1574, 'grad_norm': 2.891244411468506, 'learning_rate': 3.4603782622600305e-07, 'epoch': 1.85}
{'loss': 1.235, 'grad_norm': 3.576639413833618, 'learning_rate': 3.4330825498818907e-07, 'epoch': 1.86}
{'loss': 1.0554, 'grad_norm': 56.966278076171875, 'learning_rate': 3.4058385231577673e-07, 'epoch': 1.86}
{'loss': 1.107, 'grad_norm': 4.0603251457214355, 'learning_rate': 3.3786470807472124e-07, 'epoch': 1.87}
{'loss': 1.2498, 'grad_norm': 3.355342388153076, 'learning_rate': 3.3515091195752596e-07, 'epoch': 1.88}
{'loss': 1.206, 'grad_norm': 3.059727668762207, 'learning_rate': 3.324425534802835e-07, 'epoch': 1.88}
{'loss': 1.2308, 'grad_norm': 2.772390842437744, 'learning_rate': 3.297397219797221e-07, 'epoch': 1.89}
{'loss': 1.2591, 'grad_norm': 3.9093966484069824, 'learning_rate': 3.2704250661026043e-07, 'epoch': 1.89}
{'loss': 1.3564, 'grad_norm': 3.638437032699585, 'learning_rate': 3.243509963410654e-07, 'epoch': 1.9}
{'loss': 1.092, 'grad_norm': 2.8844900131225586, 'learning_rate': 3.2166527995311834e-07, 'epoch': 1.9}
{'loss': 1.1858, 'grad_norm': 38.358646392822266, 'learning_rate': 3.189854460362856e-07, 'epoch': 1.91}
{'loss': 1.1687, 'grad_norm': 2.8208556175231934, 'learning_rate': 3.163115829863975e-07, 'epoch': 1.91}
{'loss': 1.1629, 'grad_norm': 2.5855491161346436, 'learning_rate': 3.136437790023316e-07, 'epoch': 1.92}
{'loss': 1.1922, 'grad_norm': 2.9333748817443848, 'learning_rate': 3.109821220831038e-07, 'epoch': 1.92}
{'loss': 1.1813, 'grad_norm': 3.24919056892395, 'learning_rate': 3.083267000249658e-07, 'epoch': 1.93}
{'loss': 1.1862, 'grad_norm': 2.678481101989746, 'learning_rate': 3.0567760041850855e-07, 'epoch': 1.93}
{'loss': 1.0962, 'grad_norm': 3.193326711654663, 'learning_rate': 3.0303491064577395e-07, 'epoch': 1.94}
{'loss': 1.1451, 'grad_norm': 2.6004576683044434, 'learning_rate': 3.0039871787737115e-07, 'epoch': 1.94}
{'loss': 1.246, 'grad_norm': 3.666517734527588, 'learning_rate': 2.9776910906960265e-07, 'epoch': 1.95}
{'loss': 1.2982, 'grad_norm': 5.094383716583252, 'learning_rate': 2.951461709615951e-07, 'epoch': 1.95}
{'loss': 1.186, 'grad_norm': 3.331265926361084, 'learning_rate': 2.9252999007243784e-07, 'epoch': 1.96}
{'loss': 1.0765, 'grad_norm': 2.8631694316864014, 'learning_rate': 2.899206526983303e-07, 'epoch': 1.96}
{'loss': 1.1045, 'grad_norm': 2.75083065032959, 'learning_rate': 2.8731824490973445e-07, 'epoch': 1.97}
{'loss': 1.0572, 'grad_norm': 4.372960090637207, 'learning_rate': 2.847228525485359e-07, 'epoch': 1.97}
{'loss': 1.2077, 'grad_norm': 3.238468647003174, 'learning_rate': 2.821345612252121e-07, 'epoch': 1.98}
{'loss': 1.0723, 'grad_norm': 3.284193992614746, 'learning_rate': 2.795534563160099e-07, 'epoch': 1.98}
{'loss': 1.193, 'grad_norm': 2.919481039047241, 'learning_rate': 2.7697962296012687e-07, 'epoch': 1.99}
{'loss': 0.9827, 'grad_norm': 2.9600775241851807, 'learning_rate': 2.7441314605690485e-07, 'epoch': 1.99}
{'loss': 1.1264, 'grad_norm': 2.6094486713409424, 'learning_rate': 2.7185411026302964e-07, 'epoch': 2.0}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-385/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-385/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-385/model.safetensors.index.json.
2025-01-02 23:49:46,450 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-385/pytorch_model_fsdp.bin
2025-01-02 23:50:30,909 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-385/pytorch_model_fsdp.bin
2025-01-02 23:51:01,870 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-385/optimizer.bin
2025-01-02 23:52:29,121 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-385/optimizer.bin
                                                                                                                                                                                               
{'loss': 1.2366, 'grad_norm': 3.5678904056549072, 'learning_rate': 2.693025999897364e-07, 'epoch': 2.01}
{'loss': 1.1166, 'grad_norm': 2.5087873935699463, 'learning_rate': 2.667586994000283e-07, 'epoch': 2.01}
{'loss': 1.0452, 'grad_norm': 2.624337673187256, 'learning_rate': 2.6422249240589767e-07, 'epoch': 2.02}
{'loss': 1.014, 'grad_norm': 2.8926472663879395, 'learning_rate': 2.616940626655598e-07, 'epoch': 2.02}
{'loss': 1.2042, 'grad_norm': 2.6489782333374023, 'learning_rate': 2.591734935806929e-07, 'epoch': 2.03}
{'loss': 1.1568, 'grad_norm': 3.2710940837860107, 'learning_rate': 2.5666086829368675e-07, 'epoch': 2.03}
{'loss': 1.1468, 'grad_norm': 2.5906872749328613, 'learning_rate': 2.5415626968490074e-07, 'epoch': 2.04}
{'loss': 1.1408, 'grad_norm': 13.905023574829102, 'learning_rate': 2.516597803699294e-07, 'epoch': 2.04}
{'loss': 1.2915, 'grad_norm': 7.40068244934082, 'learning_rate': 2.491714826968785e-07, 'epoch': 2.05}
{'loss': 1.1397, 'grad_norm': 3.878474712371826, 'learning_rate': 2.4669145874364653e-07, 'epoch': 2.05}
{'loss': 1.3466, 'grad_norm': 2.8881547451019287, 'learning_rate': 2.4421979031522006e-07, 'epoch': 2.06}
{'loss': 1.0932, 'grad_norm': 7.467468738555908, 'learning_rate': 2.417565589409733e-07, 'epoch': 2.06}
{'loss': 1.259, 'grad_norm': 3.5958597660064697, 'learning_rate': 2.3930184587197897e-07, 'epoch': 2.07}
{'loss': 1.0769, 'grad_norm': 11.173032760620117, 'learning_rate': 2.3685573207832987e-07, 'epoch': 2.07}
{'loss': 1.1274, 'grad_norm': 3.8254811763763428, 'learning_rate': 2.3441829824646602e-07, 'epoch': 2.08}
{'loss': 1.105, 'grad_norm': 3.7477402687072754, 'learning_rate': 2.319896247765143e-07, 'epoch': 2.08}
{'loss': 1.2827, 'grad_norm': 13.948684692382812, 'learning_rate': 2.2956979177963598e-07, 'epoch': 2.09}
{'loss': 1.1065, 'grad_norm': 3.1329689025878906, 'learning_rate': 2.271588790753845e-07, 'epoch': 2.09}
{'loss': 1.0789, 'grad_norm': 2.661522150039673, 'learning_rate': 2.2475696618907235e-07, 'epoch': 2.1}
{'loss': 1.035, 'grad_norm': 4.838776588439941, 'learning_rate': 2.2236413234914803e-07, 'epoch': 2.1}
{'loss': 1.1788, 'grad_norm': 2.628758192062378, 'learning_rate': 2.1998045648458242e-07, 'epoch': 2.11}
{'loss': 1.1211, 'grad_norm': 4.278910160064697, 'learning_rate': 2.176060172222654e-07, 'epoch': 2.11}
{'loss': 1.0807, 'grad_norm': 2.9476747512817383, 'learning_rate': 2.1524089288441311e-07, 'epoch': 2.12}
{'loss': 1.0893, 'grad_norm': 3.977839469909668, 'learning_rate': 2.1288516148598213e-07, 'epoch': 2.12}
{'loss': 1.166, 'grad_norm': 58.17228317260742, 'learning_rate': 2.105389007320992e-07, 'epoch': 2.13}
{'loss': 1.245, 'grad_norm': 3.008298635482788, 'learning_rate': 2.0820218801549577e-07, 'epoch': 2.14}
{'loss': 1.2001, 'grad_norm': 3.043339729309082, 'learning_rate': 2.058751004139555e-07, 'epoch': 2.14}
{'loss': 1.1909, 'grad_norm': 28.683317184448242, 'learning_rate': 2.0355771468777323e-07, 'epoch': 2.15}
{'loss': 1.2453, 'grad_norm': 2.985020160675049, 'learning_rate': 2.012501072772213e-07, 'epoch': 2.15}
{'loss': 1.1093, 'grad_norm': 3.021491050720215, 'learning_rate': 1.9895235430002892e-07, 'epoch': 2.16}
{'loss': 1.2006, 'grad_norm': 3.2801995277404785, 'learning_rate': 1.966645315488713e-07, 'epoch': 2.16}
{'loss': 1.2046, 'grad_norm': 2.872121810913086, 'learning_rate': 1.9438671448886962e-07, 'epoch': 2.17}
{'loss': 1.1006, 'grad_norm': 2.9482147693634033, 'learning_rate': 1.921189782551016e-07, 'epoch': 2.17}
{'loss': 1.1015, 'grad_norm': 2.822462320327759, 'learning_rate': 1.8986139765012327e-07, 'epoch': 2.18}
{'loss': 1.4544, 'grad_norm': 3.3178963661193848, 'learning_rate': 1.8761404714150158e-07, 'epoch': 2.18}
{'loss': 1.2917, 'grad_norm': 3.115368366241455, 'learning_rate': 1.853770008593578e-07, 'epoch': 2.19}
{'loss': 1.2723, 'grad_norm': 2.751962900161743, 'learning_rate': 1.831503325939231e-07, 'epoch': 2.19}
{'loss': 1.249, 'grad_norm': 3.2546885013580322, 'learning_rate': 1.809341157931028e-07, 'epoch': 2.2}
{'loss': 1.0499, 'grad_norm': 3.0133159160614014, 'learning_rate': 1.7872842356005597e-07, 'epoch': 2.2}
{'loss': 1.1561, 'grad_norm': 3.7967331409454346, 'learning_rate': 1.765333286507824e-07, 'epoch': 2.21}
{'loss': 1.2399, 'grad_norm': 3.368622303009033, 'learning_rate': 1.743489034717226e-07, 'epoch': 2.21}
{'loss': 1.1685, 'grad_norm': 4.643161296844482, 'learning_rate': 1.7217522007737106e-07, 'epoch': 2.22}
{'loss': 1.1503, 'grad_norm': 3.1018025875091553, 'learning_rate': 1.700123501678979e-07, 'epoch': 2.22}
{'loss': 1.1424, 'grad_norm': 2.772566318511963, 'learning_rate': 1.6786036508678437e-07, 'epoch': 2.23}
{'loss': 1.1437, 'grad_norm': 12.479641914367676, 'learning_rate': 1.6571933581846965e-07, 'epoch': 2.23}
{'loss': 1.015, 'grad_norm': 2.610530138015747, 'learning_rate': 1.6358933298600907e-07, 'epoch': 2.24}
{'loss': 1.0159, 'grad_norm': 2.650874614715576, 'learning_rate': 1.6147042684874508e-07, 'epoch': 2.24}
{'loss': 1.4385, 'grad_norm': 3.3088154792785645, 'learning_rate': 1.5936268729998913e-07, 'epoch': 2.25}
{'loss': 1.2616, 'grad_norm': 3.3566811084747314, 'learning_rate': 1.5726618386471656e-07, 'epoch': 2.25}
{'loss': 1.1441, 'grad_norm': 2.706970453262329, 'learning_rate': 1.55180985697273e-07, 'epoch': 2.26}
{'loss': 1.1406, 'grad_norm': 2.715252161026001, 'learning_rate': 1.531071615790942e-07, 'epoch': 2.26}
{'loss': 1.1014, 'grad_norm': 11.4813814163208, 'learning_rate': 1.5104477991643515e-07, 'epoch': 2.27}
{'loss': 1.2038, 'grad_norm': 3.1414473056793213, 'learning_rate': 1.489939087381164e-07, 'epoch': 2.28}
{'loss': 1.208, 'grad_norm': 2.679656744003296, 'learning_rate': 1.46954615693278e-07, 'epoch': 2.28}
{'loss': 1.2661, 'grad_norm': 4.457449913024902, 'learning_rate': 1.449269680491484e-07, 'epoch': 2.29}
{'loss': 0.8986, 'grad_norm': 3.240866184234619, 'learning_rate': 1.4291103268882677e-07, 'epoch': 2.29}
{'loss': 1.0407, 'grad_norm': 2.8703770637512207, 'learning_rate': 1.4090687610907548e-07, 'epoch': 2.3}
{'loss': 1.0139, 'grad_norm': 3.250653028488159, 'learning_rate': 1.3891456441812744e-07, 'epoch': 2.3}
{'loss': 1.1307, 'grad_norm': 3.3560597896575928, 'learning_rate': 1.36934163333505e-07, 'epoch': 2.31}
{'loss': 1.1267, 'grad_norm': 4.140725135803223, 'learning_rate': 1.3496573817985262e-07, 'epoch': 2.31}
{'loss': 1.3076, 'grad_norm': 3.159691333770752, 'learning_rate': 1.3300935388678196e-07, 'epoch': 2.32}
{'loss': 1.1925, 'grad_norm': 3.3144967555999756, 'learning_rate': 1.3106507498672998e-07, 'epoch': 2.32}
{'loss': 1.2656, 'grad_norm': 2.961815357208252, 'learning_rate': 1.2913296561283054e-07, 'epoch': 2.33}
{'loss': 1.1352, 'grad_norm': 3.114917039871216, 'learning_rate': 1.2721308949679866e-07, 'epoch': 2.33}
{'loss': 1.1636, 'grad_norm': 2.7434566020965576, 'learning_rate': 1.2530550996682904e-07, 'epoch': 2.34}
{'loss': 1.0575, 'grad_norm': 3.196669340133667, 'learning_rate': 1.2341028994550556e-07, 'epoch': 2.34}
{'loss': 1.1436, 'grad_norm': 11.516162872314453, 'learning_rate': 1.2152749194772783e-07, 'epoch': 2.35}
{'loss': 1.1085, 'grad_norm': 6.317931175231934, 'learning_rate': 1.196571780786474e-07, 'epoch': 2.35}
{'loss': 1.1828, 'grad_norm': 2.905761241912842, 'learning_rate': 1.1779941003161953e-07, 'epoch': 2.36}
{'loss': 1.1407, 'grad_norm': 3.126669406890869, 'learning_rate': 1.159542490861693e-07, 'epoch': 2.36}
{'loss': 1.0436, 'grad_norm': 3.769601821899414, 'learning_rate': 1.1412175610596897e-07, 'epoch': 2.37}
{'loss': 1.1184, 'grad_norm': 3.1974172592163086, 'learning_rate': 1.1230199153683078e-07, 'epoch': 2.37}
{'loss': 1.1404, 'grad_norm': 3.0789756774902344, 'learning_rate': 1.1049501540471323e-07, 'epoch': 2.38}
{'loss': 1.1855, 'grad_norm': 3.5332815647125244, 'learning_rate': 1.0870088731374139e-07, 'epoch': 2.38}
{'loss': 1.2193, 'grad_norm': 31.585268020629883, 'learning_rate': 1.0691966644423984e-07, 'epoch': 2.39}
{'loss': 1.2575, 'grad_norm': 11.120028495788574, 'learning_rate': 1.0515141155078138e-07, 'epoch': 2.39}
{'loss': 1.1373, 'grad_norm': 3.0099995136260986, 'learning_rate': 1.0339618096024943e-07, 'epoch': 2.4}
{'loss': 1.1984, 'grad_norm': 3.1356983184814453, 'learning_rate': 1.016540325699124e-07, 'epoch': 2.41}
{'loss': 1.1415, 'grad_norm': 3.0425753593444824, 'learning_rate': 9.992502384551576e-08, 'epoch': 2.41}
{'loss': 1.1944, 'grad_norm': 2.859942674636841, 'learning_rate': 9.820921181938546e-08, 'epoch': 2.42}
{'loss': 1.1696, 'grad_norm': 2.9590954780578613, 'learning_rate': 9.650665308854678e-08, 'epoch': 2.42}
{'loss': 1.2137, 'grad_norm': 3.94205904006958, 'learning_rate': 9.48174038128578e-08, 'epoch': 2.43}
{'loss': 1.0743, 'grad_norm': 2.980555772781372, 'learning_rate': 9.314151971315664e-08, 'epoch': 2.43}
{'loss': 1.2228, 'grad_norm': 3.347033739089966, 'learning_rate': 9.147905606942363e-08, 'epoch': 2.44}
{'loss': 1.2291, 'grad_norm': 3.2723186016082764, 'learning_rate': 8.983006771895763e-08, 'epoch': 2.44}
{'loss': 1.2183, 'grad_norm': 15.104439735412598, 'learning_rate': 8.81946090545676e-08, 'epoch': 2.45}
{'loss': 1.1382, 'grad_norm': 2.8583433628082275, 'learning_rate': 8.657273402277798e-08, 'epoch': 2.45}
{'loss': 1.0462, 'grad_norm': 2.7185282707214355, 'learning_rate': 8.496449612204982e-08, 'epoch': 2.46}
{'loss': 1.1436, 'grad_norm': 2.8556573390960693, 'learning_rate': 8.336994840101513e-08, 'epoch': 2.46}
{'loss': 1.2744, 'grad_norm': 2.752183675765991, 'learning_rate': 8.1789143456728e-08, 'epoch': 2.47}
{'loss': 1.2318, 'grad_norm': 20.669954299926758, 'learning_rate': 8.022213343292955e-08, 'epoch': 2.47}
{'loss': 1.205, 'grad_norm': 3.0309345722198486, 'learning_rate': 7.866897001832695e-08, 'epoch': 2.48}
{'loss': 1.2207, 'grad_norm': 3.0121896266937256, 'learning_rate': 7.712970444489003e-08, 'epoch': 2.48}
{'loss': 1.1587, 'grad_norm': 3.200815439224243, 'learning_rate': 7.560438748615982e-08, 'epoch': 2.49}
{'loss': 1.1563, 'grad_norm': 3.3625056743621826, 'learning_rate': 7.409306945557487e-08, 'epoch': 2.49}
{'loss': 1.0964, 'grad_norm': 2.612884998321533, 'learning_rate': 7.259580020481092e-08, 'epoch': 2.5}
{'loss': 1.3195, 'grad_norm': 3.255033254623413, 'learning_rate': 7.111262912213706e-08, 'epoch': 2.5}
{'loss': 1.0283, 'grad_norm': 3.1572248935699463, 'learning_rate': 6.96436051307861e-08, 'epoch': 2.51}
{'loss': 1.1662, 'grad_norm': 3.635695219039917, 'learning_rate': 6.81887766873413e-08, 'epoch': 2.51}
{'loss': 1.1275, 'grad_norm': 3.002762794494629, 'learning_rate': 6.674819178013769e-08, 'epoch': 2.52}
{'loss': 1.3739, 'grad_norm': 3.0804874897003174, 'learning_rate': 6.532189792767922e-08, 'epoch': 2.52}
{'loss': 1.2248, 'grad_norm': 3.2087862491607666, 'learning_rate': 6.390994217707141e-08, 'epoch': 2.53}
{'loss': 1.1837, 'grad_norm': 3.5952632427215576, 'learning_rate': 6.251237110246943e-08, 'epoch': 2.54}
{'loss': 1.2864, 'grad_norm': 2.7601025104522705, 'learning_rate': 6.112923080354165e-08, 'epoch': 2.54}
{'loss': 1.3259, 'grad_norm': 2.9940311908721924, 'learning_rate': 5.976056690394959e-08, 'epoch': 2.55}
{'loss': 1.1138, 'grad_norm': 3.5985381603240967, 'learning_rate': 5.840642454984196e-08, 'epoch': 2.55}
{'loss': 1.1572, 'grad_norm': 4.34394645690918, 'learning_rate': 5.706684840836673e-08, 'epoch': 2.56}
{'loss': 1.0661, 'grad_norm': 21.46076202392578, 'learning_rate': 5.574188266619695e-08, 'epoch': 2.56}
{'loss': 1.1412, 'grad_norm': 4.323385238647461, 'learning_rate': 5.4431571028073054e-08, 'epoch': 2.57}
{'loss': 1.2133, 'grad_norm': 2.910644054412842, 'learning_rate': 5.31359567153622e-08, 'epoch': 2.57}
{'loss': 1.251, 'grad_norm': 7.529036521911621, 'learning_rate': 5.185508246463161e-08, 'epoch': 2.58}
{'loss': 1.1498, 'grad_norm': 6.301731586456299, 'learning_rate': 5.058899052623933e-08, 'epoch': 2.58}
{'loss': 1.1574, 'grad_norm': 2.806248188018799, 'learning_rate': 4.933772266294067e-08, 'epoch': 2.59}
{'loss': 1.2194, 'grad_norm': 2.835312843322754, 'learning_rate': 4.810132014851026e-08, 'epoch': 2.59}
{'loss': 1.125, 'grad_norm': 2.9269955158233643, 'learning_rate': 4.6879823766381e-08, 'epoch': 2.6}
{'loss': 1.1018, 'grad_norm': 3.0659210681915283, 'learning_rate': 4.5673273808298494e-08, 'epoch': 2.6}
{'loss': 1.0912, 'grad_norm': 2.548504590988159, 'learning_rate': 4.4481710072992284e-08, 'epoch': 2.61}
{'loss': 1.2117, 'grad_norm': 3.4960079193115234, 'learning_rate': 4.3305171864862655e-08, 'epoch': 2.61}
{'loss': 1.1652, 'grad_norm': 2.9652678966522217, 'learning_rate': 4.214369799268497e-08, 'epoch': 2.62}
{'loss': 1.121, 'grad_norm': 3.2023353576660156, 'learning_rate': 4.099732676832818e-08, 'epoch': 2.62}
{'loss': 1.2544, 'grad_norm': 3.4512054920196533, 'learning_rate': 3.9866096005492676e-08, 'epoch': 2.63}
{'loss': 1.1079, 'grad_norm': 21.159059524536133, 'learning_rate': 3.8750043018461854e-08, 'epoch': 2.63}
{'loss': 1.1458, 'grad_norm': 2.84645938873291, 'learning_rate': 3.7649204620871346e-08, 'epoch': 2.64}
{'loss': 0.9465, 'grad_norm': 2.516939640045166, 'learning_rate': 3.656361712449557e-08, 'epoch': 2.64}
{'loss': 1.1586, 'grad_norm': 2.859041690826416, 'learning_rate': 3.549331633804908e-08, 'epoch': 2.65}
{'loss': 1.1378, 'grad_norm': 2.6720082759857178, 'learning_rate': 3.443833756600567e-08, 'epoch': 2.65}
{'loss': 1.0098, 'grad_norm': 2.6831412315368652, 'learning_rate': 3.3398715607433795e-08, 'epoch': 2.66}
{'loss': 1.155, 'grad_norm': 4.232917785644531, 'learning_rate': 3.237448475484922e-08, 'epoch': 2.66}
{'loss': 1.2899, 'grad_norm': 2.8492958545684814, 'learning_rate': 3.1365678793082826e-08, 'epoch': 2.67}
{'loss': 1.1378, 'grad_norm': 2.6787092685699463, 'learning_rate': 3.037233099816705e-08, 'epoch': 2.68}
{'loss': 1.1047, 'grad_norm': 4.873188495635986, 'learning_rate': 2.9394474136238246e-08, 'epoch': 2.68}
{'loss': 1.2291, 'grad_norm': 3.5036394596099854, 'learning_rate': 2.843214046245507e-08, 'epoch': 2.69}
{'loss': 1.2532, 'grad_norm': 3.287233352661133, 'learning_rate': 2.748536171993565e-08, 'epoch': 2.69}
{'loss': 1.1231, 'grad_norm': 2.859121084213257, 'learning_rate': 2.6554169138709558e-08, 'epoch': 2.7}
{'loss': 1.2226, 'grad_norm': 3.265826463699341, 'learning_rate': 2.5638593434688218e-08, 'epoch': 2.7}
{'loss': 1.2616, 'grad_norm': 2.8961994647979736, 'learning_rate': 2.4738664808651498e-08, 'epoch': 2.71}
{'loss': 1.1572, 'grad_norm': 2.6663155555725098, 'learning_rate': 2.3854412945251756e-08, 'epoch': 2.71}
{'loss': 1.1512, 'grad_norm': 4.620259761810303, 'learning_rate': 2.2985867012034365e-08, 'epoch': 2.72}
{'loss': 1.1998, 'grad_norm': 6.739765644073486, 'learning_rate': 2.213305565847573e-08, 'epoch': 2.72}
{'loss': 1.1158, 'grad_norm': 3.035982608795166, 'learning_rate': 2.1296007015038365e-08, 'epoch': 2.73}
{'loss': 1.0529, 'grad_norm': 2.986982822418213, 'learning_rate': 2.047474869224286e-08, 'epoch': 2.73}
{'loss': 1.1379, 'grad_norm': 3.3592607975006104, 'learning_rate': 1.966930777975734e-08, 'epoch': 2.74}
{'loss': 1.2051, 'grad_norm': 3.3526370525360107, 'learning_rate': 1.8879710845503604e-08, 'epoch': 2.74}
{'loss': 1.0441, 'grad_norm': 3.0149788856506348, 'learning_rate': 1.81059839347808e-08, 'epoch': 2.75}
{'loss': 1.1287, 'grad_norm': 3.0671372413635254, 'learning_rate': 1.7348152569406748e-08, 'epoch': 2.75}
{'loss': 1.2928, 'grad_norm': 2.9119510650634766, 'learning_rate': 1.660624174687547e-08, 'epoch': 2.76}
{'loss': 1.1018, 'grad_norm': 2.689844846725464, 'learning_rate': 1.588027593953306e-08, 'epoch': 2.76}
{'loss': 1.2243, 'grad_norm': 15.842424392700195, 'learning_rate': 1.517027909377028e-08, 'epoch': 2.77}
{'loss': 1.1134, 'grad_norm': 5.392887115478516, 'learning_rate': 1.4476274629232677e-08, 'epoch': 2.77}
{'loss': 1.331, 'grad_norm': 6.923111438751221, 'learning_rate': 1.3798285438048118e-08, 'epoch': 2.78}
{'loss': 1.0706, 'grad_norm': 24.922391891479492, 'learning_rate': 1.3136333884071704e-08, 'epoch': 2.78}
{'loss': 1.2244, 'grad_norm': 3.2140331268310547, 'learning_rate': 1.2490441802148032e-08, 'epoch': 2.79}
{'loss': 1.0948, 'grad_norm': 2.800079822540283, 'learning_rate': 1.186063049739089e-08, 'epoch': 2.79}
{'loss': 1.1437, 'grad_norm': 3.2937824726104736, 'learning_rate': 1.1246920744480692e-08, 'epoch': 2.8}
{'loss': 1.2833, 'grad_norm': 2.642977476119995, 'learning_rate': 1.0649332786979049e-08, 'epoch': 2.81}
{'loss': 1.1472, 'grad_norm': 2.7180774211883545, 'learning_rate': 1.0067886336661113e-08, 'epoch': 2.81}
{'loss': 1.0594, 'grad_norm': 14.613792419433594, 'learning_rate': 9.502600572865282e-09, 'epoch': 2.82}
{'loss': 1.1839, 'grad_norm': 2.555373191833496, 'learning_rate': 8.953494141860584e-09, 'epoch': 2.82}
{'loss': 1.0506, 'grad_norm': 3.498919725418091, 'learning_rate': 8.42058515623184e-09, 'epoch': 2.83}
{'loss': 1.2728, 'grad_norm': 2.652651071548462, 'learning_rate': 7.903891194281753e-09, 'epoch': 2.83}
{'loss': 1.3343, 'grad_norm': 5.802038669586182, 'learning_rate': 7.403429299451536e-09, 'epoch': 2.84}
{'loss': 1.3031, 'grad_norm': 19.689685821533203, 'learning_rate': 6.919215979758475e-09, 'epoch': 2.84}
{'loss': 1.0976, 'grad_norm': 2.8976948261260986, 'learning_rate': 6.451267207251421e-09, 'epoch': 2.85}
{'loss': 1.008, 'grad_norm': 2.6645781993865967, 'learning_rate': 5.999598417484042e-09, 'epoch': 2.85}
{'loss': 1.2692, 'grad_norm': 2.9827206134796143, 'learning_rate': 5.5642245090055664e-09, 'epoch': 2.86}
{'loss': 1.2066, 'grad_norm': 3.240920305252075, 'learning_rate': 5.145159842869396e-09, 'epoch': 2.86}
{'loss': 1.1358, 'grad_norm': 2.8743932247161865, 'learning_rate': 4.742418242159485e-09, 'epoch': 2.87}
{'loss': 1.3073, 'grad_norm': 4.193234920501709, 'learning_rate': 4.356012991534097e-09, 'epoch': 2.87}
{'loss': 1.1358, 'grad_norm': 3.1134536266326904, 'learning_rate': 3.985956836787985e-09, 'epoch': 2.88}
{'loss': 1.4899, 'grad_norm': 3.3080925941467285, 'learning_rate': 3.6322619844317282e-09, 'epoch': 2.88}
{'loss': 1.0392, 'grad_norm': 2.5051822662353516, 'learning_rate': 3.294940101289001e-09, 'epoch': 2.89}
{'loss': 1.1007, 'grad_norm': 2.9378106594085693, 'learning_rate': 2.974002314112045e-09, 'epoch': 2.89}
{'loss': 0.9113, 'grad_norm': 2.5258188247680664, 'learning_rate': 2.6694592092144642e-09, 'epoch': 2.9}
{'loss': 1.1487, 'grad_norm': 5.9636077880859375, 'learning_rate': 2.3813208321218357e-09, 'epoch': 2.9}
{'loss': 1.1978, 'grad_norm': 3.0643866062164307, 'learning_rate': 2.1095966872407556e-09, 'epoch': 2.91}
{'loss': 1.0259, 'grad_norm': 3.262035608291626, 'learning_rate': 1.8542957375451417e-09, 'epoch': 2.91}
{'loss': 1.1123, 'grad_norm': 3.23508358001709, 'learning_rate': 1.6154264042805287e-09, 'epoch': 2.92}
{'loss': 1.0826, 'grad_norm': 3.2075860500335693, 'learning_rate': 1.3929965666861776e-09, 'epoch': 2.92}
{'loss': 1.1876, 'grad_norm': 9.626354217529297, 'learning_rate': 1.187013561735617e-09, 'epoch': 2.93}
{'loss': 1.3285, 'grad_norm': 3.168161630630493, 'learning_rate': 9.97484183894115e-10, 'epoch': 2.94}
{'loss': 1.4165, 'grad_norm': 2.9164962768554688, 'learning_rate': 8.244146848949141e-10, 'epoch': 2.94}
{'loss': 0.9996, 'grad_norm': 12.56229305267334, 'learning_rate': 6.678107735328398e-10, 'epoch': 2.95}
{'loss': 1.3138, 'grad_norm': 3.0112392902374268, 'learning_rate': 5.276776154760631e-10, 'epoch': 2.95}
{'loss': 1.1276, 'grad_norm': 2.7098312377929688, 'learning_rate': 4.0401983309568124e-10, 'epoch': 2.96}
{'loss': 1.1421, 'grad_norm': 3.271608352661133, 'learning_rate': 2.968415053131723e-10, 'epoch': 2.96}
{'loss': 1.1479, 'grad_norm': 3.3340907096862793, 'learning_rate': 2.061461674661147e-10, 'epoch': 2.97}
{'loss': 1.2708, 'grad_norm': 7.549006462097168, 'learning_rate': 1.3193681119116895e-10, 'epoch': 2.97}
{'loss': 1.172, 'grad_norm': 2.88993501663208, 'learning_rate': 7.421588432576786e-11, 'epoch': 2.98}
{'loss': 1.3148, 'grad_norm': 2.7654311656951904, 'learning_rate': 3.298529082718105e-11, 'epoch': 2.98}
{'loss': 1.2388, 'grad_norm': 3.1223316192626953, 'learning_rate': 8.246390709787388e-12, 'epoch': 2.99}
{'loss': 1.1029, 'grad_norm': 2.752298593521118, 'learning_rate': 0.0, 'epoch': 2.99}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-576/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-576/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-576/model.safetensors.index.json.
2025-01-03 00:01:54,162 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-576/pytorch_model_fsdp.bin
2025-01-03 00:02:35,456 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-576/pytorch_model_fsdp.bin
2025-01-03 00:03:07,001 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-576/optimizer.bin
2025-01-03 00:04:32,496 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-576/optimizer.bin
Saving model checkpoint to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-576
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-576/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-576/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-576/model.safetensors.index.json.
2025-01-03 00:06:36,801 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-576/pytorch_model_fsdp.bin
2025-01-03 00:07:19,327 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-576/pytorch_model_fsdp.bin
2025-01-03 00:07:50,889 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-576/optimizer.bin
2025-01-03 00:09:16,387 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/checkpoint-576/optimizer.bin


Training completed. Do not forget to share your model on huggingface.co/models =)


100%|| 576/576 [40:45<00:00,  4.25s/it]
{'train_runtime': 2446.7357, 'train_samples_per_second': 1.888, 'train_steps_per_second': 0.235, 'train_loss': 1.226394911089705, 'epoch': 2.99}
Saving model checkpoint to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5news_priorlearninglr5e06rt1rr0.1epochs5blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint725/model.safetensors.index.json.
