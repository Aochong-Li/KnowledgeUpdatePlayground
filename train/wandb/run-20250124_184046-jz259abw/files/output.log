                                                                                                                                                                                               
{'loss': 1.6466, 'grad_norm': inf, 'learning_rate': 4.1666666666666667e-07, 'epoch': 0.0}
{'loss': 1.6357, 'grad_norm': inf, 'learning_rate': 8.333333333333333e-07, 'epoch': 0.01}
{'loss': 1.6442, 'grad_norm': inf, 'learning_rate': 1.25e-06, 'epoch': 0.01}
{'loss': 1.6762, 'grad_norm': inf, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.02}
{'loss': 1.6953, 'grad_norm': inf, 'learning_rate': 2.0833333333333334e-06, 'epoch': 0.02}
{'loss': 1.6577, 'grad_norm': inf, 'learning_rate': 2.5e-06, 'epoch': 0.03}
{'loss': 1.622, 'grad_norm': inf, 'learning_rate': 2.916666666666667e-06, 'epoch': 0.03}
{'loss': 1.709, 'grad_norm': inf, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.03}
{'loss': 1.6793, 'grad_norm': inf, 'learning_rate': 3.7500000000000005e-06, 'epoch': 0.04}
{'loss': 1.679, 'grad_norm': 1.0069755197195813e+19, 'learning_rate': 4.166666666666667e-06, 'epoch': 0.04}
{'loss': 1.7977, 'grad_norm': 783870066688.0, 'learning_rate': 4.583333333333333e-06, 'epoch': 0.05}
{'loss': 1.6723, 'grad_norm': 1247.2960205078125, 'learning_rate': 5e-06, 'epoch': 0.05}
{'loss': 1.6243, 'grad_norm': 1371.9892578125, 'learning_rate': 4.999756310023261e-06, 'epoch': 0.05}
{'loss': 1.526, 'grad_norm': 53.969093322753906, 'learning_rate': 4.999025287600886e-06, 'epoch': 0.06}
{'loss': 1.5, 'grad_norm': 8.11705207824707, 'learning_rate': 4.997807075247147e-06, 'epoch': 0.06}
{'loss': 1.4415, 'grad_norm': 4.400618553161621, 'learning_rate': 4.996101910454953e-06, 'epoch': 0.07}
{'loss': 1.4393, 'grad_norm': 4.260615348815918, 'learning_rate': 4.993910125649561e-06, 'epoch': 0.07}
{'loss': 1.3946, 'grad_norm': 4.034206867218018, 'learning_rate': 4.9912321481237616e-06, 'epoch': 0.08}
{'loss': 1.3832, 'grad_norm': 2.8446872234344482, 'learning_rate': 4.988068499954578e-06, 'epoch': 0.08}
{'loss': 1.3558, 'grad_norm': 2.1964778900146484, 'learning_rate': 4.984419797901491e-06, 'epoch': 0.08}
{'loss': 1.3373, 'grad_norm': 2.9769909381866455, 'learning_rate': 4.980286753286196e-06, 'epoch': 0.09}
{'loss': 1.3064, 'grad_norm': 2.2710630893707275, 'learning_rate': 4.975670171853926e-06, 'epoch': 0.09}
{'loss': 1.3192, 'grad_norm': 2.9077069759368896, 'learning_rate': 4.970570953616383e-06, 'epoch': 0.1}
{'loss': 1.2719, 'grad_norm': 2.325042247772217, 'learning_rate': 4.964990092676263e-06, 'epoch': 0.1}
{'loss': 1.349, 'grad_norm': 2.745089530944824, 'learning_rate': 4.958928677033465e-06, 'epoch': 0.11}
{'loss': 1.2791, 'grad_norm': 2.127318859100342, 'learning_rate': 4.9523878883729794e-06, 'epoch': 0.11}
{'loss': 1.2879, 'grad_norm': 2.3043148517608643, 'learning_rate': 4.9453690018345144e-06, 'epoch': 0.11}
{'loss': 1.2793, 'grad_norm': 2.076058864593506, 'learning_rate': 4.937873385763909e-06, 'epoch': 0.12}
{'loss': 1.283, 'grad_norm': 2.9001874923706055, 'learning_rate': 4.9299025014463665e-06, 'epoch': 0.12}
{'loss': 1.2687, 'grad_norm': 2.19838285446167, 'learning_rate': 4.921457902821578e-06, 'epoch': 0.13}
{'loss': 1.2878, 'grad_norm': 2.2281365394592285, 'learning_rate': 4.912541236180779e-06, 'epoch': 0.13}
{'loss': 1.2692, 'grad_norm': 3.435526132583618, 'learning_rate': 4.903154239845798e-06, 'epoch': 0.13}
{'loss': 1.2615, 'grad_norm': 2.0059499740600586, 'learning_rate': 4.893298743830168e-06, 'epoch': 0.14}
{'loss': 1.2577, 'grad_norm': 2.350717067718506, 'learning_rate': 4.882976669482368e-06, 'epoch': 0.14}
{'loss': 1.2349, 'grad_norm': 2.7287001609802246, 'learning_rate': 4.8721900291112415e-06, 'epoch': 0.15}
{'loss': 1.2874, 'grad_norm': 2.5679197311401367, 'learning_rate': 4.860940925593703e-06, 'epoch': 0.15}
{'loss': 1.2451, 'grad_norm': 1.9375518560409546, 'learning_rate': 4.849231551964771e-06, 'epoch': 0.16}
{'loss': 1.2613, 'grad_norm': 2.663053274154663, 'learning_rate': 4.837064190990036e-06, 'epoch': 0.16}
{'loss': 1.2472, 'grad_norm': 2.2778127193450928, 'learning_rate': 4.824441214720629e-06, 'epoch': 0.16}
{'loss': 1.1895, 'grad_norm': 2.495462417602539, 'learning_rate': 4.811365084030784e-06, 'epoch': 0.17}
{'loss': 1.2362, 'grad_norm': 2.290713310241699, 'learning_rate': 4.7978383481380865e-06, 'epoch': 0.17}
{'loss': 1.2207, 'grad_norm': 1.9527405500411987, 'learning_rate': 4.783863644106502e-06, 'epoch': 0.18}
{'loss': 1.2315, 'grad_norm': 2.1588518619537354, 'learning_rate': 4.769443696332272e-06, 'epoch': 0.18}
{'loss': 1.2557, 'grad_norm': 2.005657911300659, 'learning_rate': 4.754581316012785e-06, 'epoch': 0.19}
{'loss': 1.255, 'grad_norm': 2.085891008377075, 'learning_rate': 4.7392794005985324e-06, 'epoch': 0.19}
{'loss': 1.2122, 'grad_norm': 2.307488203048706, 'learning_rate': 4.723540933228245e-06, 'epoch': 0.19}
{'loss': 1.2629, 'grad_norm': 2.25571608543396, 'learning_rate': 4.707368982147318e-06, 'epoch': 0.2}
{'loss': 1.1989, 'grad_norm': 2.0906805992126465, 'learning_rate': 4.690766700109659e-06, 'epoch': 0.2}
{'loss': 1.1719, 'grad_norm': 1.999198317527771, 'learning_rate': 4.673737323763048e-06, 'epoch': 0.21}
{'loss': 1.2657, 'grad_norm': 2.8223085403442383, 'learning_rate': 4.656284173018144e-06, 'epoch': 0.21}
{'loss': 1.1891, 'grad_norm': 2.2694153785705566, 'learning_rate': 4.638410650401267e-06, 'epoch': 0.22}
{'loss': 1.1893, 'grad_norm': 1.9358912706375122, 'learning_rate': 4.620120240391065e-06, 'epoch': 0.22}
{'loss': 1.1955, 'grad_norm': 2.05210542678833, 'learning_rate': 4.601416508739211e-06, 'epoch': 0.22}
{'loss': 1.2056, 'grad_norm': 2.2399868965148926, 'learning_rate': 4.582303101775249e-06, 'epoch': 0.23}
{'loss': 1.1686, 'grad_norm': 2.0117530822753906, 'learning_rate': 4.562783745695738e-06, 'epoch': 0.23}
{'loss': 1.2061, 'grad_norm': 2.0346367359161377, 'learning_rate': 4.542862245837821e-06, 'epoch': 0.24}
{'loss': 1.2165, 'grad_norm': 2.215557813644409, 'learning_rate': 4.522542485937369e-06, 'epoch': 0.24}
{'loss': 1.2354, 'grad_norm': 2.425588846206665, 'learning_rate': 4.501828427371834e-06, 'epoch': 0.24}
{'loss': 1.1997, 'grad_norm': 2.399212121963501, 'learning_rate': 4.4807241083879774e-06, 'epoch': 0.25}
{'loss': 1.1918, 'grad_norm': 2.056297540664673, 'learning_rate': 4.4592336433146e-06, 'epoch': 0.25}
{'loss': 1.1655, 'grad_norm': 2.0663061141967773, 'learning_rate': 4.437361221760449e-06, 'epoch': 0.26}
{'loss': 1.1719, 'grad_norm': 1.920897364616394, 'learning_rate': 4.415111107797445e-06, 'epoch': 0.26}
{'loss': 1.1591, 'grad_norm': 1.660469889640808, 'learning_rate': 4.3924876391293915e-06, 'epoch': 0.27}
{'loss': 1.1931, 'grad_norm': 1.8066507577896118, 'learning_rate': 4.36949522624633e-06, 'epoch': 0.27}
{'loss': 1.1674, 'grad_norm': 1.812313437461853, 'learning_rate': 4.346138351564711e-06, 'epoch': 0.27}
{'loss': 1.1368, 'grad_norm': 1.6713639497756958, 'learning_rate': 4.322421568553529e-06, 'epoch': 0.28}
{'loss': 1.1467, 'grad_norm': 1.4867336750030518, 'learning_rate': 4.2983495008466285e-06, 'epoch': 0.28}
{'loss': 1.2071, 'grad_norm': 1.837999701499939, 'learning_rate': 4.273926841341303e-06, 'epoch': 0.29}
{'loss': 1.2142, 'grad_norm': 1.855086326599121, 'learning_rate': 4.249158351283414e-06, 'epoch': 0.29}
{'loss': 1.1683, 'grad_norm': 1.6255531311035156, 'learning_rate': 4.224048859339175e-06, 'epoch': 0.3}
{'loss': 1.162, 'grad_norm': 1.5916767120361328, 'learning_rate': 4.198603260653792e-06, 'epoch': 0.3}
{'loss': 1.1498, 'grad_norm': 1.3489660024642944, 'learning_rate': 4.172826515897146e-06, 'epoch': 0.3}
{'loss': 1.1672, 'grad_norm': 1.3169004917144775, 'learning_rate': 4.146723650296701e-06, 'epoch': 0.31}
{'loss': 1.1675, 'grad_norm': 1.3983033895492554, 'learning_rate': 4.120299752657828e-06, 'epoch': 0.31}
{'loss': 1.1952, 'grad_norm': 1.410682201385498, 'learning_rate': 4.093559974371725e-06, 'epoch': 0.32}
{'loss': 1.1589, 'grad_norm': 1.3347400426864624, 'learning_rate': 4.066509528411151e-06, 'epoch': 0.32}
{'loss': 1.1631, 'grad_norm': 1.401659369468689, 'learning_rate': 4.039153688314146e-06, 'epoch': 0.32}
{'loss': 1.1426, 'grad_norm': 1.1720722913742065, 'learning_rate': 4.011497787155938e-06, 'epoch': 0.33}
{'loss': 1.1735, 'grad_norm': 1.266190528869629, 'learning_rate': 3.983547216509254e-06, 'epoch': 0.33}
{'loss': 1.1379, 'grad_norm': 1.2100188732147217, 'learning_rate': 3.955307425393224e-06, 'epoch': 0.34}
{'loss': 1.1127, 'grad_norm': 1.3852553367614746, 'learning_rate': 3.92678391921108e-06, 'epoch': 0.34}
{'loss': 1.1811, 'grad_norm': 1.0835508108139038, 'learning_rate': 3.897982258676867e-06, 'epoch': 0.35}
{'loss': 1.1772, 'grad_norm': 1.1347519159317017, 'learning_rate': 3.868908058731376e-06, 'epoch': 0.35}
{'loss': 1.1367, 'grad_norm': 1.0808074474334717, 'learning_rate': 3.839566987447492e-06, 'epoch': 0.35}
{'loss': 1.1564, 'grad_norm': 1.4775161743164062, 'learning_rate': 3.8099647649251984e-06, 'epoch': 0.36}
{'loss': 1.1544, 'grad_norm': 1.140984296798706, 'learning_rate': 3.780107162176429e-06, 'epoch': 0.36}
{'loss': 1.1691, 'grad_norm': 1.1190520524978638, 'learning_rate': 3.7500000000000005e-06, 'epoch': 0.37}
{'loss': 1.139, 'grad_norm': 1.0865333080291748, 'learning_rate': 3.7196491478468322e-06, 'epoch': 0.37}
{'loss': 1.1241, 'grad_norm': 2.9006454944610596, 'learning_rate': 3.689060522675689e-06, 'epoch': 0.38}
{'loss': 1.124, 'grad_norm': 0.9787397384643555, 'learning_rate': 3.658240087799655e-06, 'epoch': 0.38}
{'loss': 1.1205, 'grad_norm': 0.9649037718772888, 'learning_rate': 3.627193851723577e-06, 'epoch': 0.38}
{'loss': 1.1611, 'grad_norm': 0.9719855189323425, 'learning_rate': 3.595927866972694e-06, 'epoch': 0.39}
{'loss': 1.1322, 'grad_norm': 0.9329463839530945, 'learning_rate': 3.564448228912682e-06, 'epoch': 0.39}
{'loss': 1.1437, 'grad_norm': 0.9941666722297668, 'learning_rate': 3.532761074561355e-06, 'epoch': 0.4}
{'loss': 1.1404, 'grad_norm': 10.037091255187988, 'learning_rate': 3.5008725813922383e-06, 'epoch': 0.4}
{'loss': 1.1498, 'grad_norm': 1.1197830438613892, 'learning_rate': 3.4687889661302577e-06, 'epoch': 0.4}
{'loss': 1.1621, 'grad_norm': 0.9781020283699036, 'learning_rate': 3.436516483539781e-06, 'epoch': 0.41}
{'loss': 1.1609, 'grad_norm': 1.0097639560699463, 'learning_rate': 3.4040614252052305e-06, 'epoch': 0.41}
{'loss': 1.1539, 'grad_norm': 2.243631362915039, 'learning_rate': 3.3714301183045382e-06, 'epoch': 0.42}
{'loss': 1.1175, 'grad_norm': 1.101623773574829, 'learning_rate': 3.338628924375638e-06, 'epoch': 0.42}
{'loss': 1.1224, 'grad_norm': 0.9023314118385315, 'learning_rate': 3.3056642380762783e-06, 'epoch': 0.43}
{'loss': 1.1398, 'grad_norm': 1.7549774646759033, 'learning_rate': 3.272542485937369e-06, 'epoch': 0.43}
{'loss': 1.177, 'grad_norm': 1.0441077947616577, 'learning_rate': 3.2392701251101172e-06, 'epoch': 0.43}
{'loss': 1.1065, 'grad_norm': 0.9119685888290405, 'learning_rate': 3.205853642107192e-06, 'epoch': 0.44}
{'loss': 1.1307, 'grad_norm': 1.0476166009902954, 'learning_rate': 3.1722995515381644e-06, 'epoch': 0.44}
{'loss': 1.1548, 'grad_norm': 1.0310049057006836, 'learning_rate': 3.1386143948394764e-06, 'epoch': 0.45}
{'loss': 1.1302, 'grad_norm': 0.9846919178962708, 'learning_rate': 3.1048047389991693e-06, 'epoch': 0.45}
{'loss': 1.1285, 'grad_norm': 0.9634126424789429, 'learning_rate': 3.0708771752766397e-06, 'epoch': 0.46}
{'loss': 1.1724, 'grad_norm': 1.2287729978561401, 'learning_rate': 3.0368383179176584e-06, 'epoch': 0.46}
{'loss': 1.1268, 'grad_norm': 0.9981182217597961, 'learning_rate': 3.002694802864912e-06, 'epoch': 0.46}
{'loss': 1.123, 'grad_norm': 0.914676308631897, 'learning_rate': 2.9684532864643123e-06, 'epoch': 0.47}
{'loss': 1.1098, 'grad_norm': 0.9892123341560364, 'learning_rate': 2.9341204441673267e-06, 'epoch': 0.47}
{'loss': 1.1596, 'grad_norm': 1.0110176801681519, 'learning_rate': 2.8997029692295875e-06, 'epoch': 0.48}
{'loss': 1.1458, 'grad_norm': 0.9583893418312073, 'learning_rate': 2.8652075714060296e-06, 'epoch': 0.48}
{'loss': 1.1415, 'grad_norm': 0.9558817148208618, 'learning_rate': 2.8306409756428067e-06, 'epoch': 0.48}
{'loss': 1.0954, 'grad_norm': 0.9940220713615417, 'learning_rate': 2.7960099207662535e-06, 'epoch': 0.49}
{'loss': 1.1734, 'grad_norm': 0.9910052418708801, 'learning_rate': 2.761321158169134e-06, 'epoch': 0.49}
{'loss': 1.1397, 'grad_norm': 1.006028652191162, 'learning_rate': 2.726581450494451e-06, 'epoch': 0.5}
{'loss': 1.1091, 'grad_norm': 1.1350784301757812, 'learning_rate': 2.6917975703170466e-06, 'epoch': 0.5}
{'loss': 1.119, 'grad_norm': 0.9973502159118652, 'learning_rate': 2.6569762988232838e-06, 'epoch': 0.51}
{'loss': 1.1221, 'grad_norm': 1.0233319997787476, 'learning_rate': 2.6221244244890336e-06, 'epoch': 0.51}
{'loss': 1.1257, 'grad_norm': 0.9222121238708496, 'learning_rate': 2.587248741756253e-06, 'epoch': 0.51}
{'loss': 1.1291, 'grad_norm': 0.9951838850975037, 'learning_rate': 2.5523560497083927e-06, 'epoch': 0.52}
{'loss': 1.1452, 'grad_norm': 1.0473517179489136, 'learning_rate': 2.517453150744904e-06, 'epoch': 0.52}
{'loss': 1.0891, 'grad_norm': 0.9113153219223022, 'learning_rate': 2.482546849255096e-06, 'epoch': 0.53}
{'loss': 1.1116, 'grad_norm': 1.001702070236206, 'learning_rate': 2.447643950291608e-06, 'epoch': 0.53}
{'loss': 1.0751, 'grad_norm': 0.8694192171096802, 'learning_rate': 2.4127512582437486e-06, 'epoch': 0.54}
{'loss': 1.13, 'grad_norm': 2.3722307682037354, 'learning_rate': 2.377875575510967e-06, 'epoch': 0.54}
{'loss': 1.1595, 'grad_norm': 1.07162344455719, 'learning_rate': 2.3430237011767166e-06, 'epoch': 0.54}
{'loss': 1.0988, 'grad_norm': 1.1900334358215332, 'learning_rate': 2.3082024296829538e-06, 'epoch': 0.55}
{'loss': 1.0975, 'grad_norm': 0.9833030700683594, 'learning_rate': 2.2734185495055503e-06, 'epoch': 0.55}
{'loss': 1.1175, 'grad_norm': 0.9671364426612854, 'learning_rate': 2.238678841830867e-06, 'epoch': 0.56}
{'loss': 1.1572, 'grad_norm': 1.028777837753296, 'learning_rate': 2.2039900792337477e-06, 'epoch': 0.56}
{'loss': 1.1107, 'grad_norm': 1.044775366783142, 'learning_rate': 2.1693590243571937e-06, 'epoch': 0.56}
{'loss': 1.147, 'grad_norm': 1.0014697313308716, 'learning_rate': 2.134792428593971e-06, 'epoch': 0.57}
{'loss': 1.1082, 'grad_norm': 0.9724781513214111, 'learning_rate': 2.1002970307704134e-06, 'epoch': 0.57}
{'loss': 1.1219, 'grad_norm': 1.145517110824585, 'learning_rate': 2.0658795558326745e-06, 'epoch': 0.58}
{'loss': 1.108, 'grad_norm': 1.051794171333313, 'learning_rate': 2.031546713535688e-06, 'epoch': 0.58}
{'loss': 1.1121, 'grad_norm': 1.0570549964904785, 'learning_rate': 1.997305197135089e-06, 'epoch': 0.59}
{'loss': 1.1175, 'grad_norm': 1.1328489780426025, 'learning_rate': 1.963161682082342e-06, 'epoch': 0.59}
{'loss': 1.1265, 'grad_norm': 0.9993433952331543, 'learning_rate': 1.9291228247233607e-06, 'epoch': 0.59}
{'loss': 1.0885, 'grad_norm': 0.9207010269165039, 'learning_rate': 1.895195261000831e-06, 'epoch': 0.6}
{'loss': 1.1123, 'grad_norm': 0.9345079064369202, 'learning_rate': 1.8613856051605242e-06, 'epoch': 0.6}
{'loss': 1.0998, 'grad_norm': 1.024055004119873, 'learning_rate': 1.827700448461836e-06, 'epoch': 0.61}
{'loss': 1.0852, 'grad_norm': 0.9891921281814575, 'learning_rate': 1.7941463578928088e-06, 'epoch': 0.61}
{'loss': 1.1063, 'grad_norm': 1.0078343152999878, 'learning_rate': 1.7607298748898844e-06, 'epoch': 0.62}
{'loss': 1.0799, 'grad_norm': 0.9664648175239563, 'learning_rate': 1.7274575140626318e-06, 'epoch': 0.62}
{'loss': 1.121, 'grad_norm': 0.9570339322090149, 'learning_rate': 1.6943357619237227e-06, 'epoch': 0.62}
{'loss': 1.1069, 'grad_norm': 0.9844136238098145, 'learning_rate': 1.661371075624363e-06, 'epoch': 0.63}
{'loss': 1.1426, 'grad_norm': 0.9669477939605713, 'learning_rate': 1.6285698816954626e-06, 'epoch': 0.63}
{'loss': 1.0949, 'grad_norm': 1.049958348274231, 'learning_rate': 1.5959385747947697e-06, 'epoch': 0.64}
{'loss': 1.1035, 'grad_norm': 0.950324535369873, 'learning_rate': 1.56348351646022e-06, 'epoch': 0.64}
{'loss': 1.1246, 'grad_norm': 0.9317883849143982, 'learning_rate': 1.5312110338697427e-06, 'epoch': 0.65}
{'loss': 1.1174, 'grad_norm': 1.1376270055770874, 'learning_rate': 1.4991274186077632e-06, 'epoch': 0.65}
{'loss': 1.1064, 'grad_norm': 0.9950849413871765, 'learning_rate': 1.467238925438646e-06, 'epoch': 0.65}
{'loss': 1.0774, 'grad_norm': 0.9134871363639832, 'learning_rate': 1.4355517710873184e-06, 'epoch': 0.66}
{'loss': 1.1014, 'grad_norm': 0.8858981132507324, 'learning_rate': 1.4040721330273063e-06, 'epoch': 0.66}
{'loss': 1.1182, 'grad_norm': 0.9636738300323486, 'learning_rate': 1.3728061482764238e-06, 'epoch': 0.67}
{'loss': 1.1161, 'grad_norm': 0.9789443612098694, 'learning_rate': 1.3417599122003464e-06, 'epoch': 0.67}
{'loss': 1.0752, 'grad_norm': 0.9701132774353027, 'learning_rate': 1.3109394773243117e-06, 'epoch': 0.67}
{'loss': 1.0795, 'grad_norm': 1.0161610841751099, 'learning_rate': 1.280350852153168e-06, 'epoch': 0.68}
{'loss': 1.1054, 'grad_norm': 0.9853827357292175, 'learning_rate': 1.2500000000000007e-06, 'epoch': 0.68}
{'loss': 1.114, 'grad_norm': 0.9082340598106384, 'learning_rate': 1.2198928378235717e-06, 'epoch': 0.69}
{'loss': 1.1323, 'grad_norm': 0.951274037361145, 'learning_rate': 1.1900352350748026e-06, 'epoch': 0.69}
{'loss': 1.0972, 'grad_norm': 0.9015154242515564, 'learning_rate': 1.160433012552508e-06, 'epoch': 0.7}
{'loss': 1.1234, 'grad_norm': 0.9818660020828247, 'learning_rate': 1.1310919412686248e-06, 'epoch': 0.7}
{'loss': 1.0952, 'grad_norm': 0.9864105582237244, 'learning_rate': 1.1020177413231334e-06, 'epoch': 0.7}
{'loss': 1.0936, 'grad_norm': 0.9480448961257935, 'learning_rate': 1.073216080788921e-06, 'epoch': 0.71}
{'loss': 1.0841, 'grad_norm': 1.012035608291626, 'learning_rate': 1.0446925746067768e-06, 'epoch': 0.71}
{'loss': 1.1173, 'grad_norm': 0.9704771637916565, 'learning_rate': 1.0164527834907468e-06, 'epoch': 0.72}
{'loss': 1.1007, 'grad_norm': 0.9806947112083435, 'learning_rate': 9.88502212844063e-07, 'epoch': 0.72}
{'loss': 1.0526, 'grad_norm': 0.9957646131515503, 'learning_rate': 9.608463116858544e-07, 'epoch': 0.73}
{'loss': 1.1014, 'grad_norm': 0.8641142845153809, 'learning_rate': 9.334904715888496e-07, 'epoch': 0.73}
{'loss': 1.0898, 'grad_norm': 1.0008749961853027, 'learning_rate': 9.064400256282757e-07, 'epoch': 0.73}
{'loss': 1.1273, 'grad_norm': 0.9729471802711487, 'learning_rate': 8.797002473421729e-07, 'epoch': 0.74}
{'loss': 1.0806, 'grad_norm': 0.9249724745750427, 'learning_rate': 8.532763497032987e-07, 'epoch': 0.74}
{'loss': 1.0918, 'grad_norm': 0.940037727355957, 'learning_rate': 8.271734841028553e-07, 'epoch': 0.75}
{'loss': 1.1074, 'grad_norm': 0.8729698061943054, 'learning_rate': 8.013967393462094e-07, 'epoch': 0.75}
{'loss': 1.0457, 'grad_norm': 0.9065372347831726, 'learning_rate': 7.759511406608255e-07, 'epoch': 0.75}
{'loss': 1.0964, 'grad_norm': 1.0203922986984253, 'learning_rate': 7.508416487165862e-07, 'epoch': 0.76}
{'loss': 1.0819, 'grad_norm': 0.9550448060035706, 'learning_rate': 7.260731586586983e-07, 'epoch': 0.76}
{'loss': 1.0993, 'grad_norm': 0.884699821472168, 'learning_rate': 7.016504991533727e-07, 'epoch': 0.77}
{'loss': 1.0985, 'grad_norm': 0.8987091183662415, 'learning_rate': 6.775784314464717e-07, 'epoch': 0.77}
{'loss': 1.1178, 'grad_norm': 0.8877607583999634, 'learning_rate': 6.538616484352902e-07, 'epoch': 0.78}
{'loss': 1.1288, 'grad_norm': 0.8635047078132629, 'learning_rate': 6.305047737536707e-07, 'epoch': 0.78}
{'loss': 1.1278, 'grad_norm': 0.9313632845878601, 'learning_rate': 6.075123608706093e-07, 'epoch': 0.78}
{'loss': 1.0764, 'grad_norm': 0.9563828706741333, 'learning_rate': 5.848888922025553e-07, 'epoch': 0.79}
{'loss': 1.1085, 'grad_norm': 0.9310933947563171, 'learning_rate': 5.626387782395512e-07, 'epoch': 0.79}
{'loss': 1.085, 'grad_norm': 0.8877431154251099, 'learning_rate': 5.407663566854008e-07, 'epoch': 0.8}
{'loss': 1.1027, 'grad_norm': 0.9924443364143372, 'learning_rate': 5.192758916120236e-07, 'epoch': 0.8}
{'loss': 1.0876, 'grad_norm': 1.027952790260315, 'learning_rate': 4.981715726281666e-07, 'epoch': 0.81}
{'loss': 1.1165, 'grad_norm': 0.934718132019043, 'learning_rate': 4.774575140626317e-07, 'epoch': 0.81}
{'loss': 1.0709, 'grad_norm': 0.8614667654037476, 'learning_rate': 4.5713775416217884e-07, 'epoch': 0.81}
{'loss': 1.0617, 'grad_norm': 0.8183999061584473, 'learning_rate': 4.372162543042624e-07, 'epoch': 0.82}
{'loss': 1.0741, 'grad_norm': 0.9008658528327942, 'learning_rate': 4.1769689822475147e-07, 'epoch': 0.82}
{'loss': 1.1013, 'grad_norm': 1.1222480535507202, 'learning_rate': 3.9858349126078945e-07, 'epoch': 0.83}
{'loss': 1.1017, 'grad_norm': 1.1080812215805054, 'learning_rate': 3.798797596089351e-07, 'epoch': 0.83}
{'loss': 1.0834, 'grad_norm': 0.8598790764808655, 'learning_rate': 3.615893495987335e-07, 'epoch': 0.83}
{'loss': 1.0935, 'grad_norm': 0.8418112397193909, 'learning_rate': 3.4371582698185636e-07, 'epoch': 0.84}
{'loss': 1.0727, 'grad_norm': 0.902887761592865, 'learning_rate': 3.262626762369525e-07, 'epoch': 0.84}
{'loss': 1.0893, 'grad_norm': 0.8972229957580566, 'learning_rate': 3.092332998903416e-07, 'epoch': 0.85}
{'loss': 1.1097, 'grad_norm': 0.925621509552002, 'learning_rate': 2.9263101785268253e-07, 'epoch': 0.85}
{'loss': 1.1267, 'grad_norm': 0.9653773307800293, 'learning_rate': 2.764590667717562e-07, 'epoch': 0.86}
{'loss': 1.1301, 'grad_norm': 0.9490351676940918, 'learning_rate': 2.6072059940146775e-07, 'epoch': 0.86}
{'loss': 1.0668, 'grad_norm': 0.9039834141731262, 'learning_rate': 2.454186839872158e-07, 'epoch': 0.86}
{'loss': 1.1508, 'grad_norm': 0.9170597791671753, 'learning_rate': 2.3055630366772857e-07, 'epoch': 0.87}
{'loss': 1.1449, 'grad_norm': 0.8614933490753174, 'learning_rate': 2.1613635589349756e-07, 'epoch': 0.87}
{'loss': 1.1136, 'grad_norm': 0.9486643075942993, 'learning_rate': 2.0216165186191406e-07, 'epoch': 0.88}
{'loss': 1.1023, 'grad_norm': 0.9378331303596497, 'learning_rate': 1.8863491596921745e-07, 'epoch': 0.88}
{'loss': 1.0809, 'grad_norm': 0.9928594827651978, 'learning_rate': 1.7555878527937164e-07, 'epoch': 0.89}
{'loss': 1.0792, 'grad_norm': 0.9716244339942932, 'learning_rate': 1.629358090099639e-07, 'epoch': 0.89}
{'loss': 1.1019, 'grad_norm': 0.9677726626396179, 'learning_rate': 1.507684480352292e-07, 'epoch': 0.89}
{'loss': 1.1134, 'grad_norm': 0.8814168572425842, 'learning_rate': 1.3905907440629752e-07, 'epoch': 0.9}
{'loss': 1.0818, 'grad_norm': 0.9458897113800049, 'learning_rate': 1.278099708887587e-07, 'epoch': 0.9}
{'loss': 1.1007, 'grad_norm': 0.9268872737884521, 'learning_rate': 1.1702333051763271e-07, 'epoch': 0.91}
{'loss': 1.0909, 'grad_norm': 0.8507552146911621, 'learning_rate': 1.067012561698319e-07, 'epoch': 0.91}
{'loss': 1.0821, 'grad_norm': 0.8325397968292236, 'learning_rate': 9.684576015420277e-08, 'epoch': 0.91}
{'loss': 1.1329, 'grad_norm': 0.8913426995277405, 'learning_rate': 8.745876381922147e-08, 'epoch': 0.92}
{'loss': 1.13, 'grad_norm': 0.9050509333610535, 'learning_rate': 7.854209717842231e-08, 'epoch': 0.92}
{'loss': 1.0751, 'grad_norm': 0.866947591304779, 'learning_rate': 7.009749855363457e-08, 'epoch': 0.93}
{'loss': 1.1417, 'grad_norm': 0.8988154530525208, 'learning_rate': 6.212661423609184e-08, 'epoch': 0.93}
{'loss': 1.105, 'grad_norm': 0.8619095683097839, 'learning_rate': 5.463099816548578e-08, 'epoch': 0.94}
{'loss': 1.1009, 'grad_norm': 0.9167425036430359, 'learning_rate': 4.761211162702117e-08, 'epoch': 0.94}
{'loss': 1.1021, 'grad_norm': 1.0253812074661255, 'learning_rate': 4.1071322966535487e-08, 'epoch': 0.94}
{'loss': 1.1172, 'grad_norm': 0.8432947397232056, 'learning_rate': 3.5009907323737826e-08, 'epoch': 0.95}
{'loss': 1.0797, 'grad_norm': 0.9297440052032471, 'learning_rate': 2.9429046383618042e-08, 'epoch': 0.95}
{'loss': 1.0857, 'grad_norm': 0.9429566264152527, 'learning_rate': 2.4329828146074096e-08, 'epoch': 0.96}
{'loss': 1.0972, 'grad_norm': 0.7999323606491089, 'learning_rate': 1.9713246713805588e-08, 'epoch': 0.96}
{'loss': 1.0845, 'grad_norm': 0.8622347712516785, 'learning_rate': 1.5580202098509078e-08, 'epoch': 0.97}
{'loss': 1.105, 'grad_norm': 0.8310239315032959, 'learning_rate': 1.193150004542204e-08, 'epoch': 0.97}
{'loss': 1.1189, 'grad_norm': 0.8627626299858093, 'learning_rate': 8.767851876239075e-09, 'epoch': 0.97}
{'loss': 1.0903, 'grad_norm': 0.9272258281707764, 'learning_rate': 6.089874350439507e-09, 'epoch': 0.98}
{'loss': 1.0856, 'grad_norm': 0.9001284837722778, 'learning_rate': 3.8980895450474455e-09, 'epoch': 0.98}
{'loss': 1.086, 'grad_norm': 0.905096173286438, 'learning_rate': 2.192924752854042e-09, 'epoch': 0.99}
{'loss': 1.0819, 'grad_norm': 0.8599942326545715, 'learning_rate': 9.747123991141193e-10, 'epoch': 0.99}
{'loss': 1.1018, 'grad_norm': 0.9751641154289246, 'learning_rate': 2.43689976739403e-10, 'epoch': 0.99}
{'loss': 1.0871, 'grad_norm': 0.8842898607254028, 'learning_rate': 0.0, 'epoch': 1.0}
Configuration saved in /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/checkpoint-237/config.json
Configuration saved in /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/checkpoint-237/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/checkpoint-237/model.safetensors.index.json.
2025-01-24 20:39:37,057 - INFO - Saving model to /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/checkpoint-237/pytorch_model_fsdp.bin
2025-01-24 20:40:19,078 - INFO - Model saved to /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/checkpoint-237/pytorch_model_fsdp.bin
2025-01-24 20:40:51,017 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/checkpoint-237/optimizer.bin
2025-01-24 20:42:21,963 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/checkpoint-237/optimizer.bin
Saving model checkpoint to /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/checkpoint-237
Configuration saved in /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/checkpoint-237/config.json
Configuration saved in /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/checkpoint-237/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/checkpoint-237/model.safetensors.index.json.
2025-01-24 20:44:19,553 - INFO - Saving model to /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/checkpoint-237/pytorch_model_fsdp.bin
2025-01-24 20:44:59,714 - INFO - Model saved to /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/checkpoint-237/pytorch_model_fsdp.bin
2025-01-24 20:45:26,566 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/checkpoint-237/optimizer.bin
2025-01-24 20:46:52,980 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/checkpoint-237/optimizer.bin


Training completed. Do not forget to share your model on huggingface.co/models =)


100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 237/237 [2:06:08<00:00, 31.94s/it]
{'train_runtime': 7568.4711, 'train_samples_per_second': 4.011, 'train_steps_per_second': 0.031, 'train_loss': 1.180038488363918, 'epoch': 1.0}
Saving model checkpoint to /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B
Configuration saved in /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/config.json
Configuration saved in /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_delta/training/model/sft/instruct-sft-train-llama3-lr5e-06-rt1-rr10-epochs1-blocksize2048-bs128-wd0.01-warmup0.05-knowledge_llama8b_cpt_lr5e_06_rt1_rr0.01_epochs1_blocksize2048_bs16_wd0.01_warmup0.05_Llama_3.1_8B/model.safetensors.index.json.
