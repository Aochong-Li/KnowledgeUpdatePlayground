                                                                                                           
{'loss': 1.6176, 'grad_norm': 61.183616638183594, 'learning_rate': 2.083333333333333e-08, 'epoch': 0.0}
{'loss': 1.5401, 'grad_norm': 80.4459228515625, 'learning_rate': 4.166666666666666e-08, 'epoch': 0.0}
{'loss': 1.5307, 'grad_norm': 1218.11083984375, 'learning_rate': 6.25e-08, 'epoch': 0.0}
{'loss': 1.6303, 'grad_norm': 101099.703125, 'learning_rate': 8.333333333333333e-08, 'epoch': 0.0}
{'loss': 1.6098, 'grad_norm': 80.26720428466797, 'learning_rate': 1.0416666666666667e-07, 'epoch': 0.01}
{'loss': 1.5757, 'grad_norm': 57.148521423339844, 'learning_rate': 1.25e-07, 'epoch': 0.01}
{'loss': 1.5664, 'grad_norm': 3955.829345703125, 'learning_rate': 1.4583333333333335e-07, 'epoch': 0.01}
{'loss': 1.5967, 'grad_norm': 8275.9296875, 'learning_rate': 1.6666666666666665e-07, 'epoch': 0.01}
{'loss': 1.5613, 'grad_norm': 20.938032150268555, 'learning_rate': 1.875e-07, 'epoch': 0.01}
{'loss': 1.5398, 'grad_norm': 29.188648223876953, 'learning_rate': 2.0833333333333333e-07, 'epoch': 0.01}
{'loss': 1.4366, 'grad_norm': 107.58228302001953, 'learning_rate': 2.2916666666666663e-07, 'epoch': 0.01}
{'loss': 1.5626, 'grad_norm': 24.533533096313477, 'learning_rate': 2.5e-07, 'epoch': 0.01}
{'loss': 1.54, 'grad_norm': 17.21515464782715, 'learning_rate': 2.708333333333333e-07, 'epoch': 0.01}
{'loss': 1.4464, 'grad_norm': 20.872516632080078, 'learning_rate': 2.916666666666667e-07, 'epoch': 0.01}
{'loss': 1.5557, 'grad_norm': 2916.67236328125, 'learning_rate': 3.1249999999999997e-07, 'epoch': 0.02}
{'loss': 1.4534, 'grad_norm': 24.582683563232422, 'learning_rate': 3.333333333333333e-07, 'epoch': 0.02}
{'loss': 1.4769, 'grad_norm': 8.766458511352539, 'learning_rate': 3.541666666666667e-07, 'epoch': 0.02}
{'loss': 1.4242, 'grad_norm': 6.073850631713867, 'learning_rate': 3.75e-07, 'epoch': 0.02}
{'loss': 1.4961, 'grad_norm': 10.567342758178711, 'learning_rate': 3.958333333333333e-07, 'epoch': 0.02}
{'loss': 1.4798, 'grad_norm': 3371.6015625, 'learning_rate': 4.1666666666666667e-07, 'epoch': 0.02}
{'loss': 1.424, 'grad_norm': 4.52786111831665, 'learning_rate': 4.375e-07, 'epoch': 0.02}
{'loss': 1.4235, 'grad_norm': 4.488122940063477, 'learning_rate': 4.5833333333333327e-07, 'epoch': 0.02}
{'loss': 1.4583, 'grad_norm': 53.8022575378418, 'learning_rate': 4.791666666666667e-07, 'epoch': 0.02}
{'loss': 1.4242, 'grad_norm': 51.48683166503906, 'learning_rate': 5e-07, 'epoch': 0.03}
{'loss': 1.475, 'grad_norm': 9484.556640625, 'learning_rate': 5.208333333333334e-07, 'epoch': 0.03}
{'loss': 1.3788, 'grad_norm': 3.506537437438965, 'learning_rate': 5.416666666666666e-07, 'epoch': 0.03}
{'loss': 1.338, 'grad_norm': 8.389181137084961, 'learning_rate': 5.625e-07, 'epoch': 0.03}
{'loss': 1.34, 'grad_norm': 4.383243083953857, 'learning_rate': 5.833333333333334e-07, 'epoch': 0.03}
{'loss': 1.3633, 'grad_norm': 8.487872123718262, 'learning_rate': 6.041666666666666e-07, 'epoch': 0.03}
{'loss': 1.4359, 'grad_norm': 5.2827301025390625, 'learning_rate': 6.249999999999999e-07, 'epoch': 0.03}
{'loss': 1.4038, 'grad_norm': 7.197448253631592, 'learning_rate': 6.458333333333333e-07, 'epoch': 0.03}
{'loss': 1.3687, 'grad_norm': 7.401561260223389, 'learning_rate': 6.666666666666666e-07, 'epoch': 0.03}
{'loss': 1.3226, 'grad_norm': 2.9877283573150635, 'learning_rate': 6.875e-07, 'epoch': 0.03}
{'loss': 1.3664, 'grad_norm': 4.665536403656006, 'learning_rate': 7.083333333333334e-07, 'epoch': 0.04}
{'loss': 1.2708, 'grad_norm': 2.255082607269287, 'learning_rate': 7.291666666666666e-07, 'epoch': 0.04}
{'loss': 1.4131, 'grad_norm': 2.7479100227355957, 'learning_rate': 7.5e-07, 'epoch': 0.04}
{'loss': 1.3241, 'grad_norm': 10220.0810546875, 'learning_rate': 7.708333333333333e-07, 'epoch': 0.04}
{'loss': 1.3795, 'grad_norm': 2.429934024810791, 'learning_rate': 7.916666666666666e-07, 'epoch': 0.04}
{'loss': 1.3968, 'grad_norm': 2.943347692489624, 'learning_rate': 8.125e-07, 'epoch': 0.04}
{'loss': 1.2542, 'grad_norm': 2.4330265522003174, 'learning_rate': 8.333333333333333e-07, 'epoch': 0.04}
{'loss': 1.3333, 'grad_norm': 3.4888720512390137, 'learning_rate': 8.541666666666666e-07, 'epoch': 0.04}
{'loss': 1.3775, 'grad_norm': 3.1892635822296143, 'learning_rate': 8.75e-07, 'epoch': 0.04}
{'loss': 1.3736, 'grad_norm': 2.4098901748657227, 'learning_rate': 8.958333333333334e-07, 'epoch': 0.05}
{'loss': 1.2315, 'grad_norm': 27.758026123046875, 'learning_rate': 9.166666666666665e-07, 'epoch': 0.05}
{'loss': 1.274, 'grad_norm': 1.948381781578064, 'learning_rate': 9.374999999999999e-07, 'epoch': 0.05}
{'loss': 1.3958, 'grad_norm': 3492.74462890625, 'learning_rate': 9.583333333333334e-07, 'epoch': 0.05}
{'loss': 1.1906, 'grad_norm': 3.1944973468780518, 'learning_rate': 9.791666666666667e-07, 'epoch': 0.05}
{'loss': 1.4045, 'grad_norm': 393.7474670410156, 'learning_rate': 1e-06, 'epoch': 0.05}
{'loss': 1.2322, 'grad_norm': 2.1009974479675293, 'learning_rate': 9.999969940418939e-07, 'epoch': 0.05}
{'loss': 1.2861, 'grad_norm': 12.45337963104248, 'learning_rate': 9.999879762037186e-07, 'epoch': 0.05}
{'loss': 1.2181, 'grad_norm': 1.9727740287780762, 'learning_rate': 9.999729465939036e-07, 'epoch': 0.05}
{'loss': 1.2768, 'grad_norm': 7.2501912117004395, 'learning_rate': 9.999519053931619e-07, 'epoch': 0.05}
{'loss': 1.324, 'grad_norm': 17.990148544311523, 'learning_rate': 9.999248528544893e-07, 'epoch': 0.06}
{'loss': 1.3653, 'grad_norm': 48.69011306762695, 'learning_rate': 9.998917893031615e-07, 'epoch': 0.06}
{'loss': 1.3693, 'grad_norm': 3.9073612689971924, 'learning_rate': 9.998527151367287e-07, 'epoch': 0.06}
{'loss': 1.2469, 'grad_norm': 4.2835798263549805, 'learning_rate': 9.99807630825012e-07, 'epoch': 0.06}
{'loss': 1.3031, 'grad_norm': 2.1610593795776367, 'learning_rate': 9.997565369100982e-07, 'epoch': 0.06}
{'loss': 1.2235, 'grad_norm': 2.1524202823638916, 'learning_rate': 9.996994340063314e-07, 'epoch': 0.06}
{'loss': 1.267, 'grad_norm': 2.0484259128570557, 'learning_rate': 9.996363228003078e-07, 'epoch': 0.06}
{'loss': 1.2802, 'grad_norm': 192.76585388183594, 'learning_rate': 9.995672040508656e-07, 'epoch': 0.06}
{'loss': 1.2687, 'grad_norm': 2.033658027648926, 'learning_rate': 9.99492078589077e-07, 'epoch': 0.06}
{'loss': 1.3702, 'grad_norm': 3.1548430919647217, 'learning_rate': 9.994109473182385e-07, 'epoch': 0.06}
{'loss': 1.274, 'grad_norm': 14.138175010681152, 'learning_rate': 9.993238112138582e-07, 'epoch': 0.07}
{'loss': 1.2895, 'grad_norm': 1.9335072040557861, 'learning_rate': 9.992306713236465e-07, 'epoch': 0.07}
{'loss': 1.2203, 'grad_norm': 1.9139281511306763, 'learning_rate': 9.991315287675018e-07, 'epoch': 0.07}
{'loss': 1.2782, 'grad_norm': 2.860447883605957, 'learning_rate': 9.990263847374975e-07, 'epoch': 0.07}
{'loss': 1.2447, 'grad_norm': 2.873195171356201, 'learning_rate': 9.989152404978676e-07, 'epoch': 0.07}
{'loss': 1.2729, 'grad_norm': 2.0578205585479736, 'learning_rate': 9.987980973849922e-07, 'epoch': 0.07}
{'loss': 1.2377, 'grad_norm': 2.4615180492401123, 'learning_rate': 9.986749568073802e-07, 'epoch': 0.07}
{'loss': 1.2724, 'grad_norm': 14.41378116607666, 'learning_rate': 9.985458202456534e-07, 'epoch': 0.07}
{'loss': 1.2528, 'grad_norm': 17.82695960998535, 'learning_rate': 9.98410689252528e-07, 'epoch': 0.07}
{'loss': 1.2362, 'grad_norm': 1.883933186531067, 'learning_rate': 9.982695654527964e-07, 'epoch': 0.08}
{'loss': 1.2763, 'grad_norm': 20.88673973083496, 'learning_rate': 9.981224505433078e-07, 'epoch': 0.08}
{'loss': 1.3042, 'grad_norm': 2.185098886489868, 'learning_rate': 9.97969346292947e-07, 'epoch': 0.08}
{'loss': 1.2766, 'grad_norm': 1.824027419090271, 'learning_rate': 9.978102545426139e-07, 'epoch': 0.08}
{'loss': 1.3098, 'grad_norm': 2.137197732925415, 'learning_rate': 9.976451772052012e-07, 'epoch': 0.08}
{'loss': 1.2231, 'grad_norm': 1.9156368970870972, 'learning_rate': 9.97474116265571e-07, 'epoch': 0.08}
{'loss': 1.1786, 'grad_norm': 3.0931828022003174, 'learning_rate': 9.972970737805312e-07, 'epoch': 0.08}
{'loss': 1.3015, 'grad_norm': 1.939860224723816, 'learning_rate': 9.97114051878811e-07, 'epoch': 0.08}
{'loss': 1.2735, 'grad_norm': 4.4384870529174805, 'learning_rate': 9.969250527610354e-07, 'epoch': 0.08}
{'loss': 1.2962, 'grad_norm': 2.0483312606811523, 'learning_rate': 9.967300786996979e-07, 'epoch': 0.08}
{'loss': 1.2285, 'grad_norm': 17.204833984375, 'learning_rate': 9.96529132039134e-07, 'epoch': 0.09}
{'loss': 1.2414, 'grad_norm': 1.8498262166976929, 'learning_rate': 9.963222151954928e-07, 'epoch': 0.09}
{'loss': 1.2185, 'grad_norm': 1.9110945463180542, 'learning_rate': 9.961093306567074e-07, 'epoch': 0.09}
{'loss': 1.2521, 'grad_norm': 2.1369917392730713, 'learning_rate': 9.958904809824662e-07, 'epoch': 0.09}
{'loss': 1.2448, 'grad_norm': 20.628992080688477, 'learning_rate': 9.956656688041807e-07, 'epoch': 0.09}
{'loss': 1.3326, 'grad_norm': 36.76146697998047, 'learning_rate': 9.95434896824955e-07, 'epoch': 0.09}
{'loss': 1.1988, 'grad_norm': 1.9516490697860718, 'learning_rate': 9.951981678195527e-07, 'epoch': 0.09}
{'loss': 1.2918, 'grad_norm': 2.597468614578247, 'learning_rate': 9.949554846343638e-07, 'epoch': 0.09}
{'loss': 1.239, 'grad_norm': 2.236591100692749, 'learning_rate': 9.9470685018737e-07, 'epoch': 0.09}
{'loss': 1.2659, 'grad_norm': 28.546581268310547, 'learning_rate': 9.944522674681106e-07, 'epoch': 0.1}
{'loss': 1.2092, 'grad_norm': 1.986008882522583, 'learning_rate': 9.941917395376452e-07, 'epoch': 0.1}
{'loss': 1.2589, 'grad_norm': 1.8679492473602295, 'learning_rate': 9.93925269528518e-07, 'epoch': 0.1}
{'loss': 1.1823, 'grad_norm': 13.620424270629883, 'learning_rate': 9.936528606447198e-07, 'epoch': 0.1}
{'loss': 1.2569, 'grad_norm': 46.50482940673828, 'learning_rate': 9.933745161616497e-07, 'epoch': 0.1}
{'loss': 1.2854, 'grad_norm': 26.758089065551758, 'learning_rate': 9.930902394260744e-07, 'epoch': 0.1}
{'loss': 1.1974, 'grad_norm': 1.8713058233261108, 'learning_rate': 9.928000338560905e-07, 'epoch': 0.1}
{'loss': 1.2893, 'grad_norm': 2.0757412910461426, 'learning_rate': 9.925039029410805e-07, 'epoch': 0.1}
{'loss': 1.1525, 'grad_norm': 2.360030174255371, 'learning_rate': 9.922018502416735e-07, 'epoch': 0.1}
{'loss': 1.2304, 'grad_norm': 1.8900638818740845, 'learning_rate': 9.918938793897e-07, 'epoch': 0.1}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-100/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-100/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-100/model.safetensors.index.json.
2024-11-20 20:39:29,665 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-100/pytorch_model_fsdp.bin
2024-11-20 20:40:10,700 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-100/pytorch_model_fsdp.bin
2024-11-20 20:40:39,523 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-100/optimizer.bin
2024-11-20 20:42:01,427 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-100/optimizer.bin
                                                                                                                    
{'loss': 1.3085, 'grad_norm': 1.9327986240386963, 'learning_rate': 9.915799940881503e-07, 'epoch': 0.11}
{'loss': 1.2389, 'grad_norm': 3.6419334411621094, 'learning_rate': 9.912601981111286e-07, 'epoch': 0.11}
{'loss': 1.197, 'grad_norm': 2.2229342460632324, 'learning_rate': 9.909344953038078e-07, 'epoch': 0.11}
{'loss': 1.1995, 'grad_norm': 2.333543300628662, 'learning_rate': 9.906028895823842e-07, 'epoch': 0.11}
{'loss': 1.2245, 'grad_norm': 1.9854227304458618, 'learning_rate': 9.902653849340294e-07, 'epoch': 0.11}
{'loss': 1.3089, 'grad_norm': 46.28780746459961, 'learning_rate': 9.899219854168428e-07, 'epoch': 0.11}
{'loss': 1.2883, 'grad_norm': 41.69646453857422, 'learning_rate': 9.895726951598025e-07, 'epoch': 0.11}
{'loss': 1.2498, 'grad_norm': 18.855615615844727, 'learning_rate': 9.89217518362716e-07, 'epoch': 0.11}
{'loss': 1.2201, 'grad_norm': 1.9263616800308228, 'learning_rate': 9.888564592961696e-07, 'epoch': 0.11}
{'loss': 1.1979, 'grad_norm': 15.708641052246094, 'learning_rate': 9.88489522301477e-07, 'epoch': 0.12}
{'loss': 1.231, 'grad_norm': 2.5418901443481445, 'learning_rate': 9.881167117906274e-07, 'epoch': 0.12}
{'loss': 1.0725, 'grad_norm': 1.8773852586746216, 'learning_rate': 9.877380322462316e-07, 'epoch': 0.12}
{'loss': 1.2417, 'grad_norm': 2.3278143405914307, 'learning_rate': 9.873534882214692e-07, 'epoch': 0.12}
{'loss': 1.2575, 'grad_norm': 24.941423416137695, 'learning_rate': 9.869630843400329e-07, 'epoch': 0.12}
{'loss': 1.1808, 'grad_norm': 3.148179769515991, 'learning_rate': 9.865668252960736e-07, 'epoch': 0.12}
{'loss': 1.2033, 'grad_norm': 2.154118061065674, 'learning_rate': 9.861647158541438e-07, 'epoch': 0.12}
{'loss': 1.2192, 'grad_norm': 1.9304982423782349, 'learning_rate': 9.857567608491397e-07, 'epoch': 0.12}
{'loss': 1.2453, 'grad_norm': 2.0050947666168213, 'learning_rate': 9.853429651862444e-07, 'epoch': 0.12}
{'loss': 1.2474, 'grad_norm': 2.206683874130249, 'learning_rate': 9.849233338408673e-07, 'epoch': 0.12}
{'loss': 1.1684, 'grad_norm': 1.9330612421035767, 'learning_rate': 9.844978718585855e-07, 'epoch': 0.13}
{'loss': 1.1404, 'grad_norm': 17.66755485534668, 'learning_rate': 9.840665843550823e-07, 'epoch': 0.13}
{'loss': 1.3028, 'grad_norm': 2.0477194786071777, 'learning_rate': 9.836294765160868e-07, 'epoch': 0.13}
{'loss': 1.2341, 'grad_norm': 1.8731271028518677, 'learning_rate': 9.831865535973103e-07, 'epoch': 0.13}
{'loss': 1.2275, 'grad_norm': 1.9381150007247925, 'learning_rate': 9.827378209243833e-07, 'epoch': 0.13}
{'loss': 1.3233, 'grad_norm': 56.96411895751953, 'learning_rate': 9.822832838927928e-07, 'epoch': 0.13}
{'loss': 1.216, 'grad_norm': 1.9645543098449707, 'learning_rate': 9.818229479678158e-07, 'epoch': 0.13}
{'loss': 1.1494, 'grad_norm': 2.1730990409851074, 'learning_rate': 9.81356818684454e-07, 'epoch': 0.13}
{'loss': 1.2396, 'grad_norm': 2.6077609062194824, 'learning_rate': 9.808849016473682e-07, 'epoch': 0.13}
{'loss': 1.2791, 'grad_norm': 1.9043903350830078, 'learning_rate': 9.804072025308095e-07, 'epoch': 0.14}
{'loss': 1.2271, 'grad_norm': 2.6682727336883545, 'learning_rate': 9.79923727078552e-07, 'epoch': 0.14}
{'loss': 1.1439, 'grad_norm': 1.949896216392517, 'learning_rate': 9.794344811038237e-07, 'epoch': 0.14}
{'loss': 1.2941, 'grad_norm': 18.187639236450195, 'learning_rate': 9.789394704892364e-07, 'epoch': 0.14}
{'loss': 1.2349, 'grad_norm': 21.575183868408203, 'learning_rate': 9.784387011867143e-07, 'epoch': 0.14}
{'loss': 1.234, 'grad_norm': 17.169883728027344, 'learning_rate': 9.779321792174238e-07, 'epoch': 0.14}
{'loss': 1.189, 'grad_norm': 2.1627893447875977, 'learning_rate': 9.774199106717003e-07, 'epoch': 0.14}
{'loss': 1.1829, 'grad_norm': 2.093057870864868, 'learning_rate': 9.769019017089748e-07, 'epoch': 0.14}
{'loss': 1.3063, 'grad_norm': 1.931368350982666, 'learning_rate': 9.763781585577003e-07, 'epoch': 0.14}
{'loss': 1.2285, 'grad_norm': 3.334707021713257, 'learning_rate': 9.758486875152766e-07, 'epoch': 0.14}
{'loss': 1.1858, 'grad_norm': 1.9739563465118408, 'learning_rate': 9.75313494947975e-07, 'epoch': 0.15}
{'loss': 1.2056, 'grad_norm': 13.363139152526855, 'learning_rate': 9.747725872908607e-07, 'epoch': 0.15}
{'loss': 1.2189, 'grad_norm': 1.9552717208862305, 'learning_rate': 9.742259710477176e-07, 'epoch': 0.15}
{'loss': 1.2, 'grad_norm': 1.8053640127182007, 'learning_rate': 9.736736527909672e-07, 'epoch': 0.15}
{'loss': 1.3053, 'grad_norm': 5.253208637237549, 'learning_rate': 9.731156391615918e-07, 'epoch': 0.15}
{'loss': 1.1732, 'grad_norm': 3.4943666458129883, 'learning_rate': 9.725519368690538e-07, 'epoch': 0.15}
{'loss': 1.2788, 'grad_norm': 3.159083127975464, 'learning_rate': 9.71982552691215e-07, 'epoch': 0.15}
{'loss': 1.1499, 'grad_norm': 12.293161392211914, 'learning_rate': 9.714074934742555e-07, 'epoch': 0.15}
{'loss': 1.2673, 'grad_norm': 2.071594476699829, 'learning_rate': 9.70826766132591e-07, 'epoch': 0.15}
{'loss': 1.2083, 'grad_norm': 2.1672351360321045, 'learning_rate': 9.702403776487894e-07, 'epoch': 0.16}
{'loss': 1.2791, 'grad_norm': 2.2299020290374756, 'learning_rate': 9.696483350734878e-07, 'epoch': 0.16}
{'loss': 1.1794, 'grad_norm': 1.9952127933502197, 'learning_rate': 9.690506455253071e-07, 'epoch': 0.16}
{'loss': 1.1905, 'grad_norm': 1.9896798133850098, 'learning_rate': 9.684473161907658e-07, 'epoch': 0.16}
{'loss': 1.2276, 'grad_norm': 1.8970316648483276, 'learning_rate': 9.678383543241952e-07, 'epoch': 0.16}
{'loss': 1.2572, 'grad_norm': 1.9879992008209229, 'learning_rate': 9.672237672476504e-07, 'epoch': 0.16}
{'loss': 1.2497, 'grad_norm': 1.9646251201629639, 'learning_rate': 9.666035623508237e-07, 'epoch': 0.16}
{'loss': 1.2502, 'grad_norm': 71.88265228271484, 'learning_rate': 9.659777470909544e-07, 'epoch': 0.16}
{'loss': 1.2007, 'grad_norm': 1.9600402116775513, 'learning_rate': 9.653463289927408e-07, 'epoch': 0.16}
{'loss': 1.2017, 'grad_norm': 11.019631385803223, 'learning_rate': 9.647093156482481e-07, 'epoch': 0.16}
{'loss': 1.1898, 'grad_norm': 28.308961868286133, 'learning_rate': 9.640667147168181e-07, 'epoch': 0.17}
{'loss': 1.2017, 'grad_norm': 1.9126567840576172, 'learning_rate': 9.634185339249764e-07, 'epoch': 0.17}
{'loss': 1.2106, 'grad_norm': 2.042750835418701, 'learning_rate': 9.627647810663406e-07, 'epoch': 0.17}
{'loss': 1.242, 'grad_norm': 5.205435752868652, 'learning_rate': 9.621054640015253e-07, 'epoch': 0.17}
{'loss': 1.1998, 'grad_norm': 1.9448100328445435, 'learning_rate': 9.614405906580485e-07, 'epoch': 0.17}
{'loss': 1.2588, 'grad_norm': 2.124058961868286, 'learning_rate': 9.60770169030236e-07, 'epoch': 0.17}
{'loss': 1.1405, 'grad_norm': 2.7792177200317383, 'learning_rate': 9.600942071791248e-07, 'epoch': 0.17}
{'loss': 1.17, 'grad_norm': 2.3966221809387207, 'learning_rate': 9.59412713232367e-07, 'epoch': 0.17}
{'loss': 1.1601, 'grad_norm': 8.958186149597168, 'learning_rate': 9.587256953841315e-07, 'epoch': 0.17}
{'loss': 1.2, 'grad_norm': 2.9284303188323975, 'learning_rate': 9.580331618950062e-07, 'epoch': 0.17}
{'loss': 1.1276, 'grad_norm': 2.2651054859161377, 'learning_rate': 9.573351210918973e-07, 'epoch': 0.18}
{'loss': 1.2252, 'grad_norm': 2.039095401763916, 'learning_rate': 9.56631581367931e-07, 'epoch': 0.18}
{'loss': 1.2545, 'grad_norm': 1.9672317504882812, 'learning_rate': 9.559225511823503e-07, 'epoch': 0.18}
{'loss': 1.2324, 'grad_norm': 121.7065658569336, 'learning_rate': 9.552080390604157e-07, 'epoch': 0.18}
{'loss': 1.2573, 'grad_norm': 1.9548399448394775, 'learning_rate': 9.544880535933014e-07, 'epoch': 0.18}
{'loss': 1.2338, 'grad_norm': 825.5751342773438, 'learning_rate': 9.537626034379917e-07, 'epoch': 0.18}
{'loss': 1.2332, 'grad_norm': 2.050053596496582, 'learning_rate': 9.53031697317178e-07, 'epoch': 0.18}
{'loss': 1.159, 'grad_norm': 1.9029169082641602, 'learning_rate': 9.522953440191527e-07, 'epoch': 0.18}
{'loss': 1.2906, 'grad_norm': 1096.5972900390625, 'learning_rate': 9.515535523977046e-07, 'epoch': 0.18}
{'loss': 1.2102, 'grad_norm': 1.9232341051101685, 'learning_rate': 9.508063313720118e-07, 'epoch': 0.19}
{'loss': 1.1522, 'grad_norm': 1.8681696653366089, 'learning_rate': 9.500536899265348e-07, 'epoch': 0.19}
{'loss': 1.2736, 'grad_norm': 2.500753879547119, 'learning_rate': 9.492956371109082e-07, 'epoch': 0.19}
{'loss': 1.1435, 'grad_norm': 1.7777788639068604, 'learning_rate': 9.48532182039832e-07, 'epoch': 0.19}
{'loss': 1.1541, 'grad_norm': 2.9399571418762207, 'learning_rate': 9.477633338929621e-07, 'epoch': 0.19}
{'loss': 1.2355, 'grad_norm': 1.9250868558883667, 'learning_rate': 9.469891019147995e-07, 'epoch': 0.19}
{'loss': 1.0616, 'grad_norm': 1.8314107656478882, 'learning_rate': 9.462094954145799e-07, 'epoch': 0.19}
{'loss': 1.1508, 'grad_norm': 1.7846521139144897, 'learning_rate': 9.454245237661615e-07, 'epoch': 0.19}
{'loss': 1.2734, 'grad_norm': 2.9509899616241455, 'learning_rate': 9.446341964079116e-07, 'epoch': 0.19}
{'loss': 1.2333, 'grad_norm': 2.095217227935791, 'learning_rate': 9.438385228425938e-07, 'epoch': 0.19}
{'loss': 1.2164, 'grad_norm': 2.0835111141204834, 'learning_rate': 9.43037512637254e-07, 'epoch': 0.2}
{'loss': 1.2508, 'grad_norm': 2.5011487007141113, 'learning_rate': 9.422311754231045e-07, 'epoch': 0.2}
{'loss': 1.0763, 'grad_norm': 2.534522771835327, 'learning_rate': 9.41419520895409e-07, 'epoch': 0.2}
{'loss': 1.1954, 'grad_norm': 1.8530303239822388, 'learning_rate': 9.406025588133653e-07, 'epoch': 0.2}
{'loss': 1.2274, 'grad_norm': 1.8258280754089355, 'learning_rate': 9.397802989999887e-07, 'epoch': 0.2}
{'loss': 1.1316, 'grad_norm': 1.8476698398590088, 'learning_rate': 9.389527513419934e-07, 'epoch': 0.2}
{'loss': 1.2133, 'grad_norm': 1.941741943359375, 'learning_rate': 9.381199257896737e-07, 'epoch': 0.2}
{'loss': 1.199, 'grad_norm': 1.9021503925323486, 'learning_rate': 9.372818323567846e-07, 'epoch': 0.2}
{'loss': 1.1702, 'grad_norm': 2.2329328060150146, 'learning_rate': 9.364384811204211e-07, 'epoch': 0.2}
{'loss': 1.1728, 'grad_norm': 53.769344329833984, 'learning_rate': 9.35589882220897e-07, 'epoch': 0.21}
{'loss': 1.2937, 'grad_norm': 1.9541162252426147, 'learning_rate': 9.347360458616232e-07, 'epoch': 0.21}
{'loss': 1.1385, 'grad_norm': 1.9881432056427002, 'learning_rate': 9.338769823089852e-07, 'epoch': 0.21}
{'loss': 1.2316, 'grad_norm': 1.854174256324768, 'learning_rate': 9.330127018922193e-07, 'epoch': 0.21}
{'loss': 1.1791, 'grad_norm': 1.8849599361419678, 'learning_rate': 9.321432150032882e-07, 'epoch': 0.21}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-200/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-200/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-200/model.safetensors.index.json.
2024-11-20 20:57:18,829 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-200/pytorch_model_fsdp.bin
2024-11-20 20:58:03,435 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-200/pytorch_model_fsdp.bin
2024-11-20 20:58:35,768 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-200/optimizer.bin
2024-11-20 20:59:59,159 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-200/optimizer.bin
                                                                                                                    
{'loss': 1.1198, 'grad_norm': 1.9181931018829346, 'learning_rate': 9.312685320967563e-07, 'epoch': 0.21}
{'loss': 1.225, 'grad_norm': 57.9568977355957, 'learning_rate': 9.303886636896649e-07, 'epoch': 0.21}
{'loss': 1.2156, 'grad_norm': 2.665597677230835, 'learning_rate': 9.295036203614037e-07, 'epoch': 0.21}
{'loss': 1.2892, 'grad_norm': 2.2105205059051514, 'learning_rate': 9.286134127535859e-07, 'epoch': 0.21}
{'loss': 1.0576, 'grad_norm': 3.6964752674102783, 'learning_rate': 9.277180515699181e-07, 'epoch': 0.21}
{'loss': 1.1741, 'grad_norm': 1.8558303117752075, 'learning_rate': 9.268175475760733e-07, 'epoch': 0.22}
{'loss': 1.1335, 'grad_norm': 1.8866561651229858, 'learning_rate': 9.259119115995608e-07, 'epoch': 0.22}
{'loss': 1.2449, 'grad_norm': 2.029688596725464, 'learning_rate': 9.250011545295957e-07, 'epoch': 0.22}
{'loss': 1.2083, 'grad_norm': 1.8855643272399902, 'learning_rate': 9.240852873169685e-07, 'epoch': 0.22}
{'loss': 1.2847, 'grad_norm': 1.8682528734207153, 'learning_rate': 9.231643209739126e-07, 'epoch': 0.22}
{'loss': 1.1637, 'grad_norm': 15.501876831054688, 'learning_rate': 9.222382665739736e-07, 'epoch': 0.22}
{'loss': 1.2759, 'grad_norm': 28.479421615600586, 'learning_rate': 9.213071352518742e-07, 'epoch': 0.22}
{'loss': 1.2199, 'grad_norm': 3.3714799880981445, 'learning_rate': 9.203709382033813e-07, 'epoch': 0.22}
{'loss': 1.2565, 'grad_norm': 1.9197510480880737, 'learning_rate': 9.194296866851712e-07, 'epoch': 0.22}
{'loss': 1.1872, 'grad_norm': 1.7654938697814941, 'learning_rate': 9.184833920146948e-07, 'epoch': 0.23}
{'loss': 1.136, 'grad_norm': 1.8130970001220703, 'learning_rate': 9.175320655700405e-07, 'epoch': 0.23}
{'loss': 1.1658, 'grad_norm': 1.9971946477890015, 'learning_rate': 9.165757187897978e-07, 'epoch': 0.23}
{'loss': 1.1889, 'grad_norm': 2.0297203063964844, 'learning_rate': 9.156143631729204e-07, 'epoch': 0.23}
{'loss': 1.1559, 'grad_norm': 1.842839002609253, 'learning_rate': 9.14648010278587e-07, 'epoch': 0.23}
{'loss': 1.1497, 'grad_norm': 40.378334045410156, 'learning_rate': 9.13676671726063e-07, 'epoch': 0.23}
{'loss': 1.1715, 'grad_norm': 1.795223355293274, 'learning_rate': 9.127003591945604e-07, 'epoch': 0.23}
{'loss': 1.2238, 'grad_norm': 1.9713952541351318, 'learning_rate': 9.117190844230971e-07, 'epoch': 0.23}
{'loss': 1.1584, 'grad_norm': 1.7707595825195312, 'learning_rate': 9.107328592103569e-07, 'epoch': 0.23}
{'loss': 1.1394, 'grad_norm': 50.146514892578125, 'learning_rate': 9.097416954145465e-07, 'epoch': 0.23}
{'loss': 1.0945, 'grad_norm': 16.92220687866211, 'learning_rate': 9.087456049532529e-07, 'epoch': 0.24}
{'loss': 1.2781, 'grad_norm': 2.015127420425415, 'learning_rate': 9.077445998033014e-07, 'epoch': 0.24}
{'loss': 1.2232, 'grad_norm': 1.7522380352020264, 'learning_rate': 9.0673869200061e-07, 'epoch': 0.24}
{'loss': 1.1403, 'grad_norm': 2.063342809677124, 'learning_rate': 9.057278936400452e-07, 'epoch': 0.24}
{'loss': 1.1901, 'grad_norm': 14.106630325317383, 'learning_rate': 9.047122168752774e-07, 'epoch': 0.24}
{'loss': 1.1356, 'grad_norm': 1.8126683235168457, 'learning_rate': 9.03691673918634e-07, 'epoch': 0.24}
{'loss': 1.2337, 'grad_norm': 25.023191452026367, 'learning_rate': 9.026662770409523e-07, 'epoch': 0.24}
{'loss': 1.1859, 'grad_norm': 1.867779016494751, 'learning_rate': 9.016360385714323e-07, 'epoch': 0.24}
{'loss': 1.2359, 'grad_norm': 39.08196258544922, 'learning_rate': 9.006009708974891e-07, 'epoch': 0.24}
{'loss': 1.1908, 'grad_norm': 1.773501992225647, 'learning_rate': 8.995610864646029e-07, 'epoch': 0.25}
{'loss': 1.1742, 'grad_norm': 20.100379943847656, 'learning_rate': 8.985163977761695e-07, 'epoch': 0.25}
{'loss': 1.086, 'grad_norm': 2.060666084289551, 'learning_rate': 8.97466917393351e-07, 'epoch': 0.25}
{'loss': 1.094, 'grad_norm': 1.7504181861877441, 'learning_rate': 8.964126579349236e-07, 'epoch': 0.25}
{'loss': 1.2191, 'grad_norm': 19.706321716308594, 'learning_rate': 8.953536320771262e-07, 'epoch': 0.25}
{'loss': 1.2021, 'grad_norm': 1.990256428718567, 'learning_rate': 8.942898525535084e-07, 'epoch': 0.25}
{'loss': 1.1938, 'grad_norm': 1.7968801259994507, 'learning_rate': 8.932213321547768e-07, 'epoch': 0.25}
{'loss': 1.2164, 'grad_norm': 13.375374794006348, 'learning_rate': 8.921480837286417e-07, 'epoch': 0.25}
{'loss': 1.1869, 'grad_norm': 2.2278029918670654, 'learning_rate': 8.910701201796624e-07, 'epoch': 0.25}
{'loss': 1.1859, 'grad_norm': 1.9750334024429321, 'learning_rate': 8.89987454469092e-07, 'epoch': 0.25}
{'loss': 1.2348, 'grad_norm': 1.840463638305664, 'learning_rate': 8.889000996147213e-07, 'epoch': 0.26}
{'loss': 1.1215, 'grad_norm': 1.703554391860962, 'learning_rate': 8.87808068690723e-07, 'epoch': 0.26}
{'loss': 1.2248, 'grad_norm': 1.990095853805542, 'learning_rate': 8.867113748274939e-07, 'epoch': 0.26}
{'loss': 1.1539, 'grad_norm': 1.8435325622558594, 'learning_rate': 8.856100312114974e-07, 'epoch': 0.26}
{'loss': 1.0843, 'grad_norm': 1.992253065109253, 'learning_rate': 8.845040510851044e-07, 'epoch': 0.26}
{'loss': 1.2092, 'grad_norm': 5.23705530166626, 'learning_rate': 8.833934477464347e-07, 'epoch': 0.26}
{'loss': 1.1618, 'grad_norm': 2.522132635116577, 'learning_rate': 8.822782345491967e-07, 'epoch': 0.26}
{'loss': 1.1052, 'grad_norm': 1.7677797079086304, 'learning_rate': 8.81158424902527e-07, 'epoch': 0.26}
{'loss': 1.1494, 'grad_norm': 1.7026269435882568, 'learning_rate': 8.800340322708291e-07, 'epoch': 0.26}
{'loss': 1.1914, 'grad_norm': 1.7208033800125122, 'learning_rate': 8.789050701736117e-07, 'epoch': 0.27}
{'loss': 1.2552, 'grad_norm': 1.829323410987854, 'learning_rate': 8.777715521853257e-07, 'epoch': 0.27}
{'loss': 1.2398, 'grad_norm': 1.7928781509399414, 'learning_rate': 8.766334919352016e-07, 'epoch': 0.27}
{'loss': 1.1418, 'grad_norm': 1.7383489608764648, 'learning_rate': 8.75490903107085e-07, 'epoch': 0.27}
{'loss': 1.2046, 'grad_norm': 1.7689272165298462, 'learning_rate': 8.743437994392728e-07, 'epoch': 0.27}
{'loss': 1.1019, 'grad_norm': 1.747105598449707, 'learning_rate': 8.731921947243468e-07, 'epoch': 0.27}
{'loss': 1.212, 'grad_norm': 1.7897948026657104, 'learning_rate': 8.720361028090094e-07, 'epoch': 0.27}
{'loss': 1.1112, 'grad_norm': 1.6726316213607788, 'learning_rate': 8.708755375939161e-07, 'epoch': 0.27}
{'loss': 1.1558, 'grad_norm': 2.199936628341675, 'learning_rate': 8.697105130335084e-07, 'epoch': 0.27}
{'loss': 1.1365, 'grad_norm': 12.877079010009766, 'learning_rate': 8.685410431358464e-07, 'epoch': 0.27}
{'loss': 1.149, 'grad_norm': 1.661149501800537, 'learning_rate': 8.673671419624404e-07, 'epoch': 0.28}
{'loss': 1.2041, 'grad_norm': 50.706111907958984, 'learning_rate': 8.661888236280813e-07, 'epoch': 0.28}
{'loss': 1.1098, 'grad_norm': 5.584342002868652, 'learning_rate': 8.65006102300671e-07, 'epoch': 0.28}
{'loss': 1.0987, 'grad_norm': 2.001011371612549, 'learning_rate': 8.638189922010528e-07, 'epoch': 0.28}
{'loss': 1.2427, 'grad_norm': 2.0710232257843018, 'learning_rate': 8.626275076028396e-07, 'epoch': 0.28}
{'loss': 1.1686, 'grad_norm': 2.561925172805786, 'learning_rate': 8.614316628322427e-07, 'epoch': 0.28}
{'loss': 1.1219, 'grad_norm': 1.7001206874847412, 'learning_rate': 8.602314722678988e-07, 'epoch': 0.28}
{'loss': 1.0612, 'grad_norm': 1.8976848125457764, 'learning_rate': 8.590269503406984e-07, 'epoch': 0.28}
{'loss': 1.212, 'grad_norm': 1.7088747024536133, 'learning_rate': 8.578181115336114e-07, 'epoch': 0.28}
{'loss': 1.2069, 'grad_norm': 2.3329355716705322, 'learning_rate': 8.56604970381513e-07, 'epoch': 0.29}
{'loss': 1.141, 'grad_norm': 1.7512046098709106, 'learning_rate': 8.553875414710088e-07, 'epoch': 0.29}
{'loss': 1.2157, 'grad_norm': 1.6285489797592163, 'learning_rate': 8.541658394402605e-07, 'epoch': 0.29}
{'loss': 1.1695, 'grad_norm': 1.8125746250152588, 'learning_rate': 8.52939878978808e-07, 'epoch': 0.29}
{'loss': 1.1882, 'grad_norm': 1.6645433902740479, 'learning_rate': 8.517096748273951e-07, 'epoch': 0.29}
{'loss': 1.072, 'grad_norm': 1.6706299781799316, 'learning_rate': 8.504752417777898e-07, 'epoch': 0.29}
{'loss': 1.0854, 'grad_norm': 1.7348315715789795, 'learning_rate': 8.492365946726087e-07, 'epoch': 0.29}
{'loss': 1.0997, 'grad_norm': 1.6779356002807617, 'learning_rate': 8.479937484051368e-07, 'epoch': 0.29}
{'loss': 1.1605, 'grad_norm': 1.7238966226577759, 'learning_rate': 8.467467179191492e-07, 'epoch': 0.29}
{'loss': 1.1805, 'grad_norm': 1.6710797548294067, 'learning_rate': 8.454955182087317e-07, 'epoch': 0.29}
{'loss': 1.1255, 'grad_norm': 1.681581974029541, 'learning_rate': 8.442401643181e-07, 'epoch': 0.3}
{'loss': 1.157, 'grad_norm': 1.722630262374878, 'learning_rate': 8.429806713414188e-07, 'epoch': 0.3}
{'loss': 1.2337, 'grad_norm': 1.6359047889709473, 'learning_rate': 8.417170544226203e-07, 'epoch': 0.3}
{'loss': 1.1398, 'grad_norm': 1.5391019582748413, 'learning_rate': 8.404493287552231e-07, 'epoch': 0.3}
{'loss': 1.2285, 'grad_norm': 54.36772918701172, 'learning_rate': 8.391775095821481e-07, 'epoch': 0.3}
{'loss': 1.2028, 'grad_norm': 52.49239730834961, 'learning_rate': 8.379016121955355e-07, 'epoch': 0.3}
{'loss': 1.0919, 'grad_norm': 1.726389765739441, 'learning_rate': 8.36621651936562e-07, 'epoch': 0.3}
{'loss': 1.2185, 'grad_norm': 1.7811356782913208, 'learning_rate': 8.353376441952553e-07, 'epoch': 0.3}
{'loss': 1.1479, 'grad_norm': 1.7313910722732544, 'learning_rate': 8.340496044103094e-07, 'epoch': 0.3}
{'loss': 1.2121, 'grad_norm': 1.6851372718811035, 'learning_rate': 8.327575480688985e-07, 'epoch': 0.3}
{'loss': 1.1802, 'grad_norm': 1.6734528541564941, 'learning_rate': 8.314614907064914e-07, 'epoch': 0.31}
{'loss': 1.1544, 'grad_norm': 2.011518955230713, 'learning_rate': 8.301614479066652e-07, 'epoch': 0.31}
{'loss': 1.1135, 'grad_norm': 1.6940195560455322, 'learning_rate': 8.288574353009164e-07, 'epoch': 0.31}
{'loss': 1.1344, 'grad_norm': 2.715968132019043, 'learning_rate': 8.275494685684739e-07, 'epoch': 0.31}
{'loss': 1.0873, 'grad_norm': 1.9121686220169067, 'learning_rate': 8.262375634361107e-07, 'epoch': 0.31}
{'loss': 1.115, 'grad_norm': 1.7847224473953247, 'learning_rate': 8.249217356779543e-07, 'epoch': 0.31}
{'loss': 1.1434, 'grad_norm': 1.684032917022705, 'learning_rate': 8.236020011152968e-07, 'epoch': 0.31}
{'loss': 1.1083, 'grad_norm': 1.7663918733596802, 'learning_rate': 8.222783756164061e-07, 'epoch': 0.31}
{'loss': 1.1256, 'grad_norm': 1.7828898429870605, 'learning_rate': 8.209508750963328e-07, 'epoch': 0.31}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-300/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-300/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-300/model.safetensors.index.json.
2024-11-20 21:15:18,560 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-300/pytorch_model_fsdp.bin
2024-11-20 21:15:58,843 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-300/pytorch_model_fsdp.bin
2024-11-20 21:16:30,739 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-300/optimizer.bin
2024-11-20 21:17:54,359 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-300/optimizer.bin
                                                                                                                    
{'loss': 1.1127, 'grad_norm': 1.8199262619018555, 'learning_rate': 8.196195155167209e-07, 'epoch': 0.32}
{'loss': 1.1844, 'grad_norm': 1.5416475534439087, 'learning_rate': 8.18284312885615e-07, 'epoch': 0.32}
{'loss': 1.1154, 'grad_norm': 1.6877628564834595, 'learning_rate': 8.169452832572674e-07, 'epoch': 0.32}
{'loss': 1.1995, 'grad_norm': 9.29405403137207, 'learning_rate': 8.156024427319463e-07, 'epoch': 0.32}
{'loss': 1.1523, 'grad_norm': 1.7276030778884888, 'learning_rate': 8.142558074557412e-07, 'epoch': 0.32}
{'loss': 1.1929, 'grad_norm': 1.660731315612793, 'learning_rate': 8.129053936203687e-07, 'epoch': 0.32}
{'loss': 1.138, 'grad_norm': 2.0323903560638428, 'learning_rate': 8.115512174629788e-07, 'epoch': 0.32}
{'loss': 1.124, 'grad_norm': 1.5999994277954102, 'learning_rate': 8.101932952659585e-07, 'epoch': 0.32}
{'loss': 1.1375, 'grad_norm': 1.8421825170516968, 'learning_rate': 8.088316433567368e-07, 'epoch': 0.32}
{'loss': 1.1511, 'grad_norm': 1.7728275060653687, 'learning_rate': 8.074662781075879e-07, 'epoch': 0.32}
{'loss': 1.0694, 'grad_norm': 1.5972743034362793, 'learning_rate': 8.060972159354349e-07, 'epoch': 0.33}
{'loss': 1.0826, 'grad_norm': 1.7283339500427246, 'learning_rate': 8.047244733016521e-07, 'epoch': 0.33}
{'loss': 1.095, 'grad_norm': 1.6155022382736206, 'learning_rate': 8.033480667118666e-07, 'epoch': 0.33}
{'loss': 1.1327, 'grad_norm': 407.7620849609375, 'learning_rate': 8.019680127157606e-07, 'epoch': 0.33}
{'loss': 1.1536, 'grad_norm': 1.637313961982727, 'learning_rate': 8.005843279068723e-07, 'epoch': 0.33}
{'loss': 1.1442, 'grad_norm': 2.0021393299102783, 'learning_rate': 7.991970289223959e-07, 'epoch': 0.33}
{'loss': 1.1692, 'grad_norm': 54.402313232421875, 'learning_rate': 7.978061324429819e-07, 'epoch': 0.33}
{'loss': 1.2153, 'grad_norm': 1.5932788848876953, 'learning_rate': 7.964116551925364e-07, 'epoch': 0.33}
{'loss': 1.2037, 'grad_norm': 1.6092449426651, 'learning_rate': 7.950136139380202e-07, 'epoch': 0.33}
{'loss': 1.0893, 'grad_norm': 1.5036381483078003, 'learning_rate': 7.936120254892471e-07, 'epoch': 0.34}
{'loss': 1.2078, 'grad_norm': 2.7418928146362305, 'learning_rate': 7.922069066986819e-07, 'epoch': 0.34}
{'loss': 1.107, 'grad_norm': 1.5956441164016724, 'learning_rate': 7.907982744612372e-07, 'epoch': 0.34}
{'loss': 1.1834, 'grad_norm': 1.578832983970642, 'learning_rate': 7.893861457140711e-07, 'epoch': 0.34}
{'loss': 1.2116, 'grad_norm': 267.48126220703125, 'learning_rate': 7.87970537436383e-07, 'epoch': 0.34}
{'loss': 1.1584, 'grad_norm': 1.5230334997177124, 'learning_rate': 7.865514666492095e-07, 'epoch': 0.34}
{'loss': 1.1364, 'grad_norm': 1.5493000745773315, 'learning_rate': 7.851289504152201e-07, 'epoch': 0.34}
{'loss': 1.1703, 'grad_norm': 2.0592689514160156, 'learning_rate': 7.837030058385117e-07, 'epoch': 0.34}
{'loss': 1.1351, 'grad_norm': 2.1458022594451904, 'learning_rate': 7.822736500644027e-07, 'epoch': 0.34}
{'loss': 1.0613, 'grad_norm': 1.505102515220642, 'learning_rate': 7.808409002792276e-07, 'epoch': 0.34}
{'loss': 1.1628, 'grad_norm': 1.774350643157959, 'learning_rate': 7.794047737101297e-07, 'epoch': 0.35}
{'loss': 1.1254, 'grad_norm': 1.628707766532898, 'learning_rate': 7.779652876248541e-07, 'epoch': 0.35}
{'loss': 1.1359, 'grad_norm': 48.4421501159668, 'learning_rate': 7.765224593315402e-07, 'epoch': 0.35}
{'loss': 1.0823, 'grad_norm': 1.538303017616272, 'learning_rate': 7.750763061785137e-07, 'epoch': 0.35}
{'loss': 1.2122, 'grad_norm': 1.5258123874664307, 'learning_rate': 7.73626845554078e-07, 'epoch': 0.35}
{'loss': 1.1557, 'grad_norm': 1.832542896270752, 'learning_rate': 7.721740948863043e-07, 'epoch': 0.35}
{'loss': 1.1456, 'grad_norm': 1.660297155380249, 'learning_rate': 7.707180716428237e-07, 'epoch': 0.35}
{'loss': 1.1471, 'grad_norm': 26.599681854248047, 'learning_rate': 7.692587933306152e-07, 'epoch': 0.35}
{'loss': 1.1218, 'grad_norm': 1.666887879371643, 'learning_rate': 7.67796277495797e-07, 'epoch': 0.35}
{'loss': 1.2034, 'grad_norm': 2.1395678520202637, 'learning_rate': 7.663305417234145e-07, 'epoch': 0.36}
{'loss': 1.1549, 'grad_norm': 26.385326385498047, 'learning_rate': 7.648616036372286e-07, 'epoch': 0.36}
{'loss': 1.2616, 'grad_norm': 1.6049965620040894, 'learning_rate': 7.63389480899505e-07, 'epoch': 0.36}
{'loss': 1.1428, 'grad_norm': 1.6804078817367554, 'learning_rate': 7.619141912108006e-07, 'epoch': 0.36}
{'loss': 1.1501, 'grad_norm': 1.636976718902588, 'learning_rate': 7.604357523097516e-07, 'epoch': 0.36}
{'loss': 1.1611, 'grad_norm': 1.5839775800704956, 'learning_rate': 7.589541819728596e-07, 'epoch': 0.36}
{'loss': 1.1678, 'grad_norm': 1.5549702644348145, 'learning_rate': 7.574694980142779e-07, 'epoch': 0.36}
{'loss': 1.111, 'grad_norm': 72.37506866455078, 'learning_rate': 7.559817182855976e-07, 'epoch': 0.36}
{'loss': 1.0496, 'grad_norm': 2.1871113777160645, 'learning_rate': 7.544908606756331e-07, 'epoch': 0.36}
{'loss': 1.1854, 'grad_norm': 1.5917061567306519, 'learning_rate': 7.529969431102062e-07, 'epoch': 0.36}
{'loss': 1.2015, 'grad_norm': 20.86306381225586, 'learning_rate': 7.514999835519317e-07, 'epoch': 0.37}
{'loss': 1.1299, 'grad_norm': 27.156455993652344, 'learning_rate': 7.5e-07, 'epoch': 0.37}
{'loss': 1.1635, 'grad_norm': 2.342621088027954, 'learning_rate': 7.484970104899623e-07, 'epoch': 0.37}
{'loss': 1.1817, 'grad_norm': 1.5436075925827026, 'learning_rate': 7.469910330935125e-07, 'epoch': 0.37}
{'loss': 1.2005, 'grad_norm': 1.5141897201538086, 'learning_rate': 7.454820859182705e-07, 'epoch': 0.37}
{'loss': 1.0912, 'grad_norm': 1.530724048614502, 'learning_rate': 7.439701871075641e-07, 'epoch': 0.37}
{'loss': 1.1114, 'grad_norm': 1.399925708770752, 'learning_rate': 7.424553548402115e-07, 'epoch': 0.37}
{'loss': 1.1962, 'grad_norm': 9.752642631530762, 'learning_rate': 7.409376073303019e-07, 'epoch': 0.37}
{'loss': 1.131, 'grad_norm': 1.5070390701293945, 'learning_rate': 7.394169628269771e-07, 'epoch': 0.37}
{'loss': 1.1286, 'grad_norm': 3.426478862762451, 'learning_rate': 7.378934396142114e-07, 'epoch': 0.38}
{'loss': 1.148, 'grad_norm': 1.5309816598892212, 'learning_rate': 7.363670560105933e-07, 'epoch': 0.38}
{'loss': 1.1448, 'grad_norm': 2.1869397163391113, 'learning_rate': 7.348378303691029e-07, 'epoch': 0.38}
{'loss': 1.1677, 'grad_norm': 1.5701544284820557, 'learning_rate': 7.333057810768934e-07, 'epoch': 0.38}
{'loss': 1.1767, 'grad_norm': 1.3863794803619385, 'learning_rate': 7.317709265550684e-07, 'epoch': 0.38}
{'loss': 1.22, 'grad_norm': 1.5552873611450195, 'learning_rate': 7.302332852584619e-07, 'epoch': 0.38}
{'loss': 1.1958, 'grad_norm': 7.7836127281188965, 'learning_rate': 7.286928756754148e-07, 'epoch': 0.38}
{'loss': 1.0847, 'grad_norm': 1.514641523361206, 'learning_rate': 7.271497163275539e-07, 'epoch': 0.38}
{'loss': 1.0667, 'grad_norm': 1.4172495603561401, 'learning_rate': 7.256038257695687e-07, 'epoch': 0.38}
{'loss': 1.1807, 'grad_norm': 1.5665405988693237, 'learning_rate': 7.240552225889881e-07, 'epoch': 0.38}
{'loss': 1.1027, 'grad_norm': 1.4291670322418213, 'learning_rate': 7.225039254059573e-07, 'epoch': 0.39}
{'loss': 1.2669, 'grad_norm': 12.96060848236084, 'learning_rate': 7.209499528730138e-07, 'epoch': 0.39}
{'loss': 1.1363, 'grad_norm': 1.541703701019287, 'learning_rate': 7.193933236748626e-07, 'epoch': 0.39}
{'loss': 1.1715, 'grad_norm': 1.4425655603408813, 'learning_rate': 7.178340565281526e-07, 'epoch': 0.39}
{'loss': 1.234, 'grad_norm': 1.488405704498291, 'learning_rate': 7.162721701812505e-07, 'epoch': 0.39}
{'loss': 1.0659, 'grad_norm': 1.377758264541626, 'learning_rate': 7.147076834140162e-07, 'epoch': 0.39}
{'loss': 1.1588, 'grad_norm': 24.352842330932617, 'learning_rate': 7.131406150375762e-07, 'epoch': 0.39}
{'loss': 1.1376, 'grad_norm': 1.3848539590835571, 'learning_rate': 7.115709838940982e-07, 'epoch': 0.39}
{'loss': 1.1582, 'grad_norm': 1.478493571281433, 'learning_rate': 7.099988088565641e-07, 'epoch': 0.39}
{'loss': 1.2011, 'grad_norm': 11.474112510681152, 'learning_rate': 7.08424108828543e-07, 'epoch': 0.4}
{'loss': 1.0769, 'grad_norm': 1.4959782361984253, 'learning_rate': 7.068469027439641e-07, 'epoch': 0.4}
{'loss': 1.1067, 'grad_norm': 1.6124191284179688, 'learning_rate': 7.05267209566889e-07, 'epoch': 0.4}
{'loss': 1.1206, 'grad_norm': 1.4706480503082275, 'learning_rate': 7.036850482912839e-07, 'epoch': 0.4}
{'loss': 1.1819, 'grad_norm': 18.743661880493164, 'learning_rate': 7.021004379407908e-07, 'epoch': 0.4}
{'loss': 1.138, 'grad_norm': 3.2514731884002686, 'learning_rate': 7.005133975684992e-07, 'epoch': 0.4}
{'loss': 1.1223, 'grad_norm': 1.4612171649932861, 'learning_rate': 6.989239462567161e-07, 'epoch': 0.4}
{'loss': 1.1005, 'grad_norm': 1.4314035177230835, 'learning_rate': 6.973321031167382e-07, 'epoch': 0.4}
{'loss': 1.1631, 'grad_norm': 1.5839519500732422, 'learning_rate': 6.957378872886204e-07, 'epoch': 0.4}
{'loss': 1.1351, 'grad_norm': 7.182189464569092, 'learning_rate': 6.941413179409468e-07, 'epoch': 0.4}
{'loss': 1.1141, 'grad_norm': 1.5480494499206543, 'learning_rate': 6.925424142705997e-07, 'epoch': 0.41}
{'loss': 1.1792, 'grad_norm': 1.5530399084091187, 'learning_rate': 6.909411955025288e-07, 'epoch': 0.41}
{'loss': 1.0901, 'grad_norm': 1.5417001247406006, 'learning_rate': 6.893376808895201e-07, 'epoch': 0.41}
{'loss': 1.1596, 'grad_norm': 1.4208134412765503, 'learning_rate': 6.87731889711965e-07, 'epoch': 0.41}
{'loss': 1.1372, 'grad_norm': 1.6770552396774292, 'learning_rate': 6.861238412776271e-07, 'epoch': 0.41}
{'loss': 1.1518, 'grad_norm': 43.49208068847656, 'learning_rate': 6.845135549214117e-07, 'epoch': 0.41}
{'loss': 1.1779, 'grad_norm': 1.4595714807510376, 'learning_rate': 6.829010500051318e-07, 'epoch': 0.41}
{'loss': 1.1567, 'grad_norm': 1.6176743507385254, 'learning_rate': 6.812863459172764e-07, 'epoch': 0.41}
{'loss': 1.1326, 'grad_norm': 1.4548485279083252, 'learning_rate': 6.796694620727768e-07, 'epoch': 0.41}
{'loss': 1.1693, 'grad_norm': 74.11897277832031, 'learning_rate': 6.780504179127734e-07, 'epoch': 0.41}
{'loss': 1.1293, 'grad_norm': 1.4724730253219604, 'learning_rate': 6.76429232904382e-07, 'epoch': 0.42}
{'loss': 1.1499, 'grad_norm': 1.5015405416488647, 'learning_rate': 6.748059265404596e-07, 'epoch': 0.42}
{'loss': 1.1651, 'grad_norm': 2.029247999191284, 'learning_rate': 6.731805183393695e-07, 'epoch': 0.42}
{'loss': 1.1537, 'grad_norm': 17.2177677154541, 'learning_rate': 6.715530278447479e-07, 'epoch': 0.42}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-400/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-400/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-400/model.safetensors.index.json.
2024-11-20 21:33:09,577 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-400/pytorch_model_fsdp.bin
2024-11-20 21:33:58,271 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-400/pytorch_model_fsdp.bin
2024-11-20 21:34:31,030 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-400/optimizer.bin
2024-11-20 21:35:56,842 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-400/optimizer.bin
                                                                                                                    
{'loss': 1.1199, 'grad_norm': 1.3744667768478394, 'learning_rate': 6.699234746252674e-07, 'epoch': 0.42}
{'loss': 1.0545, 'grad_norm': 8.916720390319824, 'learning_rate': 6.682918782744031e-07, 'epoch': 0.42}
{'loss': 1.1878, 'grad_norm': 1.4467031955718994, 'learning_rate': 6.66658258410196e-07, 'epoch': 0.42}
{'loss': 1.0959, 'grad_norm': 1.5068680047988892, 'learning_rate': 6.650226346750178e-07, 'epoch': 0.42}
{'loss': 1.1416, 'grad_norm': 25.8471736907959, 'learning_rate': 6.633850267353339e-07, 'epoch': 0.42}
{'loss': 1.0776, 'grad_norm': 40.52952194213867, 'learning_rate': 6.61745454281468e-07, 'epoch': 0.43}
{'loss': 1.1204, 'grad_norm': 1.3824965953826904, 'learning_rate': 6.601039370273644e-07, 'epoch': 0.43}
{'loss': 1.1746, 'grad_norm': 1.8417547941207886, 'learning_rate': 6.584604947103513e-07, 'epoch': 0.43}
{'loss': 1.1054, 'grad_norm': 1.4320777654647827, 'learning_rate': 6.568151470909041e-07, 'epoch': 0.43}
{'loss': 1.1917, 'grad_norm': 1.5917689800262451, 'learning_rate': 6.551679139524067e-07, 'epoch': 0.43}
{'loss': 1.2103, 'grad_norm': 1.6771355867385864, 'learning_rate': 6.535188151009143e-07, 'epoch': 0.43}
{'loss': 1.1907, 'grad_norm': 16.151988983154297, 'learning_rate': 6.51867870364915e-07, 'epoch': 0.43}
{'loss': 1.1624, 'grad_norm': 1.447052001953125, 'learning_rate': 6.50215099595092e-07, 'epoch': 0.43}
{'loss': 1.1708, 'grad_norm': 1.3610090017318726, 'learning_rate': 6.485605226640836e-07, 'epoch': 0.43}
{'loss': 1.1102, 'grad_norm': 1.4372830390930176, 'learning_rate': 6.46904159466246e-07, 'epoch': 0.43}
{'loss': 1.1441, 'grad_norm': 1.4495834112167358, 'learning_rate': 6.452460299174125e-07, 'epoch': 0.44}
{'loss': 1.1285, 'grad_norm': 1.5470033884048462, 'learning_rate': 6.43586153954655e-07, 'epoch': 0.44}
{'loss': 1.0214, 'grad_norm': 1.354887843132019, 'learning_rate': 6.41924551536044e-07, 'epoch': 0.44}
{'loss': 1.0888, 'grad_norm': 3.8384640216827393, 'learning_rate': 6.402612426404082e-07, 'epoch': 0.44}
{'loss': 1.1053, 'grad_norm': 22.590059280395508, 'learning_rate': 6.385962472670953e-07, 'epoch': 0.44}
{'loss': 1.1064, 'grad_norm': 1.7972631454467773, 'learning_rate': 6.369295854357306e-07, 'epoch': 0.44}
{'loss': 1.1888, 'grad_norm': 1.4639739990234375, 'learning_rate': 6.352612771859768e-07, 'epoch': 0.44}
{'loss': 1.1262, 'grad_norm': 1.385329246520996, 'learning_rate': 6.335913425772925e-07, 'epoch': 0.44}
{'loss': 1.1303, 'grad_norm': 1.3339985609054565, 'learning_rate': 6.319198016886918e-07, 'epoch': 0.44}
{'loss': 1.1585, 'grad_norm': 1.3814282417297363, 'learning_rate': 6.302466746185021e-07, 'epoch': 0.45}
{'loss': 1.0809, 'grad_norm': 1.3790655136108398, 'learning_rate': 6.28571981484123e-07, 'epoch': 0.45}
{'loss': 1.1079, 'grad_norm': 1.6215113401412964, 'learning_rate': 6.26895742421784e-07, 'epoch': 0.45}
{'loss': 1.0942, 'grad_norm': 1.5398883819580078, 'learning_rate': 6.252179775863029e-07, 'epoch': 0.45}
{'loss': 1.1672, 'grad_norm': 5.473605632781982, 'learning_rate': 6.235387071508426e-07, 'epoch': 0.45}
{'loss': 1.2034, 'grad_norm': 1.4423625469207764, 'learning_rate': 6.218579513066697e-07, 'epoch': 0.45}
{'loss': 1.1512, 'grad_norm': 28.659818649291992, 'learning_rate': 6.201757302629107e-07, 'epoch': 0.45}
{'loss': 1.0922, 'grad_norm': 4.92756462097168, 'learning_rate': 6.184920642463094e-07, 'epoch': 0.45}
{'loss': 1.2744, 'grad_norm': 1.5467396974563599, 'learning_rate': 6.16806973500984e-07, 'epoch': 0.45}
{'loss': 1.133, 'grad_norm': 2.674706220626831, 'learning_rate': 6.151204782881835e-07, 'epoch': 0.45}
{'loss': 1.2093, 'grad_norm': 17.353496551513672, 'learning_rate': 6.134325988860433e-07, 'epoch': 0.46}
{'loss': 1.1056, 'grad_norm': 1.3573036193847656, 'learning_rate': 6.117433555893425e-07, 'epoch': 0.46}
{'loss': 1.0834, 'grad_norm': 1.595353364944458, 'learning_rate': 6.100527687092598e-07, 'epoch': 0.46}
{'loss': 1.2187, 'grad_norm': 1.4296189546585083, 'learning_rate': 6.083608585731283e-07, 'epoch': 0.46}
{'loss': 1.1844, 'grad_norm': 1.4287772178649902, 'learning_rate': 6.066676455241918e-07, 'epoch': 0.46}
{'loss': 1.1162, 'grad_norm': 1.5376744270324707, 'learning_rate': 6.049731499213605e-07, 'epoch': 0.46}
{'loss': 1.1257, 'grad_norm': 1.4217748641967773, 'learning_rate': 6.032773921389654e-07, 'epoch': 0.46}
{'loss': 1.1731, 'grad_norm': 1.4080018997192383, 'learning_rate': 6.015803925665141e-07, 'epoch': 0.46}
{'loss': 1.1189, 'grad_norm': 1.4907420873641968, 'learning_rate': 5.998821716084449e-07, 'epoch': 0.46}
{'loss': 1.1305, 'grad_norm': 9.548298835754395, 'learning_rate': 5.981827496838822e-07, 'epoch': 0.47}
{'loss': 1.1205, 'grad_norm': 1.502623200416565, 'learning_rate': 5.964821472263903e-07, 'epoch': 0.47}
{'loss': 1.1628, 'grad_norm': 4.626531600952148, 'learning_rate': 5.94780384683728e-07, 'epoch': 0.47}
{'loss': 1.1156, 'grad_norm': 1.3289704322814941, 'learning_rate': 5.930774825176033e-07, 'epoch': 0.47}
{'loss': 1.157, 'grad_norm': 2.4199142456054688, 'learning_rate': 5.913734612034264e-07, 'epoch': 0.47}
{'loss': 1.1626, 'grad_norm': 48.335243225097656, 'learning_rate': 5.89668341230064e-07, 'epoch': 0.47}
{'loss': 1.1808, 'grad_norm': 1.3693265914916992, 'learning_rate': 5.879621430995927e-07, 'epoch': 0.47}
{'loss': 1.1958, 'grad_norm': 1.3406356573104858, 'learning_rate': 5.862548873270532e-07, 'epoch': 0.47}
{'loss': 1.1328, 'grad_norm': 13.688773155212402, 'learning_rate': 5.845465944402027e-07, 'epoch': 0.47}
{'loss': 1.1334, 'grad_norm': 7.263991832733154, 'learning_rate': 5.828372849792685e-07, 'epoch': 0.47}
{'loss': 1.0564, 'grad_norm': 1.6233851909637451, 'learning_rate': 5.811269794967014e-07, 'epoch': 0.48}
{'loss': 1.1912, 'grad_norm': 9.274961471557617, 'learning_rate': 5.794156985569275e-07, 'epoch': 0.48}
{'loss': 1.0413, 'grad_norm': 6.5031023025512695, 'learning_rate': 5.777034627361025e-07, 'epoch': 0.48}
{'loss': 1.144, 'grad_norm': 1.393624186515808, 'learning_rate': 5.759902926218626e-07, 'epoch': 0.48}
{'loss': 1.181, 'grad_norm': 1.7534098625183105, 'learning_rate': 5.742762088130785e-07, 'epoch': 0.48}
{'loss': 1.151, 'grad_norm': 41.70022201538086, 'learning_rate': 5.725612319196064e-07, 'epoch': 0.48}
{'loss': 1.1046, 'grad_norm': 1.4049317836761475, 'learning_rate': 5.708453825620412e-07, 'epoch': 0.48}
{'loss': 1.1886, 'grad_norm': 1.3700594902038574, 'learning_rate': 5.69128681371468e-07, 'epoch': 0.48}
{'loss': 1.1369, 'grad_norm': 1.5011147260665894, 'learning_rate': 5.674111489892144e-07, 'epoch': 0.48}
{'loss': 1.1558, 'grad_norm': 1.6627678871154785, 'learning_rate': 5.656928060666018e-07, 'epoch': 0.49}
{'loss': 1.1602, 'grad_norm': 1.3701379299163818, 'learning_rate': 5.639736732646976e-07, 'epoch': 0.49}
{'loss': 1.1458, 'grad_norm': 38.95670700073242, 'learning_rate': 5.622537712540664e-07, 'epoch': 0.49}
{'loss': 1.054, 'grad_norm': 1.4159984588623047, 'learning_rate': 5.605331207145219e-07, 'epoch': 0.49}
{'loss': 1.1608, 'grad_norm': 1.4000214338302612, 'learning_rate': 5.588117423348778e-07, 'epoch': 0.49}
{'loss': 1.1304, 'grad_norm': 1.4077035188674927, 'learning_rate': 5.570896568126993e-07, 'epoch': 0.49}
{'loss': 1.0841, 'grad_norm': 1.6771154403686523, 'learning_rate': 5.55366884854054e-07, 'epoch': 0.49}
{'loss': 1.0927, 'grad_norm': 1.881168246269226, 'learning_rate': 5.536434471732634e-07, 'epoch': 0.49}
{'loss': 1.1743, 'grad_norm': 1.648743987083435, 'learning_rate': 5.519193644926534e-07, 'epoch': 0.49}
{'loss': 1.1268, 'grad_norm': 1.4172098636627197, 'learning_rate': 5.50194657542305e-07, 'epoch': 0.49}
{'loss': 1.1013, 'grad_norm': 1.830310344696045, 'learning_rate': 5.484693470598059e-07, 'epoch': 0.5}
{'loss': 1.1385, 'grad_norm': 11.142313003540039, 'learning_rate': 5.4674345379e-07, 'epoch': 0.5}
{'loss': 1.156, 'grad_norm': 1.6851638555526733, 'learning_rate': 5.450169984847389e-07, 'epoch': 0.5}
{'loss': 1.1302, 'grad_norm': 1.3099589347839355, 'learning_rate': 5.432900019026315e-07, 'epoch': 0.5}
{'loss': 1.0802, 'grad_norm': 3.291304349899292, 'learning_rate': 5.415624848087959e-07, 'epoch': 0.5}
{'loss': 1.168, 'grad_norm': 1.3847334384918213, 'learning_rate': 5.398344679746076e-07, 'epoch': 0.5}
{'loss': 1.0709, 'grad_norm': 5.484591007232666, 'learning_rate': 5.381059721774516e-07, 'epoch': 0.5}
{'loss': 1.1274, 'grad_norm': 1.3369228839874268, 'learning_rate': 5.36377018200472e-07, 'epoch': 0.5}
{'loss': 1.1695, 'grad_norm': 28.249496459960938, 'learning_rate': 5.346476268323213e-07, 'epoch': 0.5}
{'loss': 1.048, 'grad_norm': 1.3003126382827759, 'learning_rate': 5.329178188669117e-07, 'epoch': 0.51}
{'loss': 1.0981, 'grad_norm': 1.3585299253463745, 'learning_rate': 5.311876151031641e-07, 'epoch': 0.51}
{'loss': 1.0967, 'grad_norm': 1.411350965499878, 'learning_rate': 5.294570363447589e-07, 'epoch': 0.51}
{'loss': 1.0917, 'grad_norm': 1.4701515436172485, 'learning_rate': 5.277261033998851e-07, 'epoch': 0.51}
{'loss': 1.1199, 'grad_norm': 1.6310125589370728, 'learning_rate': 5.259948370809902e-07, 'epoch': 0.51}
{'loss': 1.2149, 'grad_norm': 1.461661458015442, 'learning_rate': 5.242632582045303e-07, 'epoch': 0.51}
{'loss': 1.1864, 'grad_norm': 25.855314254760742, 'learning_rate': 5.225313875907197e-07, 'epoch': 0.51}
{'loss': 1.0466, 'grad_norm': 3.113830327987671, 'learning_rate': 5.207992460632804e-07, 'epoch': 0.51}
{'loss': 1.1634, 'grad_norm': 1.5329408645629883, 'learning_rate': 5.190668544491918e-07, 'epoch': 0.51}
{'loss': 1.2147, 'grad_norm': 2.449875831604004, 'learning_rate': 5.173342335784406e-07, 'epoch': 0.51}
{'loss': 1.1059, 'grad_norm': 1.3935770988464355, 'learning_rate': 5.156014042837695e-07, 'epoch': 0.52}
{'loss': 1.17, 'grad_norm': 2.301426649093628, 'learning_rate': 5.138683874004278e-07, 'epoch': 0.52}
{'loss': 1.1678, 'grad_norm': 1.4721479415893555, 'learning_rate': 5.121352037659201e-07, 'epoch': 0.52}
{'loss': 1.0317, 'grad_norm': 1.4422729015350342, 'learning_rate': 5.104018742197556e-07, 'epoch': 0.52}
{'loss': 1.2016, 'grad_norm': 1.4927343130111694, 'learning_rate': 5.086684196031988e-07, 'epoch': 0.52}
{'loss': 1.1864, 'grad_norm': 1.5558053255081177, 'learning_rate': 5.069348607590172e-07, 'epoch': 0.52}
{'loss': 1.1494, 'grad_norm': 10.967684745788574, 'learning_rate': 5.052012185312321e-07, 'epoch': 0.52}
{'loss': 1.1411, 'grad_norm': 4.893093109130859, 'learning_rate': 5.034675137648669e-07, 'epoch': 0.52}
{'loss': 1.1695, 'grad_norm': 15.428766250610352, 'learning_rate': 5.017337673056971e-07, 'epoch': 0.52}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-500/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-500/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-500/model.safetensors.index.json.
2024-11-20 21:51:04,196 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-500/pytorch_model_fsdp.bin
2024-11-20 21:51:45,829 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-500/pytorch_model_fsdp.bin
2024-11-20 21:52:18,611 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-500/optimizer.bin
2024-11-20 21:53:43,464 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-500/optimizer.bin
                                                                                                                    
{'loss': 1.0364, 'grad_norm': 1.516115665435791, 'learning_rate': 5e-07, 'epoch': 0.52}
{'loss': 1.1723, 'grad_norm': 11.057374954223633, 'learning_rate': 4.982662326943028e-07, 'epoch': 0.53}
{'loss': 1.1, 'grad_norm': 6.6721272468566895, 'learning_rate': 4.965324862351332e-07, 'epoch': 0.53}
{'loss': 1.058, 'grad_norm': 1.3450831174850464, 'learning_rate': 4.947987814687679e-07, 'epoch': 0.53}
{'loss': 1.1745, 'grad_norm': 1.4904611110687256, 'learning_rate': 4.930651392409827e-07, 'epoch': 0.53}
{'loss': 1.0763, 'grad_norm': 1.4413005113601685, 'learning_rate': 4.913315803968012e-07, 'epoch': 0.53}
{'loss': 1.1541, 'grad_norm': 1.4978669881820679, 'learning_rate': 4.895981257802443e-07, 'epoch': 0.53}
{'loss': 1.0962, 'grad_norm': 1.3394646644592285, 'learning_rate': 4.8786479623408e-07, 'epoch': 0.53}
{'loss': 1.1568, 'grad_norm': 1.4392427206039429, 'learning_rate': 4.861316125995722e-07, 'epoch': 0.53}
{'loss': 1.1597, 'grad_norm': 1.570725679397583, 'learning_rate': 4.843985957162304e-07, 'epoch': 0.53}
{'loss': 1.1503, 'grad_norm': 1.4602713584899902, 'learning_rate': 4.826657664215596e-07, 'epoch': 0.54}
{'loss': 1.0353, 'grad_norm': 5.415545463562012, 'learning_rate': 4.809331455508082e-07, 'epoch': 0.54}
{'loss': 1.1695, 'grad_norm': 1.4150691032409668, 'learning_rate': 4.792007539367197e-07, 'epoch': 0.54}
{'loss': 1.0947, 'grad_norm': 1.2915130853652954, 'learning_rate': 4.774686124092804e-07, 'epoch': 0.54}
{'loss': 1.0865, 'grad_norm': 1.3271253108978271, 'learning_rate': 4.757367417954698e-07, 'epoch': 0.54}
{'loss': 1.1769, 'grad_norm': 54.16844940185547, 'learning_rate': 4.7400516291900986e-07, 'epoch': 0.54}
{'loss': 1.1799, 'grad_norm': 1.3421978950500488, 'learning_rate': 4.72273896600115e-07, 'epoch': 0.54}
{'loss': 1.1093, 'grad_norm': 1.6531431674957275, 'learning_rate': 4.7054296365524106e-07, 'epoch': 0.54}
{'loss': 1.135, 'grad_norm': 2.974660873413086, 'learning_rate': 4.688123848968359e-07, 'epoch': 0.54}
{'loss': 1.168, 'grad_norm': 1.429071068763733, 'learning_rate': 4.6708218113308835e-07, 'epoch': 0.54}
{'loss': 1.1328, 'grad_norm': 1.5815629959106445, 'learning_rate': 4.6535237316767875e-07, 'epoch': 0.55}
{'loss': 1.1832, 'grad_norm': 27.69139289855957, 'learning_rate': 4.636229817995281e-07, 'epoch': 0.55}
{'loss': 1.1002, 'grad_norm': 1.3911582231521606, 'learning_rate': 4.618940278225483e-07, 'epoch': 0.55}
{'loss': 1.1676, 'grad_norm': 1.7236969470977783, 'learning_rate': 4.601655320253924e-07, 'epoch': 0.55}
{'loss': 1.1394, 'grad_norm': 1.416633129119873, 'learning_rate': 4.5843751519120414e-07, 'epoch': 0.55}
{'loss': 1.1665, 'grad_norm': 24.102306365966797, 'learning_rate': 4.5670999809736835e-07, 'epoch': 0.55}
{'loss': 1.0195, 'grad_norm': 1.4277074337005615, 'learning_rate': 4.5498300151526115e-07, 'epoch': 0.55}
{'loss': 1.134, 'grad_norm': 1.5679383277893066, 'learning_rate': 4.532565462099999e-07, 'epoch': 0.55}
{'loss': 1.1518, 'grad_norm': 1.389256477355957, 'learning_rate': 4.51530652940194e-07, 'epoch': 0.55}
{'loss': 1.1132, 'grad_norm': 1.402680516242981, 'learning_rate': 4.498053424576948e-07, 'epoch': 0.56}
{'loss': 1.0323, 'grad_norm': 1.3307454586029053, 'learning_rate': 4.4808063550734664e-07, 'epoch': 0.56}
{'loss': 1.0843, 'grad_norm': 1.2979408502578735, 'learning_rate': 4.4635655282673663e-07, 'epoch': 0.56}
{'loss': 1.066, 'grad_norm': 1.6329948902130127, 'learning_rate': 4.4463311514594606e-07, 'epoch': 0.56}
{'loss': 1.1496, 'grad_norm': 1.4027957916259766, 'learning_rate': 4.4291034318730086e-07, 'epoch': 0.56}
{'loss': 1.1207, 'grad_norm': 1.3666517734527588, 'learning_rate': 4.411882576651223e-07, 'epoch': 0.56}
{'loss': 1.1332, 'grad_norm': 1.533339500427246, 'learning_rate': 4.394668792854782e-07, 'epoch': 0.56}
{'loss': 1.19, 'grad_norm': 1.39608895778656, 'learning_rate': 4.377462287459337e-07, 'epoch': 0.56}
{'loss': 1.1363, 'grad_norm': 1.3780581951141357, 'learning_rate': 4.360263267353025e-07, 'epoch': 0.56}
{'loss': 1.0694, 'grad_norm': 1.3360991477966309, 'learning_rate': 4.343071939333982e-07, 'epoch': 0.56}
{'loss': 1.1559, 'grad_norm': 1.3703727722167969, 'learning_rate': 4.325888510107856e-07, 'epoch': 0.57}
{'loss': 1.1412, 'grad_norm': 2.14247465133667, 'learning_rate': 4.308713186285319e-07, 'epoch': 0.57}
{'loss': 1.0542, 'grad_norm': 1.4794543981552124, 'learning_rate': 4.291546174379588e-07, 'epoch': 0.57}
{'loss': 1.2233, 'grad_norm': 8.698673248291016, 'learning_rate': 4.274387680803936e-07, 'epoch': 0.57}
{'loss': 1.1537, 'grad_norm': 1.3026714324951172, 'learning_rate': 4.2572379118692155e-07, 'epoch': 0.57}
{'loss': 1.1657, 'grad_norm': 1.4270826578140259, 'learning_rate': 4.2400970737813736e-07, 'epoch': 0.57}
{'loss': 1.0307, 'grad_norm': 1.4425268173217773, 'learning_rate': 4.2229653726389756e-07, 'epoch': 0.57}
{'loss': 1.123, 'grad_norm': 1.5480986833572388, 'learning_rate': 4.2058430144307236e-07, 'epoch': 0.57}
{'loss': 1.1903, 'grad_norm': 1.561018705368042, 'learning_rate': 4.188730205032986e-07, 'epoch': 0.57}
{'loss': 1.1023, 'grad_norm': 2.175682306289673, 'learning_rate': 4.1716271502073136e-07, 'epoch': 0.58}
{'loss': 1.2657, 'grad_norm': 41.104454040527344, 'learning_rate': 4.1545340555979724e-07, 'epoch': 0.58}
{'loss': 1.0878, 'grad_norm': 1.4311467409133911, 'learning_rate': 4.1374511267294694e-07, 'epoch': 0.58}
{'loss': 1.0884, 'grad_norm': 1.6178243160247803, 'learning_rate': 4.120378569004074e-07, 'epoch': 0.58}
{'loss': 1.0483, 'grad_norm': 1.3159114122390747, 'learning_rate': 4.103316587699362e-07, 'epoch': 0.58}
{'loss': 1.0886, 'grad_norm': 1.4081343412399292, 'learning_rate': 4.0862653879657373e-07, 'epoch': 0.58}
{'loss': 1.1593, 'grad_norm': 1.4233416318893433, 'learning_rate': 4.0692251748239677e-07, 'epoch': 0.58}
{'loss': 1.0313, 'grad_norm': 1.2503461837768555, 'learning_rate': 4.0521961531627205e-07, 'epoch': 0.58}
{'loss': 1.1702, 'grad_norm': 1.3705779314041138, 'learning_rate': 4.0351785277360985e-07, 'epoch': 0.58}
{'loss': 1.0486, 'grad_norm': 1.5410586595535278, 'learning_rate': 4.018172503161179e-07, 'epoch': 0.58}
{'loss': 1.1974, 'grad_norm': 1.468803882598877, 'learning_rate': 4.0011782839155514e-07, 'epoch': 0.59}
{'loss': 1.1412, 'grad_norm': 1.4015662670135498, 'learning_rate': 3.9841960743348594e-07, 'epoch': 0.59}
{'loss': 1.1331, 'grad_norm': 1.3823550939559937, 'learning_rate': 3.967226078610346e-07, 'epoch': 0.59}
{'loss': 1.0964, 'grad_norm': 1.43900465965271, 'learning_rate': 3.9502685007863956e-07, 'epoch': 0.59}
{'loss': 1.122, 'grad_norm': 1.356499195098877, 'learning_rate': 3.933323544758082e-07, 'epoch': 0.59}
{'loss': 1.1626, 'grad_norm': 1.410245418548584, 'learning_rate': 3.9163914142687177e-07, 'epoch': 0.59}
{'loss': 1.0553, 'grad_norm': 1.3763972520828247, 'learning_rate': 3.899472312907401e-07, 'epoch': 0.59}
{'loss': 1.0962, 'grad_norm': 14.464447975158691, 'learning_rate': 3.882566444106573e-07, 'epoch': 0.59}
{'loss': 1.136, 'grad_norm': 1.366440773010254, 'learning_rate': 3.8656740111395663e-07, 'epoch': 0.59}
{'loss': 1.1146, 'grad_norm': 1.4665783643722534, 'learning_rate': 3.8487952171181647e-07, 'epoch': 0.6}
{'loss': 1.082, 'grad_norm': 1.4132106304168701, 'learning_rate': 3.831930264990158e-07, 'epoch': 0.6}
{'loss': 1.1592, 'grad_norm': 1.3330578804016113, 'learning_rate': 3.815079357536906e-07, 'epoch': 0.6}
{'loss': 1.0191, 'grad_norm': 1.3981828689575195, 'learning_rate': 3.7982426973708944e-07, 'epoch': 0.6}
{'loss': 1.1621, 'grad_norm': 1.3749717473983765, 'learning_rate': 3.7814204869333044e-07, 'epoch': 0.6}
{'loss': 1.2035, 'grad_norm': 1.3463151454925537, 'learning_rate': 3.764612928491575e-07, 'epoch': 0.6}
{'loss': 1.0306, 'grad_norm': 1.4423623085021973, 'learning_rate': 3.747820224136973e-07, 'epoch': 0.6}
{'loss': 1.1454, 'grad_norm': 1.4737800359725952, 'learning_rate': 3.7310425757821604e-07, 'epoch': 0.6}
{'loss': 1.089, 'grad_norm': 1.39396333694458, 'learning_rate': 3.7142801851587705e-07, 'epoch': 0.6}
{'loss': 1.3079, 'grad_norm': 1.3667720556259155, 'learning_rate': 3.6975332538149795e-07, 'epoch': 0.6}
{'loss': 1.106, 'grad_norm': 1.3773928880691528, 'learning_rate': 3.680801983113082e-07, 'epoch': 0.61}
{'loss': 1.0706, 'grad_norm': 14.957832336425781, 'learning_rate': 3.664086574227075e-07, 'epoch': 0.61}
{'loss': 1.0648, 'grad_norm': 1.2999933958053589, 'learning_rate': 3.647387228140232e-07, 'epoch': 0.61}
{'loss': 1.1818, 'grad_norm': 1.498058795928955, 'learning_rate': 3.630704145642694e-07, 'epoch': 0.61}
{'loss': 1.1223, 'grad_norm': 1.6464751958847046, 'learning_rate': 3.6140375273290473e-07, 'epoch': 0.61}
{'loss': 1.1611, 'grad_norm': 1.4098528623580933, 'learning_rate': 3.597387573595919e-07, 'epoch': 0.61}
{'loss': 1.0852, 'grad_norm': 1.3418571949005127, 'learning_rate': 3.580754484639561e-07, 'epoch': 0.61}
{'loss': 1.0055, 'grad_norm': 1.3192830085754395, 'learning_rate': 3.56413846045345e-07, 'epoch': 0.61}
{'loss': 1.1058, 'grad_norm': 1.6074589490890503, 'learning_rate': 3.547539700825874e-07, 'epoch': 0.61}
{'loss': 1.1346, 'grad_norm': 41.819332122802734, 'learning_rate': 3.5309584053375384e-07, 'epoch': 0.62}
{'loss': 1.1425, 'grad_norm': 1.565808892250061, 'learning_rate': 3.5143947733591626e-07, 'epoch': 0.62}
{'loss': 1.1271, 'grad_norm': 1.3962640762329102, 'learning_rate': 3.49784900404908e-07, 'epoch': 0.62}
{'loss': 1.1663, 'grad_norm': 4.422523498535156, 'learning_rate': 3.481321296350851e-07, 'epoch': 0.62}
{'loss': 1.1358, 'grad_norm': 2.3913090229034424, 'learning_rate': 3.4648118489908584e-07, 'epoch': 0.62}
{'loss': 1.1953, 'grad_norm': 1.4119492769241333, 'learning_rate': 3.448320860475934e-07, 'epoch': 0.62}
{'loss': 1.1236, 'grad_norm': 1.3888736963272095, 'learning_rate': 3.43184852909096e-07, 'epoch': 0.62}
{'loss': 1.091, 'grad_norm': 18.896177291870117, 'learning_rate': 3.4153950528964866e-07, 'epoch': 0.62}
{'loss': 1.1772, 'grad_norm': 33.56110382080078, 'learning_rate': 3.3989606297263573e-07, 'epoch': 0.62}
{'loss': 1.2091, 'grad_norm': 9.695820808410645, 'learning_rate': 3.382545457185321e-07, 'epoch': 0.62}
{'loss': 1.1069, 'grad_norm': 1.3285956382751465, 'learning_rate': 3.3661497326466607e-07, 'epoch': 0.63}
{'loss': 1.1091, 'grad_norm': 1.366605520248413, 'learning_rate': 3.349773653249822e-07, 'epoch': 0.63}
{'loss': 1.1686, 'grad_norm': 1.6216970682144165, 'learning_rate': 3.333417415898039e-07, 'epoch': 0.63}
{'loss': 1.1638, 'grad_norm': 1.7325299978256226, 'learning_rate': 3.317081217255969e-07, 'epoch': 0.63}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-600/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-600/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-600/model.safetensors.index.json.
2024-11-20 22:08:53,466 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-600/pytorch_model_fsdp.bin
2024-11-20 22:09:40,210 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-600/pytorch_model_fsdp.bin
2024-11-20 22:10:12,465 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-600/optimizer.bin
2024-11-20 22:11:34,352 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-600/optimizer.bin
                                                                                                                    
{'loss': 1.0984, 'grad_norm': 1.3648269176483154, 'learning_rate': 3.300765253747326e-07, 'epoch': 0.63}
{'loss': 1.0757, 'grad_norm': 1.4156526327133179, 'learning_rate': 3.2844697215525217e-07, 'epoch': 0.63}
{'loss': 1.0539, 'grad_norm': 1.3237993717193604, 'learning_rate': 3.2681948166063046e-07, 'epoch': 0.63}
{'loss': 1.1557, 'grad_norm': 1.3997820615768433, 'learning_rate': 3.2519407345954043e-07, 'epoch': 0.63}
{'loss': 1.1018, 'grad_norm': 3.8937766551971436, 'learning_rate': 3.235707670956178e-07, 'epoch': 0.63}
{'loss': 1.16, 'grad_norm': 1.368688702583313, 'learning_rate': 3.219495820872265e-07, 'epoch': 0.63}
{'loss': 1.1661, 'grad_norm': 1.338873267173767, 'learning_rate': 3.203305379272232e-07, 'epoch': 0.64}
{'loss': 1.0971, 'grad_norm': 2.106346607208252, 'learning_rate': 3.1871365408272367e-07, 'epoch': 0.64}
{'loss': 0.9759, 'grad_norm': 1.6631286144256592, 'learning_rate': 3.1709894999486825e-07, 'epoch': 0.64}
{'loss': 1.0569, 'grad_norm': 1.3912523984909058, 'learning_rate': 3.1548644507858845e-07, 'epoch': 0.64}
{'loss': 1.0532, 'grad_norm': 14.71741771697998, 'learning_rate': 3.138761587223729e-07, 'epoch': 0.64}
{'loss': 1.1506, 'grad_norm': 1.3771615028381348, 'learning_rate': 3.1226811028803514e-07, 'epoch': 0.64}
{'loss': 1.1306, 'grad_norm': 1.331516146659851, 'learning_rate': 3.1066231911047994e-07, 'epoch': 0.64}
{'loss': 1.1577, 'grad_norm': 1.4019564390182495, 'learning_rate': 3.0905880449747134e-07, 'epoch': 0.64}
{'loss': 1.0465, 'grad_norm': 21.118688583374023, 'learning_rate': 3.074575857294004e-07, 'epoch': 0.64}
{'loss': 1.1048, 'grad_norm': 1.5767377614974976, 'learning_rate': 3.058586820590532e-07, 'epoch': 0.65}
{'loss': 1.0532, 'grad_norm': 1.3678282499313354, 'learning_rate': 3.042621127113796e-07, 'epoch': 0.65}
{'loss': 1.1751, 'grad_norm': 1.4685832262039185, 'learning_rate': 3.026678968832618e-07, 'epoch': 0.65}
{'loss': 1.146, 'grad_norm': 1.3109666109085083, 'learning_rate': 3.010760537432839e-07, 'epoch': 0.65}
{'loss': 1.1786, 'grad_norm': 1.392431616783142, 'learning_rate': 2.994866024315009e-07, 'epoch': 0.65}
{'loss': 1.1095, 'grad_norm': 23.956579208374023, 'learning_rate': 2.978995620592092e-07, 'epoch': 0.65}
{'loss': 1.1413, 'grad_norm': 31.038217544555664, 'learning_rate': 2.96314951708716e-07, 'epoch': 0.65}
{'loss': 1.1238, 'grad_norm': 1.7686446905136108, 'learning_rate': 2.947327904331109e-07, 'epoch': 0.65}
{'loss': 1.1, 'grad_norm': 1.5223004817962646, 'learning_rate': 2.9315309725603594e-07, 'epoch': 0.65}
{'loss': 1.1067, 'grad_norm': 1.4303016662597656, 'learning_rate': 2.91575891171457e-07, 'epoch': 0.65}
{'loss': 1.1374, 'grad_norm': 1.5218687057495117, 'learning_rate': 2.900011911434358e-07, 'epoch': 0.66}
{'loss': 1.1036, 'grad_norm': 1.7773476839065552, 'learning_rate': 2.8842901610590164e-07, 'epoch': 0.66}
{'loss': 1.1661, 'grad_norm': 20.404970169067383, 'learning_rate': 2.8685938496242367e-07, 'epoch': 0.66}
{'loss': 1.1334, 'grad_norm': 1.3309482336044312, 'learning_rate': 2.8529231658598376e-07, 'epoch': 0.66}
{'loss': 1.1065, 'grad_norm': 1.3270896673202515, 'learning_rate': 2.837278298187496e-07, 'epoch': 0.66}
{'loss': 1.1331, 'grad_norm': 1.611384391784668, 'learning_rate': 2.8216594347184753e-07, 'epoch': 0.66}
{'loss': 1.2513, 'grad_norm': 2.064671277999878, 'learning_rate': 2.8060667632513755e-07, 'epoch': 0.66}
{'loss': 1.1725, 'grad_norm': 16.14214324951172, 'learning_rate': 2.7905004712698645e-07, 'epoch': 0.66}
{'loss': 1.0768, 'grad_norm': 1.3512911796569824, 'learning_rate': 2.774960745940428e-07, 'epoch': 0.66}
{'loss': 1.0131, 'grad_norm': 1.373665452003479, 'learning_rate': 2.75944777411012e-07, 'epoch': 0.67}
{'loss': 1.1135, 'grad_norm': 1.3160699605941772, 'learning_rate': 2.743961742304314e-07, 'epoch': 0.67}
{'loss': 1.1196, 'grad_norm': 1.455735683441162, 'learning_rate': 2.728502836724462e-07, 'epoch': 0.67}
{'loss': 1.1027, 'grad_norm': 1.7245861291885376, 'learning_rate': 2.7130712432458536e-07, 'epoch': 0.67}
{'loss': 1.0673, 'grad_norm': 1.2780543565750122, 'learning_rate': 2.6976671474153823e-07, 'epoch': 0.67}
{'loss': 1.2284, 'grad_norm': 1.4117224216461182, 'learning_rate': 2.682290734449314e-07, 'epoch': 0.67}
{'loss': 1.2466, 'grad_norm': 1.6435370445251465, 'learning_rate': 2.6669421892310653e-07, 'epoch': 0.67}
{'loss': 1.1022, 'grad_norm': 1.413716197013855, 'learning_rate': 2.6516216963089693e-07, 'epoch': 0.67}
{'loss': 1.1313, 'grad_norm': 1.4564200639724731, 'learning_rate': 2.636329439894066e-07, 'epoch': 0.67}
{'loss': 1.0863, 'grad_norm': 1.3829948902130127, 'learning_rate': 2.621065603857884e-07, 'epoch': 0.67}
{'loss': 1.0593, 'grad_norm': 1.480391502380371, 'learning_rate': 2.6058303717302286e-07, 'epoch': 0.68}
{'loss': 1.1652, 'grad_norm': 1.4082543849945068, 'learning_rate': 2.5906239266969806e-07, 'epoch': 0.68}
{'loss': 1.0947, 'grad_norm': 1.4084157943725586, 'learning_rate': 2.575446451597884e-07, 'epoch': 0.68}
{'loss': 1.0996, 'grad_norm': 1.563265085220337, 'learning_rate': 2.5602981289243577e-07, 'epoch': 0.68}
{'loss': 1.1188, 'grad_norm': 19.472217559814453, 'learning_rate': 2.5451791408172966e-07, 'epoch': 0.68}
{'loss': 1.0756, 'grad_norm': 40.13976287841797, 'learning_rate': 2.5300896690648764e-07, 'epoch': 0.68}
{'loss': 1.1523, 'grad_norm': 1.36489999294281, 'learning_rate': 2.515029895100378e-07, 'epoch': 0.68}
{'loss': 1.1346, 'grad_norm': 1.5592900514602661, 'learning_rate': 2.500000000000001e-07, 'epoch': 0.68}
{'loss': 1.1368, 'grad_norm': 1.421779990196228, 'learning_rate': 2.4850001644806845e-07, 'epoch': 0.68}
{'loss': 1.1032, 'grad_norm': 1.3865233659744263, 'learning_rate': 2.4700305688979376e-07, 'epoch': 0.69}
{'loss': 1.1878, 'grad_norm': 27.027746200561523, 'learning_rate': 2.455091393243669e-07, 'epoch': 0.69}
{'loss': 1.1267, 'grad_norm': 1.5703104734420776, 'learning_rate': 2.4401828171440235e-07, 'epoch': 0.69}
{'loss': 1.1026, 'grad_norm': 1.6813160181045532, 'learning_rate': 2.4253050198572216e-07, 'epoch': 0.69}
{'loss': 1.161, 'grad_norm': 1.3303877115249634, 'learning_rate': 2.4104581802714045e-07, 'epoch': 0.69}
{'loss': 1.1545, 'grad_norm': 1.4213800430297852, 'learning_rate': 2.3956424769024843e-07, 'epoch': 0.69}
{'loss': 1.079, 'grad_norm': 1.3285471200942993, 'learning_rate': 2.3808580878919941e-07, 'epoch': 0.69}
{'loss': 1.0483, 'grad_norm': 1.475958228111267, 'learning_rate': 2.3661051910049517e-07, 'epoch': 0.69}
{'loss': 1.15, 'grad_norm': 2.0413928031921387, 'learning_rate': 2.3513839636277156e-07, 'epoch': 0.69}
{'loss': 1.0661, 'grad_norm': 1.3800528049468994, 'learning_rate': 2.3366945827658568e-07, 'epoch': 0.69}
{'loss': 1.0924, 'grad_norm': 1.2793500423431396, 'learning_rate': 2.32203722504203e-07, 'epoch': 0.7}
{'loss': 1.0548, 'grad_norm': 1.3338695764541626, 'learning_rate': 2.3074120666938485e-07, 'epoch': 0.7}
{'loss': 1.1244, 'grad_norm': 1.5111626386642456, 'learning_rate': 2.292819283571764e-07, 'epoch': 0.7}
{'loss': 1.0716, 'grad_norm': 1.3516936302185059, 'learning_rate': 2.2782590511369548e-07, 'epoch': 0.7}
{'loss': 1.2197, 'grad_norm': 1.6490001678466797, 'learning_rate': 2.263731544459219e-07, 'epoch': 0.7}
{'loss': 1.1441, 'grad_norm': 1.4173742532730103, 'learning_rate': 2.2492369382148628e-07, 'epoch': 0.7}
{'loss': 1.0708, 'grad_norm': 1.3818943500518799, 'learning_rate': 2.2347754066845986e-07, 'epoch': 0.7}
{'loss': 1.1533, 'grad_norm': 1.6091907024383545, 'learning_rate': 2.2203471237514603e-07, 'epoch': 0.7}
{'loss': 1.1287, 'grad_norm': 1.5673691034317017, 'learning_rate': 2.2059522628987037e-07, 'epoch': 0.7}
{'loss': 1.0288, 'grad_norm': 1.4185682535171509, 'learning_rate': 2.191590997207724e-07, 'epoch': 0.71}
{'loss': 1.0988, 'grad_norm': 22.804790496826172, 'learning_rate': 2.1772634993559725e-07, 'epoch': 0.71}
{'loss': 1.1853, 'grad_norm': 31.882062911987305, 'learning_rate': 2.1629699416148829e-07, 'epoch': 0.71}
{'loss': 1.1213, 'grad_norm': 1.3067991733551025, 'learning_rate': 2.1487104958477986e-07, 'epoch': 0.71}
{'loss': 1.0969, 'grad_norm': 1.4449807405471802, 'learning_rate': 2.1344853335079048e-07, 'epoch': 0.71}
{'loss': 1.1591, 'grad_norm': 1.2947243452072144, 'learning_rate': 2.1202946256361708e-07, 'epoch': 0.71}
{'loss': 1.132, 'grad_norm': 3.218193292617798, 'learning_rate': 2.1061385428592898e-07, 'epoch': 0.71}
{'loss': 1.1245, 'grad_norm': 26.67364501953125, 'learning_rate': 2.0920172553876285e-07, 'epoch': 0.71}
{'loss': 1.0835, 'grad_norm': 1.3342167139053345, 'learning_rate': 2.0779309330131816e-07, 'epoch': 0.71}
{'loss': 1.1896, 'grad_norm': 24.08902931213379, 'learning_rate': 2.0638797451075284e-07, 'epoch': 0.71}
{'loss': 1.0825, 'grad_norm': 13.449115753173828, 'learning_rate': 2.0498638606197981e-07, 'epoch': 0.72}
{'loss': 1.1265, 'grad_norm': 1.3243106603622437, 'learning_rate': 2.0358834480746363e-07, 'epoch': 0.72}
{'loss': 1.1375, 'grad_norm': 2.105102062225342, 'learning_rate': 2.0219386755701812e-07, 'epoch': 0.72}
{'loss': 1.1951, 'grad_norm': 1.8714544773101807, 'learning_rate': 2.0080297107760408e-07, 'epoch': 0.72}
{'loss': 1.0708, 'grad_norm': 1.421262502670288, 'learning_rate': 1.9941567209312766e-07, 'epoch': 0.72}
{'loss': 1.013, 'grad_norm': 1.2735553979873657, 'learning_rate': 1.9803198728423936e-07, 'epoch': 0.72}
{'loss': 1.0525, 'grad_norm': 1.416745901107788, 'learning_rate': 1.9665193328813345e-07, 'epoch': 0.72}
{'loss': 1.0907, 'grad_norm': 31.228696823120117, 'learning_rate': 1.9527552669834797e-07, 'epoch': 0.72}
{'loss': 1.2046, 'grad_norm': 1.3528690338134766, 'learning_rate': 1.9390278406456506e-07, 'epoch': 0.72}
{'loss': 1.1163, 'grad_norm': 1.3024463653564453, 'learning_rate': 1.9253372189241212e-07, 'epoch': 0.73}
{'loss': 1.0885, 'grad_norm': 1.3734148740768433, 'learning_rate': 1.9116835664326324e-07, 'epoch': 0.73}
{'loss': 1.1716, 'grad_norm': 1.6846181154251099, 'learning_rate': 1.898067047340415e-07, 'epoch': 0.73}
{'loss': 1.0984, 'grad_norm': 1.3192050457000732, 'learning_rate': 1.884487825370211e-07, 'epoch': 0.73}
{'loss': 1.1531, 'grad_norm': 1.373245120048523, 'learning_rate': 1.8709460637963122e-07, 'epoch': 0.73}
{'loss': 1.0877, 'grad_norm': 1.5350927114486694, 'learning_rate': 1.8574419254425878e-07, 'epoch': 0.73}
{'loss': 1.1267, 'grad_norm': 1.380737066268921, 'learning_rate': 1.8439755726805362e-07, 'epoch': 0.73}
{'loss': 1.0889, 'grad_norm': 1.3680485486984253, 'learning_rate': 1.830547167427326e-07, 'epoch': 0.73}
{'loss': 1.072, 'grad_norm': 1.341096043586731, 'learning_rate': 1.8171568711438512e-07, 'epoch': 0.73}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-700/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-700/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-700/model.safetensors.index.json.
2024-11-20 22:26:37,457 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-700/pytorch_model_fsdp.bin
2024-11-20 22:27:19,926 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-700/pytorch_model_fsdp.bin
2024-11-20 22:27:52,184 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-700/optimizer.bin
2024-11-20 22:29:14,389 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-700/optimizer.bin
                                                                                                                    
{'loss': 1.1067, 'grad_norm': 1.344042181968689, 'learning_rate': 1.8038048448327908e-07, 'epoch': 0.73}
{'loss': 1.1207, 'grad_norm': 1.400732159614563, 'learning_rate': 1.790491249036672e-07, 'epoch': 0.74}
{'loss': 1.0712, 'grad_norm': 1.3566876649856567, 'learning_rate': 1.777216243835939e-07, 'epoch': 0.74}
{'loss': 1.1166, 'grad_norm': 1.4715408086776733, 'learning_rate': 1.7639799888470303e-07, 'epoch': 0.74}
{'loss': 1.1725, 'grad_norm': 1.4061933755874634, 'learning_rate': 1.750782643220457e-07, 'epoch': 0.74}
{'loss': 1.1617, 'grad_norm': 1.344309687614441, 'learning_rate': 1.7376243656388922e-07, 'epoch': 0.74}
{'loss': 1.0949, 'grad_norm': 1.4265977144241333, 'learning_rate': 1.7245053143152605e-07, 'epoch': 0.74}
{'loss': 1.0456, 'grad_norm': 1.3657467365264893, 'learning_rate': 1.7114256469908379e-07, 'epoch': 0.74}
{'loss': 1.1129, 'grad_norm': 1.357581377029419, 'learning_rate': 1.698385520933349e-07, 'epoch': 0.74}
{'loss': 1.176, 'grad_norm': 1.4970557689666748, 'learning_rate': 1.6853850929350866e-07, 'epoch': 0.74}
{'loss': 1.0927, 'grad_norm': 1.4912045001983643, 'learning_rate': 1.6724245193110177e-07, 'epoch': 0.74}
{'loss': 1.1096, 'grad_norm': 19.519695281982422, 'learning_rate': 1.6595039558969082e-07, 'epoch': 0.75}
{'loss': 1.1748, 'grad_norm': 13.902247428894043, 'learning_rate': 1.6466235580474473e-07, 'epoch': 0.75}
{'loss': 1.1265, 'grad_norm': 1.3213379383087158, 'learning_rate': 1.633783480634378e-07, 'epoch': 0.75}
{'loss': 1.211, 'grad_norm': 1.4550104141235352, 'learning_rate': 1.6209838780446438e-07, 'epoch': 0.75}
{'loss': 1.139, 'grad_norm': 1.4261586666107178, 'learning_rate': 1.6082249041785195e-07, 'epoch': 0.75}
{'loss': 1.1167, 'grad_norm': 1.3078105449676514, 'learning_rate': 1.5955067124477677e-07, 'epoch': 0.75}
{'loss': 1.1629, 'grad_norm': 1.286712408065796, 'learning_rate': 1.5828294557737959e-07, 'epoch': 0.75}
{'loss': 1.1231, 'grad_norm': 1.5327509641647339, 'learning_rate': 1.570193286585813e-07, 'epoch': 0.75}
{'loss': 1.1624, 'grad_norm': 1.486441731452942, 'learning_rate': 1.5575983568189998e-07, 'epoch': 0.75}
{'loss': 1.0843, 'grad_norm': 11.899319648742676, 'learning_rate': 1.5450448179126823e-07, 'epoch': 0.76}
{'loss': 1.0696, 'grad_norm': 1.3173409700393677, 'learning_rate': 1.5325328208085074e-07, 'epoch': 0.76}
{'loss': 1.1244, 'grad_norm': 1.4220918416976929, 'learning_rate': 1.520062515948632e-07, 'epoch': 0.76}
{'loss': 1.1602, 'grad_norm': 1.7331417798995972, 'learning_rate': 1.5076340532739123e-07, 'epoch': 0.76}
{'loss': 1.1498, 'grad_norm': 1.3861308097839355, 'learning_rate': 1.4952475822221005e-07, 'epoch': 0.76}
{'loss': 1.0939, 'grad_norm': 1.2749478816986084, 'learning_rate': 1.4829032517260488e-07, 'epoch': 0.76}
{'loss': 1.1761, 'grad_norm': 1.3736016750335693, 'learning_rate': 1.4706012102119187e-07, 'epoch': 0.76}
{'loss': 1.1648, 'grad_norm': 8.871872901916504, 'learning_rate': 1.4583416055973973e-07, 'epoch': 0.76}
{'loss': 1.1654, 'grad_norm': 15.441720008850098, 'learning_rate': 1.4461245852899128e-07, 'epoch': 0.76}
{'loss': 1.0696, 'grad_norm': 1.4717518091201782, 'learning_rate': 1.433950296184872e-07, 'epoch': 0.76}
{'loss': 1.1147, 'grad_norm': 1.3468488454818726, 'learning_rate': 1.421818884663886e-07, 'epoch': 0.77}
{'loss': 1.0606, 'grad_norm': 1.3231077194213867, 'learning_rate': 1.4097304965930156e-07, 'epoch': 0.77}
{'loss': 1.2287, 'grad_norm': 1.640001654624939, 'learning_rate': 1.3976852773210123e-07, 'epoch': 0.77}
{'loss': 1.1797, 'grad_norm': 1.4425969123840332, 'learning_rate': 1.3856833716775745e-07, 'epoch': 0.77}
{'loss': 1.1291, 'grad_norm': 1.3847415447235107, 'learning_rate': 1.3737249239716041e-07, 'epoch': 0.77}
{'loss': 1.1792, 'grad_norm': 1.3645509481430054, 'learning_rate': 1.3618100779894725e-07, 'epoch': 0.77}
{'loss': 1.1625, 'grad_norm': 1.535092830657959, 'learning_rate': 1.3499389769932906e-07, 'epoch': 0.77}
{'loss': 1.0381, 'grad_norm': 1.341583013534546, 'learning_rate': 1.3381117637191886e-07, 'epoch': 0.77}
{'loss': 1.2152, 'grad_norm': 1.612034559249878, 'learning_rate': 1.3263285803755965e-07, 'epoch': 0.77}
{'loss': 1.0902, 'grad_norm': 1.3414286375045776, 'learning_rate': 1.3145895686415353e-07, 'epoch': 0.78}
{'loss': 1.0583, 'grad_norm': 1.6377488374710083, 'learning_rate': 1.3028948696649162e-07, 'epoch': 0.78}
{'loss': 1.0816, 'grad_norm': 2.257254123687744, 'learning_rate': 1.2912446240608381e-07, 'epoch': 0.78}
{'loss': 1.0918, 'grad_norm': 1.431881070137024, 'learning_rate': 1.279638971909905e-07, 'epoch': 0.78}
{'loss': 1.202, 'grad_norm': 1.3889479637145996, 'learning_rate': 1.268078052756531e-07, 'epoch': 0.78}
{'loss': 1.1557, 'grad_norm': 1.3136646747589111, 'learning_rate': 1.256562005607272e-07, 'epoch': 0.78}
{'loss': 1.0659, 'grad_norm': 1.482311725616455, 'learning_rate': 1.245090968929148e-07, 'epoch': 0.78}
{'loss': 1.1256, 'grad_norm': 2.332545042037964, 'learning_rate': 1.2336650806479827e-07, 'epoch': 0.78}
{'loss': 1.1307, 'grad_norm': 1.5462746620178223, 'learning_rate': 1.2222844781467428e-07, 'epoch': 0.78}
{'loss': 1.0898, 'grad_norm': 1.499588966369629, 'learning_rate': 1.2109492982638837e-07, 'epoch': 0.78}
{'loss': 1.1208, 'grad_norm': 16.78169822692871, 'learning_rate': 1.199659677291709e-07, 'epoch': 0.79}
{'loss': 1.1598, 'grad_norm': 1.4066853523254395, 'learning_rate': 1.1884157509747305e-07, 'epoch': 0.79}
{'loss': 1.116, 'grad_norm': 1.6667596101760864, 'learning_rate': 1.1772176545080332e-07, 'epoch': 0.79}
{'loss': 1.0242, 'grad_norm': 1.3321284055709839, 'learning_rate': 1.166065522535653e-07, 'epoch': 0.79}
{'loss': 1.083, 'grad_norm': 15.363597869873047, 'learning_rate': 1.1549594891489561e-07, 'epoch': 0.79}
{'loss': 1.1107, 'grad_norm': 1.5438140630722046, 'learning_rate': 1.1438996878850265e-07, 'epoch': 0.79}
{'loss': 1.1604, 'grad_norm': 1.386332631111145, 'learning_rate': 1.1328862517250609e-07, 'epoch': 0.79}
{'loss': 1.055, 'grad_norm': 1.5461488962173462, 'learning_rate': 1.1219193130927706e-07, 'epoch': 0.79}
{'loss': 1.043, 'grad_norm': 1.280368447303772, 'learning_rate': 1.1109990038527878e-07, 'epoch': 0.79}
{'loss': 1.0604, 'grad_norm': 1.2604283094406128, 'learning_rate': 1.1001254553090811e-07, 'epoch': 0.8}
{'loss': 1.1072, 'grad_norm': 1.2959719896316528, 'learning_rate': 1.0892987982033757e-07, 'epoch': 0.8}
{'loss': 1.2478, 'grad_norm': 1.4268314838409424, 'learning_rate': 1.078519162713582e-07, 'epoch': 0.8}
{'loss': 1.1401, 'grad_norm': 2.2350099086761475, 'learning_rate': 1.0677866784522316e-07, 'epoch': 0.8}
{'loss': 1.1038, 'grad_norm': 1.663253664970398, 'learning_rate': 1.057101474464916e-07, 'epoch': 0.8}
{'loss': 1.1053, 'grad_norm': 10.70502758026123, 'learning_rate': 1.0464636792287379e-07, 'epoch': 0.8}
{'loss': 1.1792, 'grad_norm': 1.51199471950531, 'learning_rate': 1.0358734206507641e-07, 'epoch': 0.8}
{'loss': 1.1575, 'grad_norm': 1.4402968883514404, 'learning_rate': 1.02533082606649e-07, 'epoch': 0.8}
{'loss': 1.1125, 'grad_norm': 1.4981359243392944, 'learning_rate': 1.0148360222383045e-07, 'epoch': 0.8}
{'loss': 1.2267, 'grad_norm': 1.4267802238464355, 'learning_rate': 1.0043891353539718e-07, 'epoch': 0.8}
{'loss': 1.057, 'grad_norm': 1.4883216619491577, 'learning_rate': 9.939902910251085e-08, 'epoch': 0.81}
{'loss': 1.0589, 'grad_norm': 26.76205062866211, 'learning_rate': 9.836396142856762e-08, 'epoch': 0.81}
{'loss': 1.1666, 'grad_norm': 1.3582059144973755, 'learning_rate': 9.733372295904773e-08, 'epoch': 0.81}
{'loss': 1.0885, 'grad_norm': 1.4318104982376099, 'learning_rate': 9.630832608136597e-08, 'epoch': 0.81}
{'loss': 1.173, 'grad_norm': 1.4498579502105713, 'learning_rate': 9.528778312472252e-08, 'epoch': 0.81}
{'loss': 1.0907, 'grad_norm': 1.290099859237671, 'learning_rate': 9.42721063599548e-08, 'epoch': 0.81}
{'loss': 1.149, 'grad_norm': 1.4652949571609497, 'learning_rate': 9.326130799939013e-08, 'epoch': 0.81}
{'loss': 1.064, 'grad_norm': 1.4329546689987183, 'learning_rate': 9.225540019669858e-08, 'epoch': 0.81}
{'loss': 1.0232, 'grad_norm': 1.3562068939208984, 'learning_rate': 9.125439504674698e-08, 'epoch': 0.81}
{'loss': 1.1465, 'grad_norm': 29.30810546875, 'learning_rate': 9.025830458545359e-08, 'epoch': 0.82}
{'loss': 1.1385, 'grad_norm': 1.4500688314437866, 'learning_rate': 8.92671407896431e-08, 'epoch': 0.82}
{'loss': 1.0759, 'grad_norm': 1.3786728382110596, 'learning_rate': 8.828091557690287e-08, 'epoch': 0.82}
{'loss': 1.1492, 'grad_norm': 1.4936792850494385, 'learning_rate': 8.729964080543972e-08, 'epoch': 0.82}
{'loss': 1.0867, 'grad_norm': 14.895395278930664, 'learning_rate': 8.632332827393702e-08, 'epoch': 0.82}
{'loss': 1.055, 'grad_norm': 1.2702311277389526, 'learning_rate': 8.535198972141294e-08, 'epoch': 0.82}
{'loss': 1.1287, 'grad_norm': 1.467042326927185, 'learning_rate': 8.43856368270796e-08, 'epoch': 0.82}
{'loss': 1.1069, 'grad_norm': 1.3364802598953247, 'learning_rate': 8.342428121020218e-08, 'epoch': 0.82}
{'loss': 1.0542, 'grad_norm': 22.641807556152344, 'learning_rate': 8.246793442995953e-08, 'epoch': 0.82}
{'loss': 1.1533, 'grad_norm': 1.4671807289123535, 'learning_rate': 8.151660798530524e-08, 'epoch': 0.82}
{'loss': 1.2541, 'grad_norm': 1.412693738937378, 'learning_rate': 8.057031331482878e-08, 'epoch': 0.83}
{'loss': 1.0793, 'grad_norm': 1.4140321016311646, 'learning_rate': 7.962906179661871e-08, 'epoch': 0.83}
{'loss': 1.0741, 'grad_norm': 1.3049297332763672, 'learning_rate': 7.869286474812581e-08, 'epoch': 0.83}
{'loss': 1.1022, 'grad_norm': 1.3736562728881836, 'learning_rate': 7.776173342602633e-08, 'epoch': 0.83}
{'loss': 1.1062, 'grad_norm': 1.4835935831069946, 'learning_rate': 7.683567902608729e-08, 'epoch': 0.83}
{'loss': 1.0533, 'grad_norm': 1.3400579690933228, 'learning_rate': 7.591471268303157e-08, 'epoch': 0.83}
{'loss': 1.1469, 'grad_norm': 1.4192742109298706, 'learning_rate': 7.499884547040425e-08, 'epoch': 0.83}
{'loss': 1.0599, 'grad_norm': 29.975595474243164, 'learning_rate': 7.408808840043912e-08, 'epoch': 0.83}
{'loss': 1.0701, 'grad_norm': 1.3221337795257568, 'learning_rate': 7.318245242392657e-08, 'epoch': 0.83}
{'loss': 1.0655, 'grad_norm': 1.3921266794204712, 'learning_rate': 7.22819484300819e-08, 'epoch': 0.84}
{'loss': 1.1115, 'grad_norm': 15.697196006774902, 'learning_rate': 7.138658724641417e-08, 'epoch': 0.84}
{'loss': 1.1335, 'grad_norm': 1.3268206119537354, 'learning_rate': 7.049637963859617e-08, 'epoch': 0.84}
{'loss': 1.059, 'grad_norm': 1.40300714969635, 'learning_rate': 6.961133631033511e-08, 'epoch': 0.84}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-800/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-800/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-800/model.safetensors.index.json.
2024-11-20 22:44:22,476 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-800/pytorch_model_fsdp.bin
2024-11-20 22:45:14,331 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-800/pytorch_model_fsdp.bin
2024-11-20 22:45:46,583 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-800/optimizer.bin
2024-11-20 22:47:09,679 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-800/optimizer.bin
                                                                                                                    
{'loss': 1.0713, 'grad_norm': 1.4466123580932617, 'learning_rate': 6.873146790324358e-08, 'epoch': 0.84}
{'loss': 1.1952, 'grad_norm': 1.368660807609558, 'learning_rate': 6.785678499671183e-08, 'epoch': 0.84}
{'loss': 1.1513, 'grad_norm': 1.9203300476074219, 'learning_rate': 6.698729810778064e-08, 'epoch': 0.84}
{'loss': 1.0683, 'grad_norm': 17.42531967163086, 'learning_rate': 6.612301769101464e-08, 'epoch': 0.84}
{'loss': 1.0964, 'grad_norm': 13.044672012329102, 'learning_rate': 6.526395413837672e-08, 'epoch': 0.84}
{'loss': 1.1504, 'grad_norm': 8.076083183288574, 'learning_rate': 6.441011777910299e-08, 'epoch': 0.84}
{'loss': 1.2061, 'grad_norm': 1.361667275428772, 'learning_rate': 6.3561518879579e-08, 'epoch': 0.85}
{'loss': 1.1117, 'grad_norm': 1.3232927322387695, 'learning_rate': 6.271816764321541e-08, 'epoch': 0.85}
{'loss': 1.0042, 'grad_norm': 1.3228780031204224, 'learning_rate': 6.188007421032631e-08, 'epoch': 0.85}
{'loss': 1.068, 'grad_norm': 1.3893829584121704, 'learning_rate': 6.104724865800664e-08, 'epoch': 0.85}
{'loss': 1.1352, 'grad_norm': 1.3694820404052734, 'learning_rate': 6.021970100001134e-08, 'epoch': 0.85}
{'loss': 1.0848, 'grad_norm': 9.833664894104004, 'learning_rate': 5.9397441186634754e-08, 'epoch': 0.85}
{'loss': 1.1491, 'grad_norm': 1.4373939037322998, 'learning_rate': 5.8580479104591075e-08, 'epoch': 0.85}
{'loss': 1.1307, 'grad_norm': 1.318660855293274, 'learning_rate': 5.776882457689547e-08, 'epoch': 0.85}
{'loss': 1.0831, 'grad_norm': 1.5383754968643188, 'learning_rate': 5.6962487362746006e-08, 'epoch': 0.85}
{'loss': 1.1582, 'grad_norm': 1.3141909837722778, 'learning_rate': 5.6161477157406104e-08, 'epoch': 0.86}
{'loss': 1.1231, 'grad_norm': 1.8504705429077148, 'learning_rate': 5.5365803592088426e-08, 'epoch': 0.86}
{'loss': 1.1219, 'grad_norm': 1.3558650016784668, 'learning_rate': 5.457547623383846e-08, 'epoch': 0.86}
{'loss': 1.0993, 'grad_norm': 17.909954071044922, 'learning_rate': 5.379050458541995e-08, 'epoch': 0.86}
{'loss': 1.11, 'grad_norm': 1.4667999744415283, 'learning_rate': 5.301089808520048e-08, 'epoch': 0.86}
{'loss': 1.0922, 'grad_norm': 1.4252289533615112, 'learning_rate': 5.223666610703797e-08, 'epoch': 0.86}
{'loss': 1.1388, 'grad_norm': 1.2992949485778809, 'learning_rate': 5.146781796016797e-08, 'epoch': 0.86}
{'loss': 1.1797, 'grad_norm': 1.2925018072128296, 'learning_rate': 5.070436288909169e-08, 'epoch': 0.86}
{'loss': 1.1186, 'grad_norm': 18.399599075317383, 'learning_rate': 4.9946310073465056e-08, 'epoch': 0.86}
{'loss': 1.1664, 'grad_norm': 14.306866645812988, 'learning_rate': 4.9193668627988073e-08, 'epoch': 0.86}
{'loss': 1.086, 'grad_norm': 1.3569731712341309, 'learning_rate': 4.844644760229544e-08, 'epoch': 0.87}
{'loss': 1.0565, 'grad_norm': 28.757633209228516, 'learning_rate': 4.770465598084733e-08, 'epoch': 0.87}
{'loss': 1.1049, 'grad_norm': 1.6325489282608032, 'learning_rate': 4.6968302682822036e-08, 'epoch': 0.87}
{'loss': 1.1911, 'grad_norm': 12.293882369995117, 'learning_rate': 4.62373965620082e-08, 'epoch': 0.87}
{'loss': 1.1851, 'grad_norm': 1.5020439624786377, 'learning_rate': 4.551194640669859e-08, 'epoch': 0.87}
{'loss': 1.1451, 'grad_norm': 2.233920097351074, 'learning_rate': 4.47919609395842e-08, 'epoch': 0.87}
{'loss': 1.0984, 'grad_norm': 1.9662623405456543, 'learning_rate': 4.407744881764969e-08, 'epoch': 0.87}
{'loss': 1.0646, 'grad_norm': 1.3408406972885132, 'learning_rate': 4.3368418632069137e-08, 'epoch': 0.87}
{'loss': 1.1524, 'grad_norm': 1.410831332206726, 'learning_rate': 4.266487890810255e-08, 'epoch': 0.87}
{'loss': 1.1883, 'grad_norm': 1.3754595518112183, 'learning_rate': 4.196683810499379e-08, 'epoch': 0.87}
{'loss': 1.1076, 'grad_norm': 1.3267358541488647, 'learning_rate': 4.127430461586845e-08, 'epoch': 0.88}
{'loss': 1.109, 'grad_norm': 1.4376873970031738, 'learning_rate': 4.058728676763312e-08, 'epoch': 0.88}
{'loss': 1.2031, 'grad_norm': 1.3693581819534302, 'learning_rate': 3.990579282087536e-08, 'epoch': 0.88}
{'loss': 1.0478, 'grad_norm': 2.000962734222412, 'learning_rate': 3.9229830969764124e-08, 'epoch': 0.88}
{'loss': 1.1487, 'grad_norm': 8.974443435668945, 'learning_rate': 3.855940934195145e-08, 'epoch': 0.88}
{'loss': 1.1609, 'grad_norm': 1.3319584131240845, 'learning_rate': 3.789453599847464e-08, 'epoch': 0.88}
{'loss': 1.1636, 'grad_norm': 1.3420608043670654, 'learning_rate': 3.723521893365933e-08, 'epoch': 0.88}
{'loss': 1.0797, 'grad_norm': 16.976734161376953, 'learning_rate': 3.658146607502344e-08, 'epoch': 0.88}
{'loss': 1.1216, 'grad_norm': 1.414373517036438, 'learning_rate': 3.5933285283181845e-08, 'epoch': 0.88}
{'loss': 1.1757, 'grad_norm': 1.4217233657836914, 'learning_rate': 3.52906843517517e-08, 'epoch': 0.89}
{'loss': 1.1108, 'grad_norm': 12.309746742248535, 'learning_rate': 3.465367100725908e-08, 'epoch': 0.89}
{'loss': 1.0722, 'grad_norm': 1.3116612434387207, 'learning_rate': 3.4022252909045427e-08, 'epoch': 0.89}
{'loss': 1.09, 'grad_norm': 30.48673439025879, 'learning_rate': 3.339643764917632e-08, 'epoch': 0.89}
{'loss': 1.145, 'grad_norm': 1.3405630588531494, 'learning_rate': 3.277623275234953e-08, 'epoch': 0.89}
{'loss': 1.199, 'grad_norm': 1.3468809127807617, 'learning_rate': 3.2161645675804764e-08, 'epoch': 0.89}
{'loss': 1.1408, 'grad_norm': 1.5096186399459839, 'learning_rate': 3.1552683809234095e-08, 'epoch': 0.89}
{'loss': 1.0933, 'grad_norm': 1.3685951232910156, 'learning_rate': 3.0949354474692935e-08, 'epoch': 0.89}
{'loss': 1.0774, 'grad_norm': 1.3253179788589478, 'learning_rate': 3.0351664926512085e-08, 'epoch': 0.89}
{'loss': 1.1647, 'grad_norm': 1.301127552986145, 'learning_rate': 2.97596223512106e-08, 'epoch': 0.89}
{'loss': 1.1065, 'grad_norm': 1.315904974937439, 'learning_rate': 2.9173233867409053e-08, 'epoch': 0.9}
{'loss': 1.1098, 'grad_norm': 1.6242518424987793, 'learning_rate': 2.8592506525744464e-08, 'epoch': 0.9}
{'loss': 1.1222, 'grad_norm': 1.3543106317520142, 'learning_rate': 2.8017447308784914e-08, 'epoch': 0.9}
{'loss': 1.1026, 'grad_norm': 1.3349218368530273, 'learning_rate': 2.744806313094622e-08, 'epoch': 0.9}
{'loss': 1.0447, 'grad_norm': 1.3496837615966797, 'learning_rate': 2.688436083840817e-08, 'epoch': 0.9}
{'loss': 1.1615, 'grad_norm': 1.3697847127914429, 'learning_rate': 2.6326347209032817e-08, 'epoch': 0.9}
{'loss': 1.0926, 'grad_norm': 1.3170256614685059, 'learning_rate': 2.5774028952282424e-08, 'epoch': 0.9}
{'loss': 1.173, 'grad_norm': 1.9593336582183838, 'learning_rate': 2.522741270913914e-08, 'epoch': 0.9}
{'loss': 1.0882, 'grad_norm': 1.3577810525894165, 'learning_rate': 2.4686505052025186e-08, 'epoch': 0.9}
{'loss': 1.1284, 'grad_norm': 1.3231157064437866, 'learning_rate': 2.4151312484723464e-08, 'epoch': 0.91}
{'loss': 1.0412, 'grad_norm': 1.2851755619049072, 'learning_rate': 2.3621841442299784e-08, 'epoch': 0.91}
{'loss': 1.1717, 'grad_norm': 1.4035300016403198, 'learning_rate': 2.309809829102527e-08, 'epoch': 0.91}
{'loss': 1.1034, 'grad_norm': 1.3119035959243774, 'learning_rate': 2.2580089328299746e-08, 'epoch': 0.91}
{'loss': 1.0937, 'grad_norm': 1.3208922147750854, 'learning_rate': 2.206782078257613e-08, 'epoch': 0.91}
{'loss': 1.1856, 'grad_norm': 16.539140701293945, 'learning_rate': 2.156129881328572e-08, 'epoch': 0.91}
{'loss': 1.1478, 'grad_norm': 1.5020073652267456, 'learning_rate': 2.1060529510763648e-08, 'epoch': 0.91}
{'loss': 1.2322, 'grad_norm': 19.16734504699707, 'learning_rate': 2.0565518896176137e-08, 'epoch': 0.91}
{'loss': 1.1576, 'grad_norm': 1.3050636053085327, 'learning_rate': 2.0076272921447923e-08, 'epoch': 0.91}
{'loss': 1.141, 'grad_norm': 1.7535815238952637, 'learning_rate': 1.9592797469190568e-08, 'epoch': 0.91}
{'loss': 1.1632, 'grad_norm': 1.3407248258590698, 'learning_rate': 1.9115098352631864e-08, 'epoch': 0.92}
{'loss': 1.1323, 'grad_norm': 1.3338322639465332, 'learning_rate': 1.8643181315545986e-08, 'epoch': 0.92}
{'loss': 1.1184, 'grad_norm': 1.596706509590149, 'learning_rate': 1.8177052032184282e-08, 'epoch': 0.92}
{'loss': 1.1176, 'grad_norm': 1.410821795463562, 'learning_rate': 1.771671610720715e-08, 'epoch': 0.92}
{'loss': 1.1239, 'grad_norm': 1.43938410282135, 'learning_rate': 1.7262179075616613e-08, 'epoch': 0.92}
{'loss': 1.1846, 'grad_norm': 1.576542615890503, 'learning_rate': 1.681344640268978e-08, 'epoch': 0.92}
{'loss': 1.0617, 'grad_norm': 17.089923858642578, 'learning_rate': 1.63705234839131e-08, 'epoch': 0.92}
{'loss': 1.1374, 'grad_norm': 17.128833770751953, 'learning_rate': 1.5933415644917513e-08, 'epoch': 0.92}
{'loss': 1.0938, 'grad_norm': 1.3927884101867676, 'learning_rate': 1.5502128141414493e-08, 'epoch': 0.92}
{'loss': 1.1545, 'grad_norm': 1.5494717359542847, 'learning_rate': 1.5076666159132612e-08, 'epoch': 0.93}
{'loss': 1.1481, 'grad_norm': 1.3403972387313843, 'learning_rate': 1.465703481375552e-08, 'epoch': 0.93}
{'loss': 1.1771, 'grad_norm': 1.319628119468689, 'learning_rate': 1.424323915086012e-08, 'epoch': 0.93}
{'loss': 1.1237, 'grad_norm': 13.542691230773926, 'learning_rate': 1.3835284145856273e-08, 'epoch': 0.93}
{'loss': 1.1243, 'grad_norm': 1.3755782842636108, 'learning_rate': 1.343317470392641e-08, 'epoch': 0.93}
{'loss': 1.1046, 'grad_norm': 1.3727140426635742, 'learning_rate': 1.3036915659967118e-08, 'epoch': 0.93}
{'loss': 1.0935, 'grad_norm': 1.3116097450256348, 'learning_rate': 1.2646511778530822e-08, 'epoch': 0.93}
{'loss': 1.1183, 'grad_norm': 1.335410714149475, 'learning_rate': 1.226196775376831e-08, 'epoch': 0.93}
{'loss': 1.056, 'grad_norm': 1.396047830581665, 'learning_rate': 1.1883288209372511e-08, 'epoch': 0.93}
{'loss': 1.0745, 'grad_norm': 1.2773590087890625, 'learning_rate': 1.1510477698522813e-08, 'epoch': 0.93}
{'loss': 1.1476, 'grad_norm': 1.3885935544967651, 'learning_rate': 1.1143540703830334e-08, 'epoch': 0.94}
{'loss': 1.1738, 'grad_norm': 1.386331558227539, 'learning_rate': 1.0782481637284013e-08, 'epoch': 0.94}
{'loss': 1.1297, 'grad_norm': 1.3579025268554688, 'learning_rate': 1.0427304840197493e-08, 'epoch': 0.94}
{'loss': 1.0886, 'grad_norm': 1.3815838098526, 'learning_rate': 1.0078014583157157e-08, 'epoch': 0.94}
{'loss': 1.1334, 'grad_norm': 20.261661529541016, 'learning_rate': 9.734615065970454e-09, 'epoch': 0.94}
{'loss': 1.1186, 'grad_norm': 1.4909896850585938, 'learning_rate': 9.397110417615706e-09, 'epoch': 0.94}
{'loss': 1.0339, 'grad_norm': 1.3418941497802734, 'learning_rate': 9.065504696192161e-09, 'epoch': 0.94}
{'loss': 1.1824, 'grad_norm': 1.335298776626587, 'learning_rate': 8.739801888871468e-09, 'epoch': 0.94}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-900/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-900/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-900/model.safetensors.index.json.
2024-11-20 23:02:14,999 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-900/pytorch_model_fsdp.bin
2024-11-20 23:02:54,834 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-900/pytorch_model_fsdp.bin
2024-11-20 23:03:26,769 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-900/optimizer.bin
2024-11-20 23:04:48,532 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-900/optimizer.bin
                                                                                                                    
{'loss': 1.1353, 'grad_norm': 1.290410041809082, 'learning_rate': 8.420005911849659e-09, 'epoch': 0.94}
{'loss': 1.1325, 'grad_norm': 1.3120428323745728, 'learning_rate': 8.106120610299916e-09, 'epoch': 0.95}
{'loss': 1.1097, 'grad_norm': 1.3159459829330444, 'learning_rate': 7.798149758326488e-09, 'epoch': 0.95}
{'loss': 1.2362, 'grad_norm': 1.4550142288208008, 'learning_rate': 7.496097058919348e-09, 'epoch': 0.95}
{'loss': 1.1045, 'grad_norm': 1.3108980655670166, 'learning_rate': 7.199966143909553e-09, 'epoch': 0.95}
{'loss': 1.1042, 'grad_norm': 1.4445672035217285, 'learning_rate': 6.909760573925561e-09, 'epoch': 0.95}
{'loss': 1.1083, 'grad_norm': 1.2672899961471558, 'learning_rate': 6.625483838350487e-09, 'epoch': 0.95}
{'loss': 1.1402, 'grad_norm': 1.309455394744873, 'learning_rate': 6.34713935528014e-09, 'epoch': 0.95}
{'loss': 1.1414, 'grad_norm': 1.3917733430862427, 'learning_rate': 6.074730471482048e-09, 'epoch': 0.95}
{'loss': 1.0501, 'grad_norm': 1.3689353466033936, 'learning_rate': 5.8082604623548855e-09, 'epoch': 0.95}
{'loss': 1.1829, 'grad_norm': 32.044490814208984, 'learning_rate': 5.547732531889448e-09, 'epoch': 0.95}
{'loss': 1.1803, 'grad_norm': 1.4355942010879517, 'learning_rate': 5.293149812629849e-09, 'epoch': 0.96}
{'loss': 1.1148, 'grad_norm': 21.09372329711914, 'learning_rate': 5.04451536563616e-09, 'epoch': 0.96}
{'loss': 1.1765, 'grad_norm': 1.3486188650131226, 'learning_rate': 4.801832180447163e-09, 'epoch': 0.96}
{'loss': 1.1409, 'grad_norm': 9.964409828186035, 'learning_rate': 4.565103175044882e-09, 'epoch': 0.96}
{'loss': 1.0927, 'grad_norm': 1.3266844749450684, 'learning_rate': 4.334331195819219e-09, 'epoch': 0.96}
{'loss': 1.1104, 'grad_norm': 11.153730392456055, 'learning_rate': 4.109519017533758e-09, 'epoch': 0.96}
{'loss': 1.135, 'grad_norm': 1.599989414215088, 'learning_rate': 3.890669343292463e-09, 'epoch': 0.96}
{'loss': 1.2012, 'grad_norm': 13.123199462890625, 'learning_rate': 3.6777848045071446e-09, 'epoch': 0.96}
{'loss': 1.129, 'grad_norm': 9.60202693939209, 'learning_rate': 3.47086796086582e-09, 'epoch': 0.96}
{'loss': 1.0986, 'grad_norm': 8.700210571289062, 'learning_rate': 3.2699213003019588e-09, 'epoch': 0.97}
{'loss': 1.103, 'grad_norm': 1.3558803796768188, 'learning_rate': 3.0749472389644535e-09, 'epoch': 0.97}
{'loss': 1.1711, 'grad_norm': 13.457603454589844, 'learning_rate': 2.8859481211888635e-09, 'epoch': 0.97}
{'loss': 1.2614, 'grad_norm': 10.925788879394531, 'learning_rate': 2.702926219468882e-09, 'epoch': 0.97}
{'loss': 1.1012, 'grad_norm': 1.3278141021728516, 'learning_rate': 2.525883734429135e-09, 'epoch': 0.97}
{'loss': 1.1377, 'grad_norm': 1.4205281734466553, 'learning_rate': 2.3548227947988165e-09, 'epoch': 0.97}
{'loss': 1.114, 'grad_norm': 11.858240127563477, 'learning_rate': 2.1897454573860384e-09, 'epoch': 0.97}
{'loss': 1.0568, 'grad_norm': 1.3532087802886963, 'learning_rate': 2.030653707052965e-09, 'epoch': 0.97}
{'loss': 1.2169, 'grad_norm': 1.4191007614135742, 'learning_rate': 1.8775494566921623e-09, 'epoch': 0.97}
{'loss': 1.0762, 'grad_norm': 1.8706145286560059, 'learning_rate': 1.7304345472035631e-09, 'epoch': 0.97}
{'loss': 1.1677, 'grad_norm': 17.70821189880371, 'learning_rate': 1.5893107474720947e-09, 'epoch': 0.98}
{'loss': 1.1372, 'grad_norm': 1.3440889120101929, 'learning_rate': 1.454179754346696e-09, 'epoch': 0.98}
{'loss': 1.174, 'grad_norm': 21.911069869995117, 'learning_rate': 1.3250431926197792e-09, 'epoch': 0.98}
{'loss': 1.1035, 'grad_norm': 1.373407244682312, 'learning_rate': 1.2019026150077438e-09, 'epoch': 0.98}
{'loss': 1.122, 'grad_norm': 1.3111521005630493, 'learning_rate': 1.084759502132271e-09, 'epoch': 0.98}
{'loss': 1.1174, 'grad_norm': 1.3239606618881226, 'learning_rate': 9.73615262502503e-10, 'epoch': 0.98}
{'loss': 1.0725, 'grad_norm': 1.3363744020462036, 'learning_rate': 8.684712324981136e-10, 'epoch': 0.98}
{'loss': 1.1493, 'grad_norm': 1.3586132526397705, 'learning_rate': 7.693286763533757e-10, 'epoch': 0.98}
{'loss': 1.0927, 'grad_norm': 21.337709426879883, 'learning_rate': 6.761887861417293e-10, 'epoch': 0.98}
{'loss': 1.0966, 'grad_norm': 15.838946342468262, 'learning_rate': 5.89052681761626e-10, 'epoch': 0.98}
{'loss': 1.1439, 'grad_norm': 1.373895287513733, 'learning_rate': 5.079214109229291e-10, 'epoch': 0.99}
{'loss': 1.1138, 'grad_norm': 1.934661626815796, 'learning_rate': 4.3279594913447904e-10, 'epoch': 0.99}
{'loss': 1.1044, 'grad_norm': 1.5902224779129028, 'learning_rate': 3.636771996922694e-10, 'epoch': 0.99}
{'loss': 1.0689, 'grad_norm': 1.3584431409835815, 'learning_rate': 3.005659936685112e-10, 'epoch': 0.99}
{'loss': 1.1326, 'grad_norm': 1.465746283531189, 'learning_rate': 2.43463089901752e-10, 'epoch': 0.99}
{'loss': 1.0525, 'grad_norm': 1.400762677192688, 'learning_rate': 1.9236917498782757e-10, 'epoch': 0.99}
{'loss': 1.0992, 'grad_norm': 37.20497131347656, 'learning_rate': 1.4728486327136857e-10, 'epoch': 0.99}
{'loss': 1.1764, 'grad_norm': 11.596226692199707, 'learning_rate': 1.0821069683852879e-10, 'epoch': 0.99}
{'loss': 1.1268, 'grad_norm': 1.4588227272033691, 'learning_rate': 7.514714551060119e-11, 'epoch': 0.99}
{'loss': 1.0463, 'grad_norm': 1.3691482543945312, 'learning_rate': 4.8094606838189335e-11, 'epoch': 1.0}
{'loss': 1.1276, 'grad_norm': 1.3078944683074951, 'learning_rate': 2.7053406096433363e-11, 'epoch': 1.0}
{'loss': 1.1559, 'grad_norm': 1.5208193063735962, 'learning_rate': 1.2023796281235288e-11, 'epoch': 1.0}
{'loss': 1.1445, 'grad_norm': 1.4264744520187378, 'learning_rate': 3.0059581060948303e-12, 'epoch': 1.0}
{'loss': 1.116, 'grad_norm': 1.39313542842865, 'learning_rate': 0.0, 'epoch': 1.0}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-954/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-954/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-954/model.safetensors.index.json.
2024-11-20 23:14:00,727 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-954/pytorch_model_fsdp.bin
2024-11-20 23:14:43,077 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-954/pytorch_model_fsdp.bin
2024-11-20 23:15:15,496 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-954/optimizer.bin
2024-11-20 23:16:40,435 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-954/optimizer.bin


Training completed. Do not forget to share your model on huggingface.co/models =)


100%|███████████████████████████████████████████████████████████████████████████| 954/954 [2:52:07<00:00, 10.83s/it]
{'train_runtime': 10329.12, 'train_samples_per_second': 2.957, 'train_steps_per_second': 0.092, 'train_loss': 1.1643517428474106, 'epoch': 1.0}
Saving model checkpoint to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_augmenteddatalr5e06rt1rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/model.safetensors.index.json.
