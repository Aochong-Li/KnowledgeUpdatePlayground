                                                                                                             
{'loss': 1.6659, 'grad_norm': 85.30655670166016, 'learning_rate': 2.083333333333333e-08, 'epoch': 0.0}
{'loss': 1.5716, 'grad_norm': 103.51853942871094, 'learning_rate': 4.166666666666666e-08, 'epoch': 0.0}
{'loss': 1.5701, 'grad_norm': 1536.354248046875, 'learning_rate': 6.25e-08, 'epoch': 0.0}
{'loss': 1.6898, 'grad_norm': 217659.3125, 'learning_rate': 8.333333333333333e-08, 'epoch': 0.0}
{'loss': 1.6347, 'grad_norm': 97.93560791015625, 'learning_rate': 1.0416666666666667e-07, 'epoch': 0.01}
{'loss': 1.6085, 'grad_norm': 79.5030517578125, 'learning_rate': 1.25e-07, 'epoch': 0.01}
{'loss': 1.5878, 'grad_norm': 3653.94970703125, 'learning_rate': 1.4583333333333335e-07, 'epoch': 0.01}
{'loss': 1.6409, 'grad_norm': 11646.72265625, 'learning_rate': 1.6666666666666665e-07, 'epoch': 0.01}
{'loss': 1.5865, 'grad_norm': 27.95757484436035, 'learning_rate': 1.875e-07, 'epoch': 0.01}
{'loss': 1.5661, 'grad_norm': 37.376953125, 'learning_rate': 2.0833333333333333e-07, 'epoch': 0.01}
{'loss': 1.4552, 'grad_norm': 75.16353607177734, 'learning_rate': 2.2916666666666663e-07, 'epoch': 0.01}
{'loss': 1.5809, 'grad_norm': 29.42692756652832, 'learning_rate': 2.5e-07, 'epoch': 0.01}
{'loss': 1.5586, 'grad_norm': 16.993408203125, 'learning_rate': 2.708333333333333e-07, 'epoch': 0.01}
{'loss': 1.4617, 'grad_norm': 24.645570755004883, 'learning_rate': 2.916666666666667e-07, 'epoch': 0.01}
{'loss': 1.5787, 'grad_norm': 4208.29296875, 'learning_rate': 3.1249999999999997e-07, 'epoch': 0.02}
{'loss': 1.4738, 'grad_norm': 22.012100219726562, 'learning_rate': 3.333333333333333e-07, 'epoch': 0.02}
{'loss': 1.4979, 'grad_norm': 10.789627075195312, 'learning_rate': 3.541666666666667e-07, 'epoch': 0.02}
{'loss': 1.4439, 'grad_norm': 7.108758926391602, 'learning_rate': 3.75e-07, 'epoch': 0.02}
{'loss': 1.5151, 'grad_norm': 11.604257583618164, 'learning_rate': 3.958333333333333e-07, 'epoch': 0.02}
{'loss': 1.5181, 'grad_norm': 5833.91650390625, 'learning_rate': 4.1666666666666667e-07, 'epoch': 0.02}
{'loss': 1.4388, 'grad_norm': 3.836153507232666, 'learning_rate': 4.375e-07, 'epoch': 0.02}
{'loss': 1.4379, 'grad_norm': 7.244412899017334, 'learning_rate': 4.5833333333333327e-07, 'epoch': 0.02}
{'loss': 1.4728, 'grad_norm': 50.984161376953125, 'learning_rate': 4.791666666666667e-07, 'epoch': 0.02}
{'loss': 1.4379, 'grad_norm': 34.107872009277344, 'learning_rate': 5e-07, 'epoch': 0.03}
{'loss': 1.4514, 'grad_norm': 495.6149597167969, 'learning_rate': 5.208333333333334e-07, 'epoch': 0.03}
{'loss': 1.3912, 'grad_norm': 4.806981563568115, 'learning_rate': 5.416666666666666e-07, 'epoch': 0.03}
{'loss': 1.3505, 'grad_norm': 5.142391204833984, 'learning_rate': 5.625e-07, 'epoch': 0.03}
{'loss': 1.3516, 'grad_norm': 5.543071746826172, 'learning_rate': 5.833333333333334e-07, 'epoch': 0.03}
{'loss': 1.3725, 'grad_norm': 9.860508918762207, 'learning_rate': 6.041666666666666e-07, 'epoch': 0.03}
{'loss': 1.4454, 'grad_norm': 5.167320728302002, 'learning_rate': 6.249999999999999e-07, 'epoch': 0.03}
{'loss': 1.4137, 'grad_norm': 6.808635711669922, 'learning_rate': 6.458333333333333e-07, 'epoch': 0.03}
{'loss': 1.3779, 'grad_norm': 5.755448341369629, 'learning_rate': 6.666666666666666e-07, 'epoch': 0.03}
{'loss': 1.3324, 'grad_norm': 3.059691905975342, 'learning_rate': 6.875e-07, 'epoch': 0.03}
{'loss': 1.3733, 'grad_norm': 2.511601448059082, 'learning_rate': 7.083333333333334e-07, 'epoch': 0.04}
{'loss': 1.2764, 'grad_norm': 2.6090691089630127, 'learning_rate': 7.291666666666666e-07, 'epoch': 0.04}
{'loss': 1.4186, 'grad_norm': 2.6481332778930664, 'learning_rate': 7.5e-07, 'epoch': 0.04}
{'loss': 1.3298, 'grad_norm': 3830.4580078125, 'learning_rate': 7.708333333333333e-07, 'epoch': 0.04}
{'loss': 1.3846, 'grad_norm': 2.603106737136841, 'learning_rate': 7.916666666666666e-07, 'epoch': 0.04}
{'loss': 1.399, 'grad_norm': 3.8722686767578125, 'learning_rate': 8.125e-07, 'epoch': 0.04}
{'loss': 1.2576, 'grad_norm': 3.0234787464141846, 'learning_rate': 8.333333333333333e-07, 'epoch': 0.04}
{'loss': 1.3374, 'grad_norm': 2.870999813079834, 'learning_rate': 8.541666666666666e-07, 'epoch': 0.04}
{'loss': 1.3794, 'grad_norm': 3.7443642616271973, 'learning_rate': 8.75e-07, 'epoch': 0.04}
{'loss': 1.3768, 'grad_norm': 3.3485636711120605, 'learning_rate': 8.958333333333334e-07, 'epoch': 0.05}
{'loss': 1.2384, 'grad_norm': 418.6193542480469, 'learning_rate': 9.166666666666665e-07, 'epoch': 0.05}
{'loss': 1.2761, 'grad_norm': 2.0317444801330566, 'learning_rate': 9.374999999999999e-07, 'epoch': 0.05}
{'loss': 1.3728, 'grad_norm': 1853.852294921875, 'learning_rate': 9.583333333333334e-07, 'epoch': 0.05}
{'loss': 1.192, 'grad_norm': 3.3510422706604004, 'learning_rate': 9.791666666666667e-07, 'epoch': 0.05}
{'loss': 1.396, 'grad_norm': 470.43609619140625, 'learning_rate': 1e-06, 'epoch': 0.05}
{'loss': 1.2338, 'grad_norm': 2.5518834590911865, 'learning_rate': 9.999969940418939e-07, 'epoch': 0.05}
{'loss': 1.2876, 'grad_norm': 23.71660614013672, 'learning_rate': 9.999879762037186e-07, 'epoch': 0.05}
{'loss': 1.2212, 'grad_norm': 2.318174123764038, 'learning_rate': 9.999729465939036e-07, 'epoch': 0.05}
{'loss': 1.278, 'grad_norm': 2.8522961139678955, 'learning_rate': 9.999519053931619e-07, 'epoch': 0.05}
{'loss': 1.316, 'grad_norm': 417.56439208984375, 'learning_rate': 9.999248528544893e-07, 'epoch': 0.06}
{'loss': 1.3298, 'grad_norm': 276.2769775390625, 'learning_rate': 9.998917893031615e-07, 'epoch': 0.06}
{'loss': 1.3711, 'grad_norm': 2.796945333480835, 'learning_rate': 9.998527151367287e-07, 'epoch': 0.06}
{'loss': 1.2482, 'grad_norm': 2.989373207092285, 'learning_rate': 9.99807630825012e-07, 'epoch': 0.06}
{'loss': 1.3037, 'grad_norm': 1.988405466079712, 'learning_rate': 9.997565369100982e-07, 'epoch': 0.06}
{'loss': 1.2252, 'grad_norm': 2.0469918251037598, 'learning_rate': 9.996994340063314e-07, 'epoch': 0.06}
{'loss': 1.2675, 'grad_norm': 2.40921950340271, 'learning_rate': 9.996363228003078e-07, 'epoch': 0.06}
{'loss': 1.282, 'grad_norm': 2.4588358402252197, 'learning_rate': 9.995672040508656e-07, 'epoch': 0.06}
{'loss': 1.2686, 'grad_norm': 2.4966561794281006, 'learning_rate': 9.99492078589077e-07, 'epoch': 0.06}
{'loss': 1.3726, 'grad_norm': 4.230606555938721, 'learning_rate': 9.994109473182385e-07, 'epoch': 0.06}
{'loss': 1.2632, 'grad_norm': 2.252743721008301, 'learning_rate': 9.993238112138582e-07, 'epoch': 0.07}
{'loss': 1.2901, 'grad_norm': 2.8456523418426514, 'learning_rate': 9.992306713236465e-07, 'epoch': 0.07}
{'loss': 1.221, 'grad_norm': 1.9100542068481445, 'learning_rate': 9.991315287675018e-07, 'epoch': 0.07}
{'loss': 1.2793, 'grad_norm': 3.821643829345703, 'learning_rate': 9.990263847374975e-07, 'epoch': 0.07}
{'loss': 1.2447, 'grad_norm': 3.035454511642456, 'learning_rate': 9.989152404978676e-07, 'epoch': 0.07}
{'loss': 1.2725, 'grad_norm': 2.456754446029663, 'learning_rate': 9.987980973849922e-07, 'epoch': 0.07}
{'loss': 1.2366, 'grad_norm': 2.332728862762451, 'learning_rate': 9.986749568073802e-07, 'epoch': 0.07}
{'loss': 1.2723, 'grad_norm': 3.9372003078460693, 'learning_rate': 9.985458202456534e-07, 'epoch': 0.07}
{'loss': 1.2405, 'grad_norm': 2.3239376544952393, 'learning_rate': 9.98410689252528e-07, 'epoch': 0.07}
{'loss': 1.2354, 'grad_norm': 1.8698511123657227, 'learning_rate': 9.982695654527964e-07, 'epoch': 0.08}
{'loss': 1.2577, 'grad_norm': 4.114017486572266, 'learning_rate': 9.981224505433078e-07, 'epoch': 0.08}
{'loss': 1.3038, 'grad_norm': 2.2195987701416016, 'learning_rate': 9.97969346292947e-07, 'epoch': 0.08}
{'loss': 1.276, 'grad_norm': 1.8387116193771362, 'learning_rate': 9.978102545426139e-07, 'epoch': 0.08}
{'loss': 1.3084, 'grad_norm': 2.007768154144287, 'learning_rate': 9.976451772052012e-07, 'epoch': 0.08}
{'loss': 1.2218, 'grad_norm': 1.875706672668457, 'learning_rate': 9.97474116265571e-07, 'epoch': 0.08}
{'loss': 1.1779, 'grad_norm': 8.753095626831055, 'learning_rate': 9.972970737805312e-07, 'epoch': 0.08}
{'loss': 1.2997, 'grad_norm': 2.008690357208252, 'learning_rate': 9.97114051878811e-07, 'epoch': 0.08}
{'loss': 1.2727, 'grad_norm': 2.002990245819092, 'learning_rate': 9.969250527610354e-07, 'epoch': 0.08}
{'loss': 1.2952, 'grad_norm': 1.9467016458511353, 'learning_rate': 9.967300786996979e-07, 'epoch': 0.08}
{'loss': 1.2126, 'grad_norm': 4.032817363739014, 'learning_rate': 9.96529132039134e-07, 'epoch': 0.09}
{'loss': 1.2406, 'grad_norm': 1.9567718505859375, 'learning_rate': 9.963222151954928e-07, 'epoch': 0.09}
{'loss': 1.2172, 'grad_norm': 2.039372444152832, 'learning_rate': 9.961093306567074e-07, 'epoch': 0.09}
{'loss': 1.2513, 'grad_norm': 1.8740214109420776, 'learning_rate': 9.958904809824662e-07, 'epoch': 0.09}
{'loss': 1.2289, 'grad_norm': 17.15371322631836, 'learning_rate': 9.956656688041807e-07, 'epoch': 0.09}
{'loss': 1.2775, 'grad_norm': 6.530374050140381, 'learning_rate': 9.95434896824955e-07, 'epoch': 0.09}
{'loss': 1.1971, 'grad_norm': 2.0388972759246826, 'learning_rate': 9.951981678195527e-07, 'epoch': 0.09}
{'loss': 1.2899, 'grad_norm': 2.5200400352478027, 'learning_rate': 9.949554846343638e-07, 'epoch': 0.09}
{'loss': 1.2378, 'grad_norm': 1.975885033607483, 'learning_rate': 9.9470685018737e-07, 'epoch': 0.09}
{'loss': 1.2495, 'grad_norm': 2.4269399642944336, 'learning_rate': 9.944522674681106e-07, 'epoch': 0.1}
{'loss': 1.2072, 'grad_norm': 1.8848397731781006, 'learning_rate': 9.941917395376452e-07, 'epoch': 0.1}
{'loss': 1.257, 'grad_norm': 1.9981180429458618, 'learning_rate': 9.93925269528518e-07, 'epoch': 0.1}
{'loss': 1.1679, 'grad_norm': 4.255380153656006, 'learning_rate': 9.936528606447198e-07, 'epoch': 0.1}
{'loss': 1.2232, 'grad_norm': 2.3596489429473877, 'learning_rate': 9.933745161616497e-07, 'epoch': 0.1}
{'loss': 1.2444, 'grad_norm': 2.5802159309387207, 'learning_rate': 9.930902394260744e-07, 'epoch': 0.1}
{'loss': 1.1951, 'grad_norm': 1.925478458404541, 'learning_rate': 9.928000338560905e-07, 'epoch': 0.1}
{'loss': 1.2865, 'grad_norm': 2.1556036472320557, 'learning_rate': 9.925039029410805e-07, 'epoch': 0.1}
{'loss': 1.1506, 'grad_norm': 2.237229347229004, 'learning_rate': 9.922018502416735e-07, 'epoch': 0.1}
{'loss': 1.2272, 'grad_norm': 2.095700263977051, 'learning_rate': 9.918938793897e-07, 'epoch': 0.1}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-100/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-100/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-100/model.safetensors.index.json.
2024-11-30 19:37:02,457 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-100/pytorch_model_fsdp.bin
2024-11-30 19:37:42,791 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-100/pytorch_model_fsdp.bin
2024-11-30 19:38:10,293 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-100/optimizer.bin
2024-11-30 19:39:34,731 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-100/optimizer.bin
                                                                                                             
{'loss': 1.3047, 'grad_norm': 2.0873796939849854, 'learning_rate': 9.915799940881503e-07, 'epoch': 0.11}
{'loss': 1.2363, 'grad_norm': 2.2337732315063477, 'learning_rate': 9.912601981111286e-07, 'epoch': 0.11}
{'loss': 1.1933, 'grad_norm': 2.0910837650299072, 'learning_rate': 9.909344953038078e-07, 'epoch': 0.11}
{'loss': 1.1956, 'grad_norm': 2.151113986968994, 'learning_rate': 9.906028895823842e-07, 'epoch': 0.11}
{'loss': 1.2211, 'grad_norm': 1.8830549716949463, 'learning_rate': 9.902653849340294e-07, 'epoch': 0.11}
{'loss': 1.2723, 'grad_norm': 15.322933197021484, 'learning_rate': 9.899219854168428e-07, 'epoch': 0.11}
{'loss': 1.2563, 'grad_norm': 7.670990943908691, 'learning_rate': 9.895726951598025e-07, 'epoch': 0.11}
{'loss': 1.2398, 'grad_norm': 12.257128715515137, 'learning_rate': 9.89217518362716e-07, 'epoch': 0.11}
{'loss': 1.2158, 'grad_norm': 1.9806984663009644, 'learning_rate': 9.888564592961696e-07, 'epoch': 0.11}
{'loss': 1.1828, 'grad_norm': 2.264282703399658, 'learning_rate': 9.88489522301477e-07, 'epoch': 0.12}
{'loss': 1.227, 'grad_norm': 2.118922233581543, 'learning_rate': 9.881167117906274e-07, 'epoch': 0.12}
{'loss': 1.069, 'grad_norm': 1.867411732673645, 'learning_rate': 9.877380322462316e-07, 'epoch': 0.12}
{'loss': 1.2375, 'grad_norm': 1.86214280128479, 'learning_rate': 9.873534882214692e-07, 'epoch': 0.12}
{'loss': 1.2271, 'grad_norm': 2.6345572471618652, 'learning_rate': 9.869630843400329e-07, 'epoch': 0.12}
{'loss': 1.1754, 'grad_norm': 2.7206568717956543, 'learning_rate': 9.865668252960736e-07, 'epoch': 0.12}
{'loss': 1.1989, 'grad_norm': 2.0289034843444824, 'learning_rate': 9.861647158541438e-07, 'epoch': 0.12}
{'loss': 1.215, 'grad_norm': 1.9104117155075073, 'learning_rate': 9.857567608491397e-07, 'epoch': 0.12}
{'loss': 1.2389, 'grad_norm': 1.8716895580291748, 'learning_rate': 9.853429651862444e-07, 'epoch': 0.12}
{'loss': 1.2428, 'grad_norm': 2.040325164794922, 'learning_rate': 9.849233338408673e-07, 'epoch': 0.12}
{'loss': 1.1629, 'grad_norm': 1.931717872619629, 'learning_rate': 9.844978718585855e-07, 'epoch': 0.13}
{'loss': 1.1226, 'grad_norm': 3.0637946128845215, 'learning_rate': 9.840665843550823e-07, 'epoch': 0.13}
{'loss': 1.2978, 'grad_norm': 1.9328049421310425, 'learning_rate': 9.836294765160868e-07, 'epoch': 0.13}
{'loss': 1.2305, 'grad_norm': 1.8599233627319336, 'learning_rate': 9.831865535973103e-07, 'epoch': 0.13}
{'loss': 1.2229, 'grad_norm': 1.9146034717559814, 'learning_rate': 9.827378209243833e-07, 'epoch': 0.13}
{'loss': 1.3021, 'grad_norm': 5.9183173179626465, 'learning_rate': 9.822832838927928e-07, 'epoch': 0.13}
{'loss': 1.2117, 'grad_norm': 1.8743510246276855, 'learning_rate': 9.818229479678158e-07, 'epoch': 0.13}
{'loss': 1.1428, 'grad_norm': 2.1413774490356445, 'learning_rate': 9.81356818684454e-07, 'epoch': 0.13}
{'loss': 1.2353, 'grad_norm': 2.2307612895965576, 'learning_rate': 9.808849016473682e-07, 'epoch': 0.13}
{'loss': 1.274, 'grad_norm': 1.9566396474838257, 'learning_rate': 9.804072025308095e-07, 'epoch': 0.14}
{'loss': 1.2218, 'grad_norm': 24.080373764038086, 'learning_rate': 9.79923727078552e-07, 'epoch': 0.14}
{'loss': 1.1386, 'grad_norm': 1.9479026794433594, 'learning_rate': 9.794344811038237e-07, 'epoch': 0.14}
{'loss': 1.2751, 'grad_norm': 2.299137830734253, 'learning_rate': 9.789394704892364e-07, 'epoch': 0.14}
{'loss': 1.2043, 'grad_norm': 2.688598394393921, 'learning_rate': 9.784387011867143e-07, 'epoch': 0.14}
{'loss': 1.2115, 'grad_norm': 2.1288554668426514, 'learning_rate': 9.779321792174238e-07, 'epoch': 0.14}
{'loss': 1.1841, 'grad_norm': 1.972832441329956, 'learning_rate': 9.774199106717003e-07, 'epoch': 0.14}
{'loss': 1.1786, 'grad_norm': 2.17844557762146, 'learning_rate': 9.769019017089748e-07, 'epoch': 0.14}
{'loss': 1.3011, 'grad_norm': 2.340787887573242, 'learning_rate': 9.763781585577003e-07, 'epoch': 0.14}
{'loss': 1.2234, 'grad_norm': 1.9601281881332397, 'learning_rate': 9.758486875152766e-07, 'epoch': 0.14}
{'loss': 1.181, 'grad_norm': 2.0288195610046387, 'learning_rate': 9.75313494947975e-07, 'epoch': 0.15}
{'loss': 1.1896, 'grad_norm': 3.1153643131256104, 'learning_rate': 9.747725872908607e-07, 'epoch': 0.15}
{'loss': 1.2148, 'grad_norm': 2.0069639682769775, 'learning_rate': 9.742259710477176e-07, 'epoch': 0.15}
{'loss': 1.1948, 'grad_norm': 1.9162333011627197, 'learning_rate': 9.736736527909672e-07, 'epoch': 0.15}
{'loss': 1.2983, 'grad_norm': 17.11995506286621, 'learning_rate': 9.731156391615918e-07, 'epoch': 0.15}
{'loss': 1.1667, 'grad_norm': 8.180314064025879, 'learning_rate': 9.725519368690538e-07, 'epoch': 0.15}
{'loss': 1.2724, 'grad_norm': 3.33150315284729, 'learning_rate': 9.71982552691215e-07, 'epoch': 0.15}
{'loss': 1.141, 'grad_norm': 4.757267475128174, 'learning_rate': 9.714074934742555e-07, 'epoch': 0.15}
{'loss': 1.2639, 'grad_norm': 2.040346622467041, 'learning_rate': 9.70826766132591e-07, 'epoch': 0.15}
{'loss': 1.2018, 'grad_norm': 2.0992372035980225, 'learning_rate': 9.702403776487894e-07, 'epoch': 0.16}
{'loss': 1.273, 'grad_norm': 2.055579662322998, 'learning_rate': 9.696483350734878e-07, 'epoch': 0.16}
{'loss': 1.175, 'grad_norm': 1.9023743867874146, 'learning_rate': 9.690506455253071e-07, 'epoch': 0.16}
{'loss': 1.186, 'grad_norm': 1.9875985383987427, 'learning_rate': 9.684473161907658e-07, 'epoch': 0.16}
{'loss': 1.2226, 'grad_norm': 1.8815207481384277, 'learning_rate': 9.678383543241952e-07, 'epoch': 0.16}
{'loss': 1.2519, 'grad_norm': 2.032900333404541, 'learning_rate': 9.672237672476504e-07, 'epoch': 0.16}
{'loss': 1.2438, 'grad_norm': 2.117607593536377, 'learning_rate': 9.666035623508237e-07, 'epoch': 0.16}
{'loss': 1.2184, 'grad_norm': 8.109907150268555, 'learning_rate': 9.659777470909544e-07, 'epoch': 0.16}
{'loss': 1.1952, 'grad_norm': 2.109189510345459, 'learning_rate': 9.653463289927408e-07, 'epoch': 0.16}
{'loss': 1.1897, 'grad_norm': 4.175631999969482, 'learning_rate': 9.647093156482481e-07, 'epoch': 0.16}
{'loss': 1.1666, 'grad_norm': 3.10868501663208, 'learning_rate': 9.640667147168181e-07, 'epoch': 0.17}
{'loss': 1.1966, 'grad_norm': 1.8446379899978638, 'learning_rate': 9.634185339249764e-07, 'epoch': 0.17}
{'loss': 1.2056, 'grad_norm': 1.973790168762207, 'learning_rate': 9.627647810663406e-07, 'epoch': 0.17}
{'loss': 1.2363, 'grad_norm': 2.606402635574341, 'learning_rate': 9.621054640015253e-07, 'epoch': 0.17}
{'loss': 1.1951, 'grad_norm': 1.8710156679153442, 'learning_rate': 9.614405906580485e-07, 'epoch': 0.17}
{'loss': 1.2521, 'grad_norm': 1.996944785118103, 'learning_rate': 9.60770169030236e-07, 'epoch': 0.17}
{'loss': 1.134, 'grad_norm': 4.67655086517334, 'learning_rate': 9.600942071791248e-07, 'epoch': 0.17}
{'loss': 1.1647, 'grad_norm': 5.578188896179199, 'learning_rate': 9.59412713232367e-07, 'epoch': 0.17}
{'loss': 1.1559, 'grad_norm': 2.9081871509552, 'learning_rate': 9.587256953841315e-07, 'epoch': 0.17}
{'loss': 1.1948, 'grad_norm': 2.115401029586792, 'learning_rate': 9.580331618950062e-07, 'epoch': 0.17}
{'loss': 1.1224, 'grad_norm': 1.8889013528823853, 'learning_rate': 9.573351210918973e-07, 'epoch': 0.18}
{'loss': 1.2196, 'grad_norm': 1.964048147201538, 'learning_rate': 9.56631581367931e-07, 'epoch': 0.18}
{'loss': 1.2501, 'grad_norm': 2.1663036346435547, 'learning_rate': 9.559225511823503e-07, 'epoch': 0.18}
{'loss': 1.2069, 'grad_norm': 3.3813183307647705, 'learning_rate': 9.552080390604157e-07, 'epoch': 0.18}
{'loss': 1.2517, 'grad_norm': 1.9540553092956543, 'learning_rate': 9.544880535933014e-07, 'epoch': 0.18}
{'loss': 1.208, 'grad_norm': 2.613576650619507, 'learning_rate': 9.537626034379917e-07, 'epoch': 0.18}
{'loss': 1.227, 'grad_norm': 2.1765940189361572, 'learning_rate': 9.53031697317178e-07, 'epoch': 0.18}
{'loss': 1.1534, 'grad_norm': 1.8834965229034424, 'learning_rate': 9.522953440191527e-07, 'epoch': 0.18}
{'loss': 1.2576, 'grad_norm': 2.0959231853485107, 'learning_rate': 9.515535523977046e-07, 'epoch': 0.18}
{'loss': 1.2042, 'grad_norm': 1.8712613582611084, 'learning_rate': 9.508063313720118e-07, 'epoch': 0.19}
{'loss': 1.1457, 'grad_norm': 1.8584213256835938, 'learning_rate': 9.500536899265348e-07, 'epoch': 0.19}
{'loss': 1.269, 'grad_norm': 1.9502155780792236, 'learning_rate': 9.492956371109082e-07, 'epoch': 0.19}
{'loss': 1.1388, 'grad_norm': 1.9358881711959839, 'learning_rate': 9.48532182039832e-07, 'epoch': 0.19}
{'loss': 1.1475, 'grad_norm': 2.044334650039673, 'learning_rate': 9.477633338929621e-07, 'epoch': 0.19}
{'loss': 1.2296, 'grad_norm': 1.9225096702575684, 'learning_rate': 9.469891019147995e-07, 'epoch': 0.19}
{'loss': 1.0554, 'grad_norm': 1.850933313369751, 'learning_rate': 9.462094954145799e-07, 'epoch': 0.19}
{'loss': 1.1452, 'grad_norm': 1.767014503479004, 'learning_rate': 9.454245237661615e-07, 'epoch': 0.19}
{'loss': 1.2669, 'grad_norm': 4.022180557250977, 'learning_rate': 9.446341964079116e-07, 'epoch': 0.19}
{'loss': 1.2274, 'grad_norm': 1.8954434394836426, 'learning_rate': 9.438385228425938e-07, 'epoch': 0.19}
{'loss': 1.2099, 'grad_norm': 2.0368828773498535, 'learning_rate': 9.43037512637254e-07, 'epoch': 0.2}
{'loss': 1.2448, 'grad_norm': 2.340313673019409, 'learning_rate': 9.422311754231045e-07, 'epoch': 0.2}
{'loss': 1.0715, 'grad_norm': 2.3490731716156006, 'learning_rate': 9.41419520895409e-07, 'epoch': 0.2}
{'loss': 1.1906, 'grad_norm': 1.9093248844146729, 'learning_rate': 9.406025588133653e-07, 'epoch': 0.2}
{'loss': 1.2213, 'grad_norm': 1.8212342262268066, 'learning_rate': 9.397802989999887e-07, 'epoch': 0.2}
{'loss': 1.1256, 'grad_norm': 1.8588449954986572, 'learning_rate': 9.389527513419934e-07, 'epoch': 0.2}
{'loss': 1.2077, 'grad_norm': 1.8940436840057373, 'learning_rate': 9.381199257896737e-07, 'epoch': 0.2}
{'loss': 1.1934, 'grad_norm': 1.9212392568588257, 'learning_rate': 9.372818323567846e-07, 'epoch': 0.2}
{'loss': 1.1637, 'grad_norm': 1.9247421026229858, 'learning_rate': 9.364384811204211e-07, 'epoch': 0.2}
{'loss': 1.1449, 'grad_norm': 3.276749849319458, 'learning_rate': 9.35589882220897e-07, 'epoch': 0.21}
{'loss': 1.2874, 'grad_norm': 1.9071723222732544, 'learning_rate': 9.347360458616232e-07, 'epoch': 0.21}
{'loss': 1.1322, 'grad_norm': 2.160386800765991, 'learning_rate': 9.338769823089852e-07, 'epoch': 0.21}
{'loss': 1.2262, 'grad_norm': 1.8303884267807007, 'learning_rate': 9.330127018922193e-07, 'epoch': 0.21}
{'loss': 1.1733, 'grad_norm': 1.857276201248169, 'learning_rate': 9.321432150032882e-07, 'epoch': 0.21}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-200/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-200/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-200/model.safetensors.index.json.
2024-11-30 19:54:47,333 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-200/pytorch_model_fsdp.bin
2024-11-30 19:55:28,810 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-200/pytorch_model_fsdp.bin
2024-11-30 19:55:59,572 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-200/optimizer.bin
2024-11-30 19:57:40,178 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-200/optimizer.bin
                                                                                                             
{'loss': 1.115, 'grad_norm': 1.7223377227783203, 'learning_rate': 9.312685320967563e-07, 'epoch': 0.21}
{'loss': 1.1983, 'grad_norm': 2.4631078243255615, 'learning_rate': 9.303886636896649e-07, 'epoch': 0.21}
{'loss': 1.2104, 'grad_norm': 2.566089630126953, 'learning_rate': 9.295036203614037e-07, 'epoch': 0.21}
{'loss': 1.2835, 'grad_norm': 1.9844142198562622, 'learning_rate': 9.286134127535859e-07, 'epoch': 0.21}
{'loss': 1.0513, 'grad_norm': 2.1522483825683594, 'learning_rate': 9.277180515699181e-07, 'epoch': 0.21}
{'loss': 1.1685, 'grad_norm': 2.2389283180236816, 'learning_rate': 9.268175475760733e-07, 'epoch': 0.22}
{'loss': 1.1285, 'grad_norm': 1.8609694242477417, 'learning_rate': 9.259119115995608e-07, 'epoch': 0.22}
{'loss': 1.2393, 'grad_norm': 1.9338266849517822, 'learning_rate': 9.250011545295957e-07, 'epoch': 0.22}
{'loss': 1.2036, 'grad_norm': 1.7569611072540283, 'learning_rate': 9.240852873169685e-07, 'epoch': 0.22}
{'loss': 1.278, 'grad_norm': 1.8563175201416016, 'learning_rate': 9.231643209739126e-07, 'epoch': 0.22}
{'loss': 1.1461, 'grad_norm': 1.9620695114135742, 'learning_rate': 9.222382665739736e-07, 'epoch': 0.22}
{'loss': 1.2478, 'grad_norm': 2.283860445022583, 'learning_rate': 9.213071352518742e-07, 'epoch': 0.22}
{'loss': 1.2136, 'grad_norm': 1.9916255474090576, 'learning_rate': 9.203709382033813e-07, 'epoch': 0.22}
{'loss': 1.2511, 'grad_norm': 2.2682723999023438, 'learning_rate': 9.194296866851712e-07, 'epoch': 0.22}
{'loss': 1.182, 'grad_norm': 1.917242169380188, 'learning_rate': 9.184833920146948e-07, 'epoch': 0.23}
{'loss': 1.1304, 'grad_norm': 1.7528241872787476, 'learning_rate': 9.175320655700405e-07, 'epoch': 0.23}
{'loss': 1.1599, 'grad_norm': 1.7970476150512695, 'learning_rate': 9.165757187897978e-07, 'epoch': 0.23}
{'loss': 1.1835, 'grad_norm': 1.9954296350479126, 'learning_rate': 9.156143631729204e-07, 'epoch': 0.23}
{'loss': 1.1502, 'grad_norm': 1.7529497146606445, 'learning_rate': 9.14648010278587e-07, 'epoch': 0.23}
{'loss': 1.1292, 'grad_norm': 3.642836570739746, 'learning_rate': 9.13676671726063e-07, 'epoch': 0.23}
{'loss': 1.1669, 'grad_norm': 1.8172320127487183, 'learning_rate': 9.127003591945604e-07, 'epoch': 0.23}
{'loss': 1.2186, 'grad_norm': 1.9774742126464844, 'learning_rate': 9.117190844230971e-07, 'epoch': 0.23}
{'loss': 1.1527, 'grad_norm': 1.7195061445236206, 'learning_rate': 9.107328592103569e-07, 'epoch': 0.23}
{'loss': 1.0961, 'grad_norm': 2.4756977558135986, 'learning_rate': 9.097416954145465e-07, 'epoch': 0.23}
{'loss': 1.0845, 'grad_norm': 2.6640937328338623, 'learning_rate': 9.087456049532529e-07, 'epoch': 0.24}
{'loss': 1.2728, 'grad_norm': 1.7869820594787598, 'learning_rate': 9.077445998033014e-07, 'epoch': 0.24}
{'loss': 1.2168, 'grad_norm': 1.7267357110977173, 'learning_rate': 9.0673869200061e-07, 'epoch': 0.24}
{'loss': 1.1341, 'grad_norm': 1.937851071357727, 'learning_rate': 9.057278936400452e-07, 'epoch': 0.24}
{'loss': 1.1692, 'grad_norm': 2.253018379211426, 'learning_rate': 9.047122168752774e-07, 'epoch': 0.24}
{'loss': 1.1295, 'grad_norm': 1.7353960275650024, 'learning_rate': 9.03691673918634e-07, 'epoch': 0.24}
{'loss': 1.2132, 'grad_norm': 3.4407694339752197, 'learning_rate': 9.026662770409523e-07, 'epoch': 0.24}
{'loss': 1.1793, 'grad_norm': 1.7385131120681763, 'learning_rate': 9.016360385714323e-07, 'epoch': 0.24}
{'loss': 1.2283, 'grad_norm': 6.128482818603516, 'learning_rate': 9.006009708974891e-07, 'epoch': 0.24}
{'loss': 1.1838, 'grad_norm': 1.7696887254714966, 'learning_rate': 8.995610864646029e-07, 'epoch': 0.25}
{'loss': 1.1638, 'grad_norm': 2.021543264389038, 'learning_rate': 8.985163977761695e-07, 'epoch': 0.25}
{'loss': 1.0801, 'grad_norm': 2.0515105724334717, 'learning_rate': 8.97466917393351e-07, 'epoch': 0.25}
{'loss': 1.088, 'grad_norm': 1.9465194940567017, 'learning_rate': 8.964126579349236e-07, 'epoch': 0.25}
{'loss': 1.1919, 'grad_norm': 2.2075374126434326, 'learning_rate': 8.953536320771262e-07, 'epoch': 0.25}
{'loss': 1.1948, 'grad_norm': 2.2815017700195312, 'learning_rate': 8.942898525535084e-07, 'epoch': 0.25}
{'loss': 1.187, 'grad_norm': 1.7333519458770752, 'learning_rate': 8.932213321547768e-07, 'epoch': 0.25}
{'loss': 1.2011, 'grad_norm': 3.409442663192749, 'learning_rate': 8.921480837286417e-07, 'epoch': 0.25}
{'loss': 1.181, 'grad_norm': 1.764156460762024, 'learning_rate': 8.910701201796624e-07, 'epoch': 0.25}
{'loss': 1.1785, 'grad_norm': 1.8549485206604004, 'learning_rate': 8.89987454469092e-07, 'epoch': 0.25}
{'loss': 1.2288, 'grad_norm': 1.7018401622772217, 'learning_rate': 8.889000996147213e-07, 'epoch': 0.26}
{'loss': 1.1157, 'grad_norm': 1.6381402015686035, 'learning_rate': 8.87808068690723e-07, 'epoch': 0.26}
{'loss': 1.2176, 'grad_norm': 8.407045364379883, 'learning_rate': 8.867113748274939e-07, 'epoch': 0.26}
{'loss': 1.1472, 'grad_norm': 2.381570339202881, 'learning_rate': 8.856100312114974e-07, 'epoch': 0.26}
{'loss': 1.0787, 'grad_norm': 1.702569842338562, 'learning_rate': 8.845040510851044e-07, 'epoch': 0.26}
{'loss': 1.2019, 'grad_norm': 2.235462188720703, 'learning_rate': 8.833934477464347e-07, 'epoch': 0.26}
{'loss': 1.1556, 'grad_norm': 3.8891441822052, 'learning_rate': 8.822782345491967e-07, 'epoch': 0.26}
{'loss': 1.0998, 'grad_norm': 1.681361198425293, 'learning_rate': 8.81158424902527e-07, 'epoch': 0.26}
{'loss': 1.1438, 'grad_norm': 1.9454597234725952, 'learning_rate': 8.800340322708291e-07, 'epoch': 0.26}
{'loss': 1.1854, 'grad_norm': 1.7044225931167603, 'learning_rate': 8.789050701736117e-07, 'epoch': 0.27}
{'loss': 1.2489, 'grad_norm': 1.7590534687042236, 'learning_rate': 8.777715521853257e-07, 'epoch': 0.27}
{'loss': 1.234, 'grad_norm': 1.7985336780548096, 'learning_rate': 8.766334919352016e-07, 'epoch': 0.27}
{'loss': 1.1354, 'grad_norm': 1.7536537647247314, 'learning_rate': 8.75490903107085e-07, 'epoch': 0.27}
{'loss': 1.1985, 'grad_norm': 1.6698663234710693, 'learning_rate': 8.743437994392728e-07, 'epoch': 0.27}
{'loss': 1.0961, 'grad_norm': 1.7382092475891113, 'learning_rate': 8.731921947243468e-07, 'epoch': 0.27}
{'loss': 1.2062, 'grad_norm': 1.7507363557815552, 'learning_rate': 8.720361028090094e-07, 'epoch': 0.27}
{'loss': 1.1054, 'grad_norm': 1.6470805406570435, 'learning_rate': 8.708755375939161e-07, 'epoch': 0.27}
{'loss': 1.1502, 'grad_norm': 2.5224130153656006, 'learning_rate': 8.697105130335084e-07, 'epoch': 0.27}
{'loss': 1.1261, 'grad_norm': 3.8465828895568848, 'learning_rate': 8.685410431358464e-07, 'epoch': 0.27}
{'loss': 1.1438, 'grad_norm': 1.5974643230438232, 'learning_rate': 8.673671419624404e-07, 'epoch': 0.28}
{'loss': 1.1747, 'grad_norm': 3.9172377586364746, 'learning_rate': 8.661888236280813e-07, 'epoch': 0.28}
{'loss': 1.1044, 'grad_norm': 1.6752543449401855, 'learning_rate': 8.65006102300671e-07, 'epoch': 0.28}
{'loss': 1.0931, 'grad_norm': 1.5809284448623657, 'learning_rate': 8.638189922010528e-07, 'epoch': 0.28}
{'loss': 1.2377, 'grad_norm': 1.7130323648452759, 'learning_rate': 8.626275076028396e-07, 'epoch': 0.28}
{'loss': 1.164, 'grad_norm': 2.5867323875427246, 'learning_rate': 8.614316628322427e-07, 'epoch': 0.28}
{'loss': 1.1176, 'grad_norm': 1.5260251760482788, 'learning_rate': 8.602314722678988e-07, 'epoch': 0.28}
{'loss': 1.055, 'grad_norm': 1.6615173816680908, 'learning_rate': 8.590269503406984e-07, 'epoch': 0.28}
{'loss': 1.2063, 'grad_norm': 1.5990906953811646, 'learning_rate': 8.578181115336114e-07, 'epoch': 0.28}
{'loss': 1.2013, 'grad_norm': 1.7067521810531616, 'learning_rate': 8.56604970381513e-07, 'epoch': 0.29}
{'loss': 1.1347, 'grad_norm': 1.7715017795562744, 'learning_rate': 8.553875414710088e-07, 'epoch': 0.29}
{'loss': 1.209, 'grad_norm': 1.570701003074646, 'learning_rate': 8.541658394402605e-07, 'epoch': 0.29}
{'loss': 1.1631, 'grad_norm': 1.9339983463287354, 'learning_rate': 8.52939878978808e-07, 'epoch': 0.29}
{'loss': 1.1831, 'grad_norm': 1.6038228273391724, 'learning_rate': 8.517096748273951e-07, 'epoch': 0.29}
{'loss': 1.0669, 'grad_norm': 1.669973373413086, 'learning_rate': 8.504752417777898e-07, 'epoch': 0.29}
{'loss': 1.0799, 'grad_norm': 1.693071722984314, 'learning_rate': 8.492365946726087e-07, 'epoch': 0.29}
{'loss': 1.095, 'grad_norm': 1.7268465757369995, 'learning_rate': 8.479937484051368e-07, 'epoch': 0.29}
{'loss': 1.1553, 'grad_norm': 1.5978820323944092, 'learning_rate': 8.467467179191492e-07, 'epoch': 0.29}
{'loss': 1.1759, 'grad_norm': 1.5724129676818848, 'learning_rate': 8.454955182087317e-07, 'epoch': 0.29}
{'loss': 1.1202, 'grad_norm': 1.7711135149002075, 'learning_rate': 8.442401643181e-07, 'epoch': 0.3}
{'loss': 1.1514, 'grad_norm': 1.6013643741607666, 'learning_rate': 8.429806713414188e-07, 'epoch': 0.3}
{'loss': 1.228, 'grad_norm': 1.6967960596084595, 'learning_rate': 8.417170544226203e-07, 'epoch': 0.3}
{'loss': 1.1348, 'grad_norm': 1.501417636871338, 'learning_rate': 8.404493287552231e-07, 'epoch': 0.3}
{'loss': 1.2099, 'grad_norm': 4.205880641937256, 'learning_rate': 8.391775095821481e-07, 'epoch': 0.3}
{'loss': 1.1882, 'grad_norm': 4.68896484375, 'learning_rate': 8.379016121955355e-07, 'epoch': 0.3}
{'loss': 1.0874, 'grad_norm': 1.6307883262634277, 'learning_rate': 8.36621651936562e-07, 'epoch': 0.3}
{'loss': 1.2144, 'grad_norm': 1.8345417976379395, 'learning_rate': 8.353376441952553e-07, 'epoch': 0.3}
{'loss': 1.1426, 'grad_norm': 1.6167534589767456, 'learning_rate': 8.340496044103094e-07, 'epoch': 0.3}
{'loss': 1.2078, 'grad_norm': 1.6006863117218018, 'learning_rate': 8.327575480688985e-07, 'epoch': 0.3}
{'loss': 1.1752, 'grad_norm': 1.6194368600845337, 'learning_rate': 8.314614907064914e-07, 'epoch': 0.31}
{'loss': 1.1504, 'grad_norm': 1.459714412689209, 'learning_rate': 8.301614479066652e-07, 'epoch': 0.31}
{'loss': 1.1091, 'grad_norm': 1.6276735067367554, 'learning_rate': 8.288574353009164e-07, 'epoch': 0.31}
{'loss': 1.1303, 'grad_norm': 1.6345889568328857, 'learning_rate': 8.275494685684739e-07, 'epoch': 0.31}
{'loss': 1.0822, 'grad_norm': 1.6656986474990845, 'learning_rate': 8.262375634361107e-07, 'epoch': 0.31}
{'loss': 1.1106, 'grad_norm': 1.7113972902297974, 'learning_rate': 8.249217356779543e-07, 'epoch': 0.31}
{'loss': 1.1382, 'grad_norm': 1.6339577436447144, 'learning_rate': 8.236020011152968e-07, 'epoch': 0.31}
{'loss': 1.103, 'grad_norm': 1.7153947353363037, 'learning_rate': 8.222783756164061e-07, 'epoch': 0.31}
{'loss': 1.1209, 'grad_norm': 1.5500421524047852, 'learning_rate': 8.209508750963328e-07, 'epoch': 0.31}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-300/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-300/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-300/model.safetensors.index.json.
2024-11-30 20:12:57,871 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-300/pytorch_model_fsdp.bin
2024-11-30 20:13:37,990 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-300/pytorch_model_fsdp.bin
2024-11-30 20:14:08,688 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-300/optimizer.bin
2024-11-30 20:15:28,319 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-300/optimizer.bin
                                                                                                             
{'loss': 1.1079, 'grad_norm': 1.8533002138137817, 'learning_rate': 8.196195155167209e-07, 'epoch': 0.32}
{'loss': 1.1798, 'grad_norm': 1.5760116577148438, 'learning_rate': 8.18284312885615e-07, 'epoch': 0.32}
{'loss': 1.1108, 'grad_norm': 1.7901028394699097, 'learning_rate': 8.169452832572674e-07, 'epoch': 0.32}
{'loss': 1.1952, 'grad_norm': 2.145967483520508, 'learning_rate': 8.156024427319463e-07, 'epoch': 0.32}
{'loss': 1.1478, 'grad_norm': 1.5871020555496216, 'learning_rate': 8.142558074557412e-07, 'epoch': 0.32}
{'loss': 1.1883, 'grad_norm': 1.6198617219924927, 'learning_rate': 8.129053936203687e-07, 'epoch': 0.32}
{'loss': 1.1331, 'grad_norm': 1.893763542175293, 'learning_rate': 8.115512174629788e-07, 'epoch': 0.32}
{'loss': 1.1196, 'grad_norm': 1.5851479768753052, 'learning_rate': 8.101932952659585e-07, 'epoch': 0.32}
{'loss': 1.133, 'grad_norm': 1.6644976139068604, 'learning_rate': 8.088316433567368e-07, 'epoch': 0.32}
{'loss': 1.1468, 'grad_norm': 1.7926392555236816, 'learning_rate': 8.074662781075879e-07, 'epoch': 0.32}
{'loss': 1.0655, 'grad_norm': 1.52574622631073, 'learning_rate': 8.060972159354349e-07, 'epoch': 0.33}
{'loss': 1.0779, 'grad_norm': 1.4693388938903809, 'learning_rate': 8.047244733016521e-07, 'epoch': 0.33}
{'loss': 1.0902, 'grad_norm': 1.609666347503662, 'learning_rate': 8.033480667118666e-07, 'epoch': 0.33}
{'loss': 1.1045, 'grad_norm': 1.4570164680480957, 'learning_rate': 8.019680127157606e-07, 'epoch': 0.33}
{'loss': 1.1488, 'grad_norm': 1.6080505847930908, 'learning_rate': 8.005843279068723e-07, 'epoch': 0.33}
{'loss': 1.1391, 'grad_norm': 7.600809574127197, 'learning_rate': 7.991970289223959e-07, 'epoch': 0.33}
{'loss': 1.1437, 'grad_norm': 16.69818115234375, 'learning_rate': 7.978061324429819e-07, 'epoch': 0.33}
{'loss': 1.2108, 'grad_norm': 1.5515660047531128, 'learning_rate': 7.964116551925364e-07, 'epoch': 0.33}
{'loss': 1.1999, 'grad_norm': 1.5013333559036255, 'learning_rate': 7.950136139380202e-07, 'epoch': 0.33}
{'loss': 1.0862, 'grad_norm': 1.635257601737976, 'learning_rate': 7.936120254892471e-07, 'epoch': 0.34}
{'loss': 1.203, 'grad_norm': 2.1516363620758057, 'learning_rate': 7.922069066986819e-07, 'epoch': 0.34}
{'loss': 1.1038, 'grad_norm': 1.5270200967788696, 'learning_rate': 7.907982744612372e-07, 'epoch': 0.34}
{'loss': 1.1784, 'grad_norm': 1.5275026559829712, 'learning_rate': 7.893861457140711e-07, 'epoch': 0.34}
{'loss': 1.1899, 'grad_norm': 4.345768451690674, 'learning_rate': 7.87970537436383e-07, 'epoch': 0.34}
{'loss': 1.155, 'grad_norm': 1.5273046493530273, 'learning_rate': 7.865514666492095e-07, 'epoch': 0.34}
{'loss': 1.1325, 'grad_norm': 1.457726240158081, 'learning_rate': 7.851289504152201e-07, 'epoch': 0.34}
{'loss': 1.1669, 'grad_norm': 1.6884472370147705, 'learning_rate': 7.837030058385117e-07, 'epoch': 0.34}
{'loss': 1.131, 'grad_norm': 1.4880510568618774, 'learning_rate': 7.822736500644027e-07, 'epoch': 0.34}
{'loss': 1.0581, 'grad_norm': 1.449809193611145, 'learning_rate': 7.808409002792276e-07, 'epoch': 0.34}
{'loss': 1.159, 'grad_norm': 1.5901802778244019, 'learning_rate': 7.794047737101297e-07, 'epoch': 0.35}
{'loss': 1.1214, 'grad_norm': 1.4409151077270508, 'learning_rate': 7.779652876248541e-07, 'epoch': 0.35}
{'loss': 1.1122, 'grad_norm': 3.0828609466552734, 'learning_rate': 7.765224593315402e-07, 'epoch': 0.35}
{'loss': 1.0788, 'grad_norm': 1.5226991176605225, 'learning_rate': 7.750763061785137e-07, 'epoch': 0.35}
{'loss': 1.208, 'grad_norm': 1.663430094718933, 'learning_rate': 7.73626845554078e-07, 'epoch': 0.35}
{'loss': 1.1509, 'grad_norm': 1.5842820405960083, 'learning_rate': 7.721740948863043e-07, 'epoch': 0.35}
{'loss': 1.1421, 'grad_norm': 1.5345420837402344, 'learning_rate': 7.707180716428237e-07, 'epoch': 0.35}
{'loss': 1.1298, 'grad_norm': 1.564253330230713, 'learning_rate': 7.692587933306152e-07, 'epoch': 0.35}
{'loss': 1.1177, 'grad_norm': 1.510611891746521, 'learning_rate': 7.67796277495797e-07, 'epoch': 0.35}
{'loss': 1.1989, 'grad_norm': 2.063673973083496, 'learning_rate': 7.663305417234145e-07, 'epoch': 0.36}
{'loss': 1.1373, 'grad_norm': 2.853195905685425, 'learning_rate': 7.648616036372286e-07, 'epoch': 0.36}
{'loss': 1.2574, 'grad_norm': 1.5540870428085327, 'learning_rate': 7.63389480899505e-07, 'epoch': 0.36}
{'loss': 1.1407, 'grad_norm': 1.7566783428192139, 'learning_rate': 7.619141912108006e-07, 'epoch': 0.36}
{'loss': 1.146, 'grad_norm': 1.748244047164917, 'learning_rate': 7.604357523097516e-07, 'epoch': 0.36}
{'loss': 1.1578, 'grad_norm': 1.4870328903198242, 'learning_rate': 7.589541819728596e-07, 'epoch': 0.36}
{'loss': 1.164, 'grad_norm': 1.4723435640335083, 'learning_rate': 7.574694980142779e-07, 'epoch': 0.36}
{'loss': 1.0807, 'grad_norm': 1.8028117418289185, 'learning_rate': 7.559817182855976e-07, 'epoch': 0.36}
{'loss': 1.0461, 'grad_norm': 1.701368808746338, 'learning_rate': 7.544908606756331e-07, 'epoch': 0.36}
{'loss': 1.1822, 'grad_norm': 1.5309488773345947, 'learning_rate': 7.529969431102062e-07, 'epoch': 0.36}
{'loss': 1.1739, 'grad_norm': 1.9784419536590576, 'learning_rate': 7.514999835519317e-07, 'epoch': 0.37}
{'loss': 1.126, 'grad_norm': 1.6296850442886353, 'learning_rate': 7.5e-07, 'epoch': 0.37}
{'loss': 1.1593, 'grad_norm': 1.702905297279358, 'learning_rate': 7.484970104899623e-07, 'epoch': 0.37}
{'loss': 1.1765, 'grad_norm': 1.5543986558914185, 'learning_rate': 7.469910330935125e-07, 'epoch': 0.37}
{'loss': 1.1968, 'grad_norm': 1.424005150794983, 'learning_rate': 7.454820859182705e-07, 'epoch': 0.37}
{'loss': 1.0884, 'grad_norm': 1.5341321229934692, 'learning_rate': 7.439701871075641e-07, 'epoch': 0.37}
{'loss': 1.1069, 'grad_norm': 1.3990442752838135, 'learning_rate': 7.424553548402115e-07, 'epoch': 0.37}
{'loss': 1.1922, 'grad_norm': 3.284698247909546, 'learning_rate': 7.409376073303019e-07, 'epoch': 0.37}
{'loss': 1.1268, 'grad_norm': 1.3622251749038696, 'learning_rate': 7.394169628269771e-07, 'epoch': 0.37}
{'loss': 1.1247, 'grad_norm': 1.6239136457443237, 'learning_rate': 7.378934396142114e-07, 'epoch': 0.38}
{'loss': 1.1446, 'grad_norm': 1.4934498071670532, 'learning_rate': 7.363670560105933e-07, 'epoch': 0.38}
{'loss': 1.1413, 'grad_norm': 2.490079641342163, 'learning_rate': 7.348378303691029e-07, 'epoch': 0.38}
{'loss': 1.1638, 'grad_norm': 1.5203560590744019, 'learning_rate': 7.333057810768934e-07, 'epoch': 0.38}
{'loss': 1.1732, 'grad_norm': 1.37687349319458, 'learning_rate': 7.317709265550684e-07, 'epoch': 0.38}
{'loss': 1.2166, 'grad_norm': 1.483684778213501, 'learning_rate': 7.302332852584619e-07, 'epoch': 0.38}
{'loss': 1.1922, 'grad_norm': 1.4490028619766235, 'learning_rate': 7.286928756754148e-07, 'epoch': 0.38}
{'loss': 1.0805, 'grad_norm': 1.4305864572525024, 'learning_rate': 7.271497163275539e-07, 'epoch': 0.38}
{'loss': 1.0634, 'grad_norm': 1.3688952922821045, 'learning_rate': 7.256038257695687e-07, 'epoch': 0.38}
{'loss': 1.1774, 'grad_norm': 1.5275994539260864, 'learning_rate': 7.240552225889881e-07, 'epoch': 0.38}
{'loss': 1.0992, 'grad_norm': 1.3970258235931396, 'learning_rate': 7.225039254059573e-07, 'epoch': 0.39}
{'loss': 1.2575, 'grad_norm': 10.180667877197266, 'learning_rate': 7.209499528730138e-07, 'epoch': 0.39}
{'loss': 1.133, 'grad_norm': 1.5196278095245361, 'learning_rate': 7.193933236748626e-07, 'epoch': 0.39}
{'loss': 1.1686, 'grad_norm': 1.4340234994888306, 'learning_rate': 7.178340565281526e-07, 'epoch': 0.39}
{'loss': 1.2309, 'grad_norm': 5.00830602645874, 'learning_rate': 7.162721701812505e-07, 'epoch': 0.39}
{'loss': 1.0625, 'grad_norm': 1.3634617328643799, 'learning_rate': 7.147076834140162e-07, 'epoch': 0.39}
{'loss': 1.1384, 'grad_norm': 6.97025728225708, 'learning_rate': 7.131406150375762e-07, 'epoch': 0.39}
{'loss': 1.1361, 'grad_norm': 1.4064851999282837, 'learning_rate': 7.115709838940982e-07, 'epoch': 0.39}
{'loss': 1.1554, 'grad_norm': 1.4999371767044067, 'learning_rate': 7.099988088565641e-07, 'epoch': 0.39}
{'loss': 1.1923, 'grad_norm': 1.7490917444229126, 'learning_rate': 7.08424108828543e-07, 'epoch': 0.4}
{'loss': 1.0742, 'grad_norm': 1.5249788761138916, 'learning_rate': 7.068469027439641e-07, 'epoch': 0.4}
{'loss': 1.1026, 'grad_norm': 1.3953814506530762, 'learning_rate': 7.05267209566889e-07, 'epoch': 0.4}
{'loss': 1.1181, 'grad_norm': 1.420096516609192, 'learning_rate': 7.036850482912839e-07, 'epoch': 0.4}
{'loss': 1.1715, 'grad_norm': 2.9756550788879395, 'learning_rate': 7.021004379407908e-07, 'epoch': 0.4}
{'loss': 1.1346, 'grad_norm': 3.2876670360565186, 'learning_rate': 7.005133975684992e-07, 'epoch': 0.4}
{'loss': 1.1181, 'grad_norm': 1.4424026012420654, 'learning_rate': 6.989239462567161e-07, 'epoch': 0.4}
{'loss': 1.0979, 'grad_norm': 1.490950584411621, 'learning_rate': 6.973321031167382e-07, 'epoch': 0.4}
{'loss': 1.1597, 'grad_norm': 1.7530646324157715, 'learning_rate': 6.957378872886204e-07, 'epoch': 0.4}
{'loss': 1.1286, 'grad_norm': 3.822793483734131, 'learning_rate': 6.941413179409468e-07, 'epoch': 0.4}
{'loss': 1.1106, 'grad_norm': 1.5662446022033691, 'learning_rate': 6.925424142705997e-07, 'epoch': 0.41}
{'loss': 1.1753, 'grad_norm': 1.5164469480514526, 'learning_rate': 6.909411955025288e-07, 'epoch': 0.41}
{'loss': 1.0877, 'grad_norm': 1.5797011852264404, 'learning_rate': 6.893376808895201e-07, 'epoch': 0.41}
{'loss': 1.1562, 'grad_norm': 1.4215102195739746, 'learning_rate': 6.87731889711965e-07, 'epoch': 0.41}
{'loss': 1.134, 'grad_norm': 1.5128618478775024, 'learning_rate': 6.861238412776271e-07, 'epoch': 0.41}
{'loss': 1.1334, 'grad_norm': 1.4121254682540894, 'learning_rate': 6.845135549214117e-07, 'epoch': 0.41}
{'loss': 1.1743, 'grad_norm': 1.3838341236114502, 'learning_rate': 6.829010500051318e-07, 'epoch': 0.41}
{'loss': 1.1541, 'grad_norm': 1.457501769065857, 'learning_rate': 6.812863459172764e-07, 'epoch': 0.41}
{'loss': 1.1294, 'grad_norm': 1.380197286605835, 'learning_rate': 6.796694620727768e-07, 'epoch': 0.41}
{'loss': 1.1331, 'grad_norm': 8.238574028015137, 'learning_rate': 6.780504179127734e-07, 'epoch': 0.41}
{'loss': 1.1272, 'grad_norm': 1.4237046241760254, 'learning_rate': 6.76429232904382e-07, 'epoch': 0.42}
{'loss': 1.1475, 'grad_norm': 1.54957115650177, 'learning_rate': 6.748059265404596e-07, 'epoch': 0.42}
{'loss': 1.1623, 'grad_norm': 1.939054250717163, 'learning_rate': 6.731805183393695e-07, 'epoch': 0.42}
{'loss': 1.1447, 'grad_norm': 2.882765531539917, 'learning_rate': 6.715530278447479e-07, 'epoch': 0.42}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-400/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-400/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-400/model.safetensors.index.json.
2024-11-30 20:30:42,617 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-400/pytorch_model_fsdp.bin
2024-11-30 20:31:25,290 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-400/pytorch_model_fsdp.bin
2024-11-30 20:31:56,791 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-400/optimizer.bin
2024-11-30 20:33:19,963 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-400/optimizer.bin
                                                                                                             
{'loss': 1.1167, 'grad_norm': 1.3767045736312866, 'learning_rate': 6.699234746252674e-07, 'epoch': 0.42}
{'loss': 1.0512, 'grad_norm': 4.067066192626953, 'learning_rate': 6.682918782744031e-07, 'epoch': 0.42}
{'loss': 1.1845, 'grad_norm': 1.4698741436004639, 'learning_rate': 6.66658258410196e-07, 'epoch': 0.42}
{'loss': 1.0927, 'grad_norm': 1.4802439212799072, 'learning_rate': 6.650226346750178e-07, 'epoch': 0.42}
{'loss': 1.1212, 'grad_norm': 4.29186487197876, 'learning_rate': 6.633850267353339e-07, 'epoch': 0.42}
{'loss': 1.0633, 'grad_norm': 2.8004045486450195, 'learning_rate': 6.61745454281468e-07, 'epoch': 0.43}
{'loss': 1.117, 'grad_norm': 1.346875548362732, 'learning_rate': 6.601039370273644e-07, 'epoch': 0.43}
{'loss': 1.1704, 'grad_norm': 1.5292766094207764, 'learning_rate': 6.584604947103513e-07, 'epoch': 0.43}
{'loss': 1.1019, 'grad_norm': 1.3604209423065186, 'learning_rate': 6.568151470909041e-07, 'epoch': 0.43}
{'loss': 1.1879, 'grad_norm': 1.6049253940582275, 'learning_rate': 6.551679139524067e-07, 'epoch': 0.43}
{'loss': 1.2072, 'grad_norm': 1.739099383354187, 'learning_rate': 6.535188151009143e-07, 'epoch': 0.43}
{'loss': 1.1849, 'grad_norm': 1.4653187990188599, 'learning_rate': 6.51867870364915e-07, 'epoch': 0.43}
{'loss': 1.1588, 'grad_norm': 1.3918781280517578, 'learning_rate': 6.50215099595092e-07, 'epoch': 0.43}
{'loss': 1.168, 'grad_norm': 1.358686089515686, 'learning_rate': 6.485605226640836e-07, 'epoch': 0.43}
{'loss': 1.1067, 'grad_norm': 1.4375765323638916, 'learning_rate': 6.46904159466246e-07, 'epoch': 0.43}
{'loss': 1.1409, 'grad_norm': 1.460972785949707, 'learning_rate': 6.452460299174125e-07, 'epoch': 0.44}
{'loss': 1.1254, 'grad_norm': 1.5504449605941772, 'learning_rate': 6.43586153954655e-07, 'epoch': 0.44}
{'loss': 1.0188, 'grad_norm': 1.3692251443862915, 'learning_rate': 6.41924551536044e-07, 'epoch': 0.44}
{'loss': 1.0865, 'grad_norm': 1.8367655277252197, 'learning_rate': 6.402612426404082e-07, 'epoch': 0.44}
{'loss': 1.0965, 'grad_norm': 2.5547211170196533, 'learning_rate': 6.385962472670953e-07, 'epoch': 0.44}
{'loss': 1.103, 'grad_norm': 1.839435338973999, 'learning_rate': 6.369295854357306e-07, 'epoch': 0.44}
{'loss': 1.1851, 'grad_norm': 1.4049023389816284, 'learning_rate': 6.352612771859768e-07, 'epoch': 0.44}
{'loss': 1.1225, 'grad_norm': 1.384529948234558, 'learning_rate': 6.335913425772925e-07, 'epoch': 0.44}
{'loss': 1.1273, 'grad_norm': 1.3302959203720093, 'learning_rate': 6.319198016886918e-07, 'epoch': 0.44}
{'loss': 1.1556, 'grad_norm': 1.3471006155014038, 'learning_rate': 6.302466746185021e-07, 'epoch': 0.45}
{'loss': 1.0787, 'grad_norm': 1.3458024263381958, 'learning_rate': 6.28571981484123e-07, 'epoch': 0.45}
{'loss': 1.1047, 'grad_norm': 1.8056514263153076, 'learning_rate': 6.26895742421784e-07, 'epoch': 0.45}
{'loss': 1.0911, 'grad_norm': 1.3321235179901123, 'learning_rate': 6.252179775863029e-07, 'epoch': 0.45}
{'loss': 1.1639, 'grad_norm': 6.610617160797119, 'learning_rate': 6.235387071508426e-07, 'epoch': 0.45}
{'loss': 1.1999, 'grad_norm': 1.5377427339553833, 'learning_rate': 6.218579513066697e-07, 'epoch': 0.45}
{'loss': 1.1205, 'grad_norm': 1.8552772998809814, 'learning_rate': 6.201757302629107e-07, 'epoch': 0.45}
{'loss': 1.0897, 'grad_norm': 1.8461174964904785, 'learning_rate': 6.184920642463094e-07, 'epoch': 0.45}
{'loss': 1.2698, 'grad_norm': 1.4849283695220947, 'learning_rate': 6.16806973500984e-07, 'epoch': 0.45}
{'loss': 1.1277, 'grad_norm': 1.798307180404663, 'learning_rate': 6.151204782881835e-07, 'epoch': 0.45}
{'loss': 1.1982, 'grad_norm': 2.9984970092773438, 'learning_rate': 6.134325988860433e-07, 'epoch': 0.46}
{'loss': 1.1033, 'grad_norm': 1.3476850986480713, 'learning_rate': 6.117433555893425e-07, 'epoch': 0.46}
{'loss': 1.0807, 'grad_norm': 1.5363574028015137, 'learning_rate': 6.100527687092598e-07, 'epoch': 0.46}
{'loss': 1.2155, 'grad_norm': 1.5038491487503052, 'learning_rate': 6.083608585731283e-07, 'epoch': 0.46}
{'loss': 1.1819, 'grad_norm': 1.3205174207687378, 'learning_rate': 6.066676455241918e-07, 'epoch': 0.46}
{'loss': 1.1134, 'grad_norm': 1.3829357624053955, 'learning_rate': 6.049731499213605e-07, 'epoch': 0.46}
{'loss': 1.123, 'grad_norm': 1.3833532333374023, 'learning_rate': 6.032773921389654e-07, 'epoch': 0.46}
{'loss': 1.1697, 'grad_norm': 1.4364545345306396, 'learning_rate': 6.015803925665141e-07, 'epoch': 0.46}
{'loss': 1.116, 'grad_norm': 1.502000093460083, 'learning_rate': 5.998821716084449e-07, 'epoch': 0.46}
{'loss': 1.1253, 'grad_norm': 1.4390252828598022, 'learning_rate': 5.981827496838822e-07, 'epoch': 0.47}
{'loss': 1.1177, 'grad_norm': 1.3940492868423462, 'learning_rate': 5.964821472263903e-07, 'epoch': 0.47}
{'loss': 1.1592, 'grad_norm': 1.5338226556777954, 'learning_rate': 5.94780384683728e-07, 'epoch': 0.47}
{'loss': 1.1129, 'grad_norm': 1.3059141635894775, 'learning_rate': 5.930774825176033e-07, 'epoch': 0.47}
{'loss': 1.1535, 'grad_norm': 1.5889700651168823, 'learning_rate': 5.913734612034264e-07, 'epoch': 0.47}
{'loss': 1.148, 'grad_norm': 4.386067867279053, 'learning_rate': 5.89668341230064e-07, 'epoch': 0.47}
{'loss': 1.1778, 'grad_norm': 1.3400179147720337, 'learning_rate': 5.879621430995927e-07, 'epoch': 0.47}
{'loss': 1.1923, 'grad_norm': 1.3595085144042969, 'learning_rate': 5.862548873270532e-07, 'epoch': 0.47}
{'loss': 1.1195, 'grad_norm': 3.6631240844726562, 'learning_rate': 5.845465944402027e-07, 'epoch': 0.47}
{'loss': 1.13, 'grad_norm': 3.1957218647003174, 'learning_rate': 5.828372849792685e-07, 'epoch': 0.47}
{'loss': 1.0536, 'grad_norm': 1.73438560962677, 'learning_rate': 5.811269794967014e-07, 'epoch': 0.48}
{'loss': 1.1806, 'grad_norm': 1.6640211343765259, 'learning_rate': 5.794156985569275e-07, 'epoch': 0.48}
{'loss': 1.0379, 'grad_norm': 1.534984827041626, 'learning_rate': 5.777034627361025e-07, 'epoch': 0.48}
{'loss': 1.1411, 'grad_norm': 1.4314689636230469, 'learning_rate': 5.759902926218626e-07, 'epoch': 0.48}
{'loss': 1.1785, 'grad_norm': 1.6659250259399414, 'learning_rate': 5.742762088130785e-07, 'epoch': 0.48}
{'loss': 1.1273, 'grad_norm': 2.897606611251831, 'learning_rate': 5.725612319196064e-07, 'epoch': 0.48}
{'loss': 1.1018, 'grad_norm': 1.3524760007858276, 'learning_rate': 5.708453825620412e-07, 'epoch': 0.48}
{'loss': 1.1861, 'grad_norm': 1.3982163667678833, 'learning_rate': 5.69128681371468e-07, 'epoch': 0.48}
{'loss': 1.1336, 'grad_norm': 1.3925917148590088, 'learning_rate': 5.674111489892144e-07, 'epoch': 0.48}
{'loss': 1.1536, 'grad_norm': 1.4458223581314087, 'learning_rate': 5.656928060666018e-07, 'epoch': 0.49}
{'loss': 1.1569, 'grad_norm': 1.4692769050598145, 'learning_rate': 5.639736732646976e-07, 'epoch': 0.49}
{'loss': 1.1309, 'grad_norm': 1.3269802331924438, 'learning_rate': 5.622537712540664e-07, 'epoch': 0.49}
{'loss': 1.0511, 'grad_norm': 1.39632248878479, 'learning_rate': 5.605331207145219e-07, 'epoch': 0.49}
{'loss': 1.1569, 'grad_norm': 1.3948171138763428, 'learning_rate': 5.588117423348778e-07, 'epoch': 0.49}
{'loss': 1.1268, 'grad_norm': 1.3405262231826782, 'learning_rate': 5.570896568126993e-07, 'epoch': 0.49}
{'loss': 1.0808, 'grad_norm': 2.139843702316284, 'learning_rate': 5.55366884854054e-07, 'epoch': 0.49}
{'loss': 1.0904, 'grad_norm': 1.8082218170166016, 'learning_rate': 5.536434471732634e-07, 'epoch': 0.49}
{'loss': 1.1719, 'grad_norm': 1.4759448766708374, 'learning_rate': 5.519193644926534e-07, 'epoch': 0.49}
{'loss': 1.1242, 'grad_norm': 1.3964922428131104, 'learning_rate': 5.50194657542305e-07, 'epoch': 0.49}
{'loss': 1.0979, 'grad_norm': 1.836309790611267, 'learning_rate': 5.484693470598059e-07, 'epoch': 0.5}
{'loss': 1.1317, 'grad_norm': 1.3647524118423462, 'learning_rate': 5.4674345379e-07, 'epoch': 0.5}
{'loss': 1.1536, 'grad_norm': 1.6928956508636475, 'learning_rate': 5.450169984847389e-07, 'epoch': 0.5}
{'loss': 1.1284, 'grad_norm': 1.288411259651184, 'learning_rate': 5.432900019026315e-07, 'epoch': 0.5}
{'loss': 1.076, 'grad_norm': 1.562720775604248, 'learning_rate': 5.415624848087959e-07, 'epoch': 0.5}
{'loss': 1.1652, 'grad_norm': 1.3734071254730225, 'learning_rate': 5.398344679746076e-07, 'epoch': 0.5}
{'loss': 1.0675, 'grad_norm': 9.074712753295898, 'learning_rate': 5.381059721774516e-07, 'epoch': 0.5}
{'loss': 1.1244, 'grad_norm': 1.307069182395935, 'learning_rate': 5.36377018200472e-07, 'epoch': 0.5}
{'loss': 1.1522, 'grad_norm': 5.265067100524902, 'learning_rate': 5.346476268323213e-07, 'epoch': 0.5}
{'loss': 1.0447, 'grad_norm': 1.3227742910385132, 'learning_rate': 5.329178188669117e-07, 'epoch': 0.51}
{'loss': 1.0963, 'grad_norm': 1.3359737396240234, 'learning_rate': 5.311876151031641e-07, 'epoch': 0.51}
{'loss': 1.0931, 'grad_norm': 1.3876943588256836, 'learning_rate': 5.294570363447589e-07, 'epoch': 0.51}
{'loss': 1.0878, 'grad_norm': 1.4012961387634277, 'learning_rate': 5.277261033998851e-07, 'epoch': 0.51}
{'loss': 1.1173, 'grad_norm': 1.5404136180877686, 'learning_rate': 5.259948370809902e-07, 'epoch': 0.51}
{'loss': 1.2117, 'grad_norm': 1.4067846536636353, 'learning_rate': 5.242632582045303e-07, 'epoch': 0.51}
{'loss': 1.1672, 'grad_norm': 1.384694218635559, 'learning_rate': 5.225313875907197e-07, 'epoch': 0.51}
{'loss': 1.044, 'grad_norm': 3.6498193740844727, 'learning_rate': 5.207992460632804e-07, 'epoch': 0.51}
{'loss': 1.1595, 'grad_norm': 1.588958740234375, 'learning_rate': 5.190668544491918e-07, 'epoch': 0.51}
{'loss': 1.2127, 'grad_norm': 2.1917171478271484, 'learning_rate': 5.173342335784406e-07, 'epoch': 0.51}
{'loss': 1.1026, 'grad_norm': 1.382889986038208, 'learning_rate': 5.156014042837695e-07, 'epoch': 0.52}
{'loss': 1.167, 'grad_norm': 3.8563036918640137, 'learning_rate': 5.138683874004278e-07, 'epoch': 0.52}
{'loss': 1.1637, 'grad_norm': 1.4354134798049927, 'learning_rate': 5.121352037659201e-07, 'epoch': 0.52}
{'loss': 1.0278, 'grad_norm': 1.445402979850769, 'learning_rate': 5.104018742197556e-07, 'epoch': 0.52}
{'loss': 1.1982, 'grad_norm': 1.455311894416809, 'learning_rate': 5.086684196031988e-07, 'epoch': 0.52}
{'loss': 1.1837, 'grad_norm': 1.6023482084274292, 'learning_rate': 5.069348607590172e-07, 'epoch': 0.52}
{'loss': 1.1387, 'grad_norm': 4.738922119140625, 'learning_rate': 5.052012185312321e-07, 'epoch': 0.52}
{'loss': 1.1367, 'grad_norm': 1.38253915309906, 'learning_rate': 5.034675137648669e-07, 'epoch': 0.52}
{'loss': 1.1564, 'grad_norm': 1.5751734972000122, 'learning_rate': 5.017337673056971e-07, 'epoch': 0.52}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-500/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-500/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-500/model.safetensors.index.json.
2024-11-30 20:48:35,697 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-500/pytorch_model_fsdp.bin
2024-11-30 20:49:24,727 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-500/pytorch_model_fsdp.bin
2024-11-30 20:49:55,959 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-500/optimizer.bin
2024-11-30 20:51:23,035 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-500/optimizer.bin
                                                                                                             
{'loss': 1.0334, 'grad_norm': 1.3611400127410889, 'learning_rate': 5e-07, 'epoch': 0.52}
{'loss': 1.1611, 'grad_norm': 1.4976140260696411, 'learning_rate': 4.982662326943028e-07, 'epoch': 0.53}
{'loss': 1.0977, 'grad_norm': 3.3499436378479004, 'learning_rate': 4.965324862351332e-07, 'epoch': 0.53}
{'loss': 1.055, 'grad_norm': 1.333817958831787, 'learning_rate': 4.947987814687679e-07, 'epoch': 0.53}
{'loss': 1.1714, 'grad_norm': 1.3549623489379883, 'learning_rate': 4.930651392409827e-07, 'epoch': 0.53}
{'loss': 1.0727, 'grad_norm': 1.396685004234314, 'learning_rate': 4.913315803968012e-07, 'epoch': 0.53}
{'loss': 1.1513, 'grad_norm': 1.3873392343521118, 'learning_rate': 4.895981257802443e-07, 'epoch': 0.53}
{'loss': 1.0925, 'grad_norm': 1.3545061349868774, 'learning_rate': 4.8786479623408e-07, 'epoch': 0.53}
{'loss': 1.1542, 'grad_norm': 1.4145472049713135, 'learning_rate': 4.861316125995722e-07, 'epoch': 0.53}
{'loss': 1.1574, 'grad_norm': 1.4434362649917603, 'learning_rate': 4.843985957162304e-07, 'epoch': 0.53}
{'loss': 1.1462, 'grad_norm': 1.3983629941940308, 'learning_rate': 4.826657664215596e-07, 'epoch': 0.54}
{'loss': 1.0322, 'grad_norm': 2.915214776992798, 'learning_rate': 4.809331455508082e-07, 'epoch': 0.54}
{'loss': 1.1667, 'grad_norm': 1.599094033241272, 'learning_rate': 4.792007539367197e-07, 'epoch': 0.54}
{'loss': 1.0913, 'grad_norm': 1.3304541110992432, 'learning_rate': 4.774686124092804e-07, 'epoch': 0.54}
{'loss': 1.0836, 'grad_norm': 1.2954511642456055, 'learning_rate': 4.757367417954698e-07, 'epoch': 0.54}
{'loss': 1.1574, 'grad_norm': 1.3967540264129639, 'learning_rate': 4.7400516291900986e-07, 'epoch': 0.54}
{'loss': 1.1778, 'grad_norm': 1.3742111921310425, 'learning_rate': 4.72273896600115e-07, 'epoch': 0.54}
{'loss': 1.1062, 'grad_norm': 1.483764886856079, 'learning_rate': 4.7054296365524106e-07, 'epoch': 0.54}
{'loss': 1.1318, 'grad_norm': 1.3763295412063599, 'learning_rate': 4.688123848968359e-07, 'epoch': 0.54}
{'loss': 1.165, 'grad_norm': 1.4172217845916748, 'learning_rate': 4.6708218113308835e-07, 'epoch': 0.54}
{'loss': 1.1281, 'grad_norm': 1.4199504852294922, 'learning_rate': 4.6535237316767875e-07, 'epoch': 0.55}
{'loss': 1.1614, 'grad_norm': 1.4562067985534668, 'learning_rate': 4.636229817995281e-07, 'epoch': 0.55}
{'loss': 1.0969, 'grad_norm': 1.4789302349090576, 'learning_rate': 4.618940278225483e-07, 'epoch': 0.55}
{'loss': 1.1644, 'grad_norm': 1.5750550031661987, 'learning_rate': 4.601655320253924e-07, 'epoch': 0.55}
{'loss': 1.1361, 'grad_norm': 1.3420848846435547, 'learning_rate': 4.5843751519120414e-07, 'epoch': 0.55}
{'loss': 1.141, 'grad_norm': 1.4116257429122925, 'learning_rate': 4.5670999809736835e-07, 'epoch': 0.55}
{'loss': 1.0165, 'grad_norm': 1.3521641492843628, 'learning_rate': 4.5498300151526115e-07, 'epoch': 0.55}
{'loss': 1.1301, 'grad_norm': 1.3870341777801514, 'learning_rate': 4.532565462099999e-07, 'epoch': 0.55}
{'loss': 1.1486, 'grad_norm': 1.3993637561798096, 'learning_rate': 4.51530652940194e-07, 'epoch': 0.55}
{'loss': 1.11, 'grad_norm': 1.4093718528747559, 'learning_rate': 4.498053424576948e-07, 'epoch': 0.56}
{'loss': 1.0283, 'grad_norm': 1.355103850364685, 'learning_rate': 4.4808063550734664e-07, 'epoch': 0.56}
{'loss': 1.0814, 'grad_norm': 1.3932793140411377, 'learning_rate': 4.4635655282673663e-07, 'epoch': 0.56}
{'loss': 1.0628, 'grad_norm': 1.547668218612671, 'learning_rate': 4.4463311514594606e-07, 'epoch': 0.56}
{'loss': 1.1462, 'grad_norm': 1.4774068593978882, 'learning_rate': 4.4291034318730086e-07, 'epoch': 0.56}
{'loss': 1.1174, 'grad_norm': 1.4582016468048096, 'learning_rate': 4.411882576651223e-07, 'epoch': 0.56}
{'loss': 1.1305, 'grad_norm': 2.080674648284912, 'learning_rate': 4.394668792854782e-07, 'epoch': 0.56}
{'loss': 1.1876, 'grad_norm': 1.3545297384262085, 'learning_rate': 4.377462287459337e-07, 'epoch': 0.56}
{'loss': 1.133, 'grad_norm': 1.4893832206726074, 'learning_rate': 4.360263267353025e-07, 'epoch': 0.56}
{'loss': 1.0666, 'grad_norm': 1.3804188966751099, 'learning_rate': 4.343071939333982e-07, 'epoch': 0.56}
{'loss': 1.1516, 'grad_norm': 1.5582804679870605, 'learning_rate': 4.325888510107856e-07, 'epoch': 0.57}
{'loss': 1.1377, 'grad_norm': 1.4535014629364014, 'learning_rate': 4.308713186285319e-07, 'epoch': 0.57}
{'loss': 1.0506, 'grad_norm': 1.421966552734375, 'learning_rate': 4.291546174379588e-07, 'epoch': 0.57}
{'loss': 1.2163, 'grad_norm': 1.711591362953186, 'learning_rate': 4.274387680803936e-07, 'epoch': 0.57}
{'loss': 1.1495, 'grad_norm': 1.309428095817566, 'learning_rate': 4.2572379118692155e-07, 'epoch': 0.57}
{'loss': 1.1626, 'grad_norm': 1.4007031917572021, 'learning_rate': 4.2400970737813736e-07, 'epoch': 0.57}
{'loss': 1.0267, 'grad_norm': 1.3456275463104248, 'learning_rate': 4.2229653726389756e-07, 'epoch': 0.57}
{'loss': 1.1202, 'grad_norm': 1.5559552907943726, 'learning_rate': 4.2058430144307236e-07, 'epoch': 0.57}
{'loss': 1.1868, 'grad_norm': 1.453204870223999, 'learning_rate': 4.188730205032986e-07, 'epoch': 0.57}
{'loss': 1.0999, 'grad_norm': 1.6713043451309204, 'learning_rate': 4.1716271502073136e-07, 'epoch': 0.58}
{'loss': 1.2431, 'grad_norm': 1.8050494194030762, 'learning_rate': 4.1545340555979724e-07, 'epoch': 0.58}
{'loss': 1.0857, 'grad_norm': 1.519552230834961, 'learning_rate': 4.1374511267294694e-07, 'epoch': 0.58}
{'loss': 1.0853, 'grad_norm': 1.352251648902893, 'learning_rate': 4.120378569004074e-07, 'epoch': 0.58}
{'loss': 1.045, 'grad_norm': 1.3186860084533691, 'learning_rate': 4.103316587699362e-07, 'epoch': 0.58}
{'loss': 1.0851, 'grad_norm': 1.307819128036499, 'learning_rate': 4.0862653879657373e-07, 'epoch': 0.58}
{'loss': 1.1567, 'grad_norm': 1.4205513000488281, 'learning_rate': 4.0692251748239677e-07, 'epoch': 0.58}
{'loss': 1.0278, 'grad_norm': 1.2778723239898682, 'learning_rate': 4.0521961531627205e-07, 'epoch': 0.58}
{'loss': 1.1675, 'grad_norm': 1.370963454246521, 'learning_rate': 4.0351785277360985e-07, 'epoch': 0.58}
{'loss': 1.0455, 'grad_norm': 1.4694985151290894, 'learning_rate': 4.018172503161179e-07, 'epoch': 0.58}
{'loss': 1.1933, 'grad_norm': 1.4533181190490723, 'learning_rate': 4.0011782839155514e-07, 'epoch': 0.59}
{'loss': 1.1387, 'grad_norm': 1.4256830215454102, 'learning_rate': 3.9841960743348594e-07, 'epoch': 0.59}
{'loss': 1.1292, 'grad_norm': 1.423826813697815, 'learning_rate': 3.967226078610346e-07, 'epoch': 0.59}
{'loss': 1.0929, 'grad_norm': 1.5028917789459229, 'learning_rate': 3.9502685007863956e-07, 'epoch': 0.59}
{'loss': 1.1195, 'grad_norm': 1.3406870365142822, 'learning_rate': 3.933323544758082e-07, 'epoch': 0.59}
{'loss': 1.1593, 'grad_norm': 1.387030005455017, 'learning_rate': 3.9163914142687177e-07, 'epoch': 0.59}
{'loss': 1.0519, 'grad_norm': 1.438875675201416, 'learning_rate': 3.899472312907401e-07, 'epoch': 0.59}
{'loss': 1.0809, 'grad_norm': 3.407228946685791, 'learning_rate': 3.882566444106573e-07, 'epoch': 0.59}
{'loss': 1.1325, 'grad_norm': 1.3351715803146362, 'learning_rate': 3.8656740111395663e-07, 'epoch': 0.59}
{'loss': 1.1113, 'grad_norm': 1.470458745956421, 'learning_rate': 3.8487952171181647e-07, 'epoch': 0.6}
{'loss': 1.0782, 'grad_norm': 1.3969860076904297, 'learning_rate': 3.831930264990158e-07, 'epoch': 0.6}
{'loss': 1.1557, 'grad_norm': 1.3640491962432861, 'learning_rate': 3.815079357536906e-07, 'epoch': 0.6}
{'loss': 1.0153, 'grad_norm': 1.3967982530593872, 'learning_rate': 3.7982426973708944e-07, 'epoch': 0.6}
{'loss': 1.1584, 'grad_norm': 1.3644036054611206, 'learning_rate': 3.7814204869333044e-07, 'epoch': 0.6}
{'loss': 1.1996, 'grad_norm': 1.3812968730926514, 'learning_rate': 3.764612928491575e-07, 'epoch': 0.6}
{'loss': 1.028, 'grad_norm': 1.3297370672225952, 'learning_rate': 3.747820224136973e-07, 'epoch': 0.6}
{'loss': 1.1415, 'grad_norm': 1.4096198081970215, 'learning_rate': 3.7310425757821604e-07, 'epoch': 0.6}
{'loss': 1.0864, 'grad_norm': 1.3040324449539185, 'learning_rate': 3.7142801851587705e-07, 'epoch': 0.6}
{'loss': 1.3051, 'grad_norm': 1.464391827583313, 'learning_rate': 3.6975332538149795e-07, 'epoch': 0.6}
{'loss': 1.1032, 'grad_norm': 1.404902696609497, 'learning_rate': 3.680801983113082e-07, 'epoch': 0.61}
{'loss': 1.0616, 'grad_norm': 7.067348957061768, 'learning_rate': 3.664086574227075e-07, 'epoch': 0.61}
{'loss': 1.062, 'grad_norm': 1.3243297338485718, 'learning_rate': 3.647387228140232e-07, 'epoch': 0.61}
{'loss': 1.1775, 'grad_norm': 1.4244977235794067, 'learning_rate': 3.630704145642694e-07, 'epoch': 0.61}
{'loss': 1.1194, 'grad_norm': 1.5934264659881592, 'learning_rate': 3.6140375273290473e-07, 'epoch': 0.61}
{'loss': 1.157, 'grad_norm': 1.452355980873108, 'learning_rate': 3.597387573595919e-07, 'epoch': 0.61}
{'loss': 1.082, 'grad_norm': 1.5442532300949097, 'learning_rate': 3.580754484639561e-07, 'epoch': 0.61}
{'loss': 1.0023, 'grad_norm': 1.2964520454406738, 'learning_rate': 3.56413846045345e-07, 'epoch': 0.61}
{'loss': 1.103, 'grad_norm': 1.317363977432251, 'learning_rate': 3.547539700825874e-07, 'epoch': 0.61}
{'loss': 1.1054, 'grad_norm': 4.787823677062988, 'learning_rate': 3.5309584053375384e-07, 'epoch': 0.62}
{'loss': 1.1406, 'grad_norm': 1.4615896940231323, 'learning_rate': 3.5143947733591626e-07, 'epoch': 0.62}
{'loss': 1.1239, 'grad_norm': 1.3498258590698242, 'learning_rate': 3.49784900404908e-07, 'epoch': 0.62}
{'loss': 1.1638, 'grad_norm': 1.9671499729156494, 'learning_rate': 3.481321296350851e-07, 'epoch': 0.62}
{'loss': 1.1319, 'grad_norm': 1.4014774560928345, 'learning_rate': 3.4648118489908584e-07, 'epoch': 0.62}
{'loss': 1.1928, 'grad_norm': 1.4042649269104004, 'learning_rate': 3.448320860475934e-07, 'epoch': 0.62}
{'loss': 1.1201, 'grad_norm': 1.4016966819763184, 'learning_rate': 3.43184852909096e-07, 'epoch': 0.62}
{'loss': 1.0847, 'grad_norm': 2.5181097984313965, 'learning_rate': 3.4153950528964866e-07, 'epoch': 0.62}
{'loss': 1.1646, 'grad_norm': 1.878809928894043, 'learning_rate': 3.3989606297263573e-07, 'epoch': 0.62}
{'loss': 1.2032, 'grad_norm': 1.907006859779358, 'learning_rate': 3.382545457185321e-07, 'epoch': 0.62}
{'loss': 1.1034, 'grad_norm': 1.3165946006774902, 'learning_rate': 3.3661497326466607e-07, 'epoch': 0.63}
{'loss': 1.1056, 'grad_norm': 1.3679612874984741, 'learning_rate': 3.349773653249822e-07, 'epoch': 0.63}
{'loss': 1.1652, 'grad_norm': 1.4294955730438232, 'learning_rate': 3.333417415898039e-07, 'epoch': 0.63}
{'loss': 1.1603, 'grad_norm': 1.3445024490356445, 'learning_rate': 3.317081217255969e-07, 'epoch': 0.63}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-600/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-600/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-600/model.safetensors.index.json.
2024-11-30 21:06:31,019 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-600/pytorch_model_fsdp.bin
2024-11-30 21:07:23,507 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-600/pytorch_model_fsdp.bin
2024-11-30 21:07:54,794 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-600/optimizer.bin
2024-11-30 21:09:37,095 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-600/optimizer.bin
                                                                                                             
{'loss': 1.0951, 'grad_norm': 1.4358769655227661, 'learning_rate': 3.300765253747326e-07, 'epoch': 0.63}
{'loss': 1.0725, 'grad_norm': 1.4579644203186035, 'learning_rate': 3.2844697215525217e-07, 'epoch': 0.63}
{'loss': 1.051, 'grad_norm': 1.3397283554077148, 'learning_rate': 3.2681948166063046e-07, 'epoch': 0.63}
{'loss': 1.1525, 'grad_norm': 1.391255497932434, 'learning_rate': 3.2519407345954043e-07, 'epoch': 0.63}
{'loss': 1.0989, 'grad_norm': 2.998904228210449, 'learning_rate': 3.235707670956178e-07, 'epoch': 0.63}
{'loss': 1.156, 'grad_norm': 1.3593924045562744, 'learning_rate': 3.219495820872265e-07, 'epoch': 0.63}
{'loss': 1.1629, 'grad_norm': 1.3528687953948975, 'learning_rate': 3.203305379272232e-07, 'epoch': 0.64}
{'loss': 1.094, 'grad_norm': 1.6196832656860352, 'learning_rate': 3.1871365408272367e-07, 'epoch': 0.64}
{'loss': 0.9726, 'grad_norm': 1.3008549213409424, 'learning_rate': 3.1709894999486825e-07, 'epoch': 0.64}
{'loss': 1.0544, 'grad_norm': 1.4196456670761108, 'learning_rate': 3.1548644507858845e-07, 'epoch': 0.64}
{'loss': 1.0417, 'grad_norm': 1.5122814178466797, 'learning_rate': 3.138761587223729e-07, 'epoch': 0.64}
{'loss': 1.1481, 'grad_norm': 1.3863886594772339, 'learning_rate': 3.1226811028803514e-07, 'epoch': 0.64}
{'loss': 1.1276, 'grad_norm': 1.331308364868164, 'learning_rate': 3.1066231911047994e-07, 'epoch': 0.64}
{'loss': 1.1543, 'grad_norm': 1.5358537435531616, 'learning_rate': 3.0905880449747134e-07, 'epoch': 0.64}
{'loss': 1.0312, 'grad_norm': 22.3935546875, 'learning_rate': 3.074575857294004e-07, 'epoch': 0.64}
{'loss': 1.1011, 'grad_norm': 1.3539777994155884, 'learning_rate': 3.058586820590532e-07, 'epoch': 0.65}
{'loss': 1.0506, 'grad_norm': 1.3519518375396729, 'learning_rate': 3.042621127113796e-07, 'epoch': 0.65}
{'loss': 1.1722, 'grad_norm': 1.4301261901855469, 'learning_rate': 3.026678968832618e-07, 'epoch': 0.65}
{'loss': 1.1431, 'grad_norm': 1.3110843896865845, 'learning_rate': 3.010760537432839e-07, 'epoch': 0.65}
{'loss': 1.1755, 'grad_norm': 1.3473693132400513, 'learning_rate': 2.994866024315009e-07, 'epoch': 0.65}
{'loss': 1.0899, 'grad_norm': 2.3831632137298584, 'learning_rate': 2.978995620592092e-07, 'epoch': 0.65}
{'loss': 1.1308, 'grad_norm': 1.4823248386383057, 'learning_rate': 2.96314951708716e-07, 'epoch': 0.65}
{'loss': 1.1215, 'grad_norm': 1.5991544723510742, 'learning_rate': 2.947327904331109e-07, 'epoch': 0.65}
{'loss': 1.0967, 'grad_norm': 6.043533802032471, 'learning_rate': 2.9315309725603594e-07, 'epoch': 0.65}
{'loss': 1.103, 'grad_norm': 1.4031413793563843, 'learning_rate': 2.91575891171457e-07, 'epoch': 0.65}
{'loss': 1.1341, 'grad_norm': 1.416000247001648, 'learning_rate': 2.900011911434358e-07, 'epoch': 0.66}
{'loss': 1.0995, 'grad_norm': 1.702640175819397, 'learning_rate': 2.8842901610590164e-07, 'epoch': 0.66}
{'loss': 1.1414, 'grad_norm': 1.4599758386611938, 'learning_rate': 2.8685938496242367e-07, 'epoch': 0.66}
{'loss': 1.1306, 'grad_norm': 1.349745750427246, 'learning_rate': 2.8529231658598376e-07, 'epoch': 0.66}
{'loss': 1.1023, 'grad_norm': 1.3645001649856567, 'learning_rate': 2.837278298187496e-07, 'epoch': 0.66}
{'loss': 1.1296, 'grad_norm': 1.5766379833221436, 'learning_rate': 2.8216594347184753e-07, 'epoch': 0.66}
{'loss': 1.2479, 'grad_norm': 1.8689384460449219, 'learning_rate': 2.8060667632513755e-07, 'epoch': 0.66}
{'loss': 1.1586, 'grad_norm': 1.391266107559204, 'learning_rate': 2.7905004712698645e-07, 'epoch': 0.66}
{'loss': 1.0743, 'grad_norm': 1.3237627744674683, 'learning_rate': 2.774960745940428e-07, 'epoch': 0.66}
{'loss': 1.0096, 'grad_norm': 1.4230881929397583, 'learning_rate': 2.75944777411012e-07, 'epoch': 0.67}
{'loss': 1.1105, 'grad_norm': 1.3149902820587158, 'learning_rate': 2.743961742304314e-07, 'epoch': 0.67}
{'loss': 1.1162, 'grad_norm': 1.6314085721969604, 'learning_rate': 2.728502836724462e-07, 'epoch': 0.67}
{'loss': 1.1, 'grad_norm': 1.9926799535751343, 'learning_rate': 2.7130712432458536e-07, 'epoch': 0.67}
{'loss': 1.0637, 'grad_norm': 1.2834380865097046, 'learning_rate': 2.6976671474153823e-07, 'epoch': 0.67}
{'loss': 1.2255, 'grad_norm': 1.4638795852661133, 'learning_rate': 2.682290734449314e-07, 'epoch': 0.67}
{'loss': 1.2432, 'grad_norm': 1.7485393285751343, 'learning_rate': 2.6669421892310653e-07, 'epoch': 0.67}
{'loss': 1.0985, 'grad_norm': 1.4749459028244019, 'learning_rate': 2.6516216963089693e-07, 'epoch': 0.67}
{'loss': 1.1286, 'grad_norm': 1.4506988525390625, 'learning_rate': 2.636329439894066e-07, 'epoch': 0.67}
{'loss': 1.0817, 'grad_norm': 1.3634785413742065, 'learning_rate': 2.621065603857884e-07, 'epoch': 0.67}
{'loss': 1.0562, 'grad_norm': 1.4087048768997192, 'learning_rate': 2.6058303717302286e-07, 'epoch': 0.68}
{'loss': 1.1626, 'grad_norm': 1.437658667564392, 'learning_rate': 2.5906239266969806e-07, 'epoch': 0.68}
{'loss': 1.0913, 'grad_norm': 1.7374893426895142, 'learning_rate': 2.575446451597884e-07, 'epoch': 0.68}
{'loss': 1.0958, 'grad_norm': 1.4390497207641602, 'learning_rate': 2.5602981289243577e-07, 'epoch': 0.68}
{'loss': 1.1061, 'grad_norm': 3.650061845779419, 'learning_rate': 2.5451791408172966e-07, 'epoch': 0.68}
{'loss': 1.056, 'grad_norm': 2.8430838584899902, 'learning_rate': 2.5300896690648764e-07, 'epoch': 0.68}
{'loss': 1.1499, 'grad_norm': 1.370294451713562, 'learning_rate': 2.515029895100378e-07, 'epoch': 0.68}
{'loss': 1.1314, 'grad_norm': 2.3863515853881836, 'learning_rate': 2.500000000000001e-07, 'epoch': 0.68}
{'loss': 1.1328, 'grad_norm': 1.4344159364700317, 'learning_rate': 2.4850001644806845e-07, 'epoch': 0.68}
{'loss': 1.1009, 'grad_norm': 1.3568110466003418, 'learning_rate': 2.4700305688979376e-07, 'epoch': 0.69}
{'loss': 1.1543, 'grad_norm': 2.3549036979675293, 'learning_rate': 2.455091393243669e-07, 'epoch': 0.69}
{'loss': 1.1239, 'grad_norm': 1.5745322704315186, 'learning_rate': 2.4401828171440235e-07, 'epoch': 0.69}
{'loss': 1.0987, 'grad_norm': 1.5042476654052734, 'learning_rate': 2.4253050198572216e-07, 'epoch': 0.69}
{'loss': 1.1571, 'grad_norm': 1.3549270629882812, 'learning_rate': 2.4104581802714045e-07, 'epoch': 0.69}
{'loss': 1.152, 'grad_norm': 1.3977094888687134, 'learning_rate': 2.3956424769024843e-07, 'epoch': 0.69}
{'loss': 1.0759, 'grad_norm': 1.3403342962265015, 'learning_rate': 2.3808580878919941e-07, 'epoch': 0.69}
{'loss': 1.0446, 'grad_norm': 1.4448432922363281, 'learning_rate': 2.3661051910049517e-07, 'epoch': 0.69}
{'loss': 1.147, 'grad_norm': 1.747083306312561, 'learning_rate': 2.3513839636277156e-07, 'epoch': 0.69}
{'loss': 1.062, 'grad_norm': 1.322283387184143, 'learning_rate': 2.3366945827658568e-07, 'epoch': 0.69}
{'loss': 1.0894, 'grad_norm': 1.3109335899353027, 'learning_rate': 2.32203722504203e-07, 'epoch': 0.7}
{'loss': 1.0512, 'grad_norm': 1.332292079925537, 'learning_rate': 2.3074120666938485e-07, 'epoch': 0.7}
{'loss': 1.1209, 'grad_norm': 1.570302963256836, 'learning_rate': 2.292819283571764e-07, 'epoch': 0.7}
{'loss': 1.0675, 'grad_norm': 1.3767755031585693, 'learning_rate': 2.2782590511369548e-07, 'epoch': 0.7}
{'loss': 1.2168, 'grad_norm': 1.6392961740493774, 'learning_rate': 2.263731544459219e-07, 'epoch': 0.7}
{'loss': 1.1411, 'grad_norm': 1.3237941265106201, 'learning_rate': 2.2492369382148628e-07, 'epoch': 0.7}
{'loss': 1.0681, 'grad_norm': 1.3856724500656128, 'learning_rate': 2.2347754066845986e-07, 'epoch': 0.7}
{'loss': 1.1504, 'grad_norm': 1.6153544187545776, 'learning_rate': 2.2203471237514603e-07, 'epoch': 0.7}
{'loss': 1.1259, 'grad_norm': 1.4626446962356567, 'learning_rate': 2.2059522628987037e-07, 'epoch': 0.7}
{'loss': 1.0259, 'grad_norm': 1.5069693326950073, 'learning_rate': 2.191590997207724e-07, 'epoch': 0.71}
{'loss': 1.0892, 'grad_norm': 1.7602970600128174, 'learning_rate': 2.1772634993559725e-07, 'epoch': 0.71}
{'loss': 1.1541, 'grad_norm': 3.365041732788086, 'learning_rate': 2.1629699416148829e-07, 'epoch': 0.71}
{'loss': 1.1188, 'grad_norm': 1.2946807146072388, 'learning_rate': 2.1487104958477986e-07, 'epoch': 0.71}
{'loss': 1.0932, 'grad_norm': 1.4399632215499878, 'learning_rate': 2.1344853335079048e-07, 'epoch': 0.71}
{'loss': 1.1564, 'grad_norm': 1.3662229776382446, 'learning_rate': 2.1202946256361708e-07, 'epoch': 0.71}
{'loss': 1.1291, 'grad_norm': 25.362911224365234, 'learning_rate': 2.1061385428592898e-07, 'epoch': 0.71}
{'loss': 1.111, 'grad_norm': 2.349546194076538, 'learning_rate': 2.0920172553876285e-07, 'epoch': 0.71}
{'loss': 1.0803, 'grad_norm': 1.3347699642181396, 'learning_rate': 2.0779309330131816e-07, 'epoch': 0.71}
{'loss': 1.1627, 'grad_norm': 3.2735514640808105, 'learning_rate': 2.0638797451075284e-07, 'epoch': 0.71}
{'loss': 1.0671, 'grad_norm': 2.8925061225891113, 'learning_rate': 2.0498638606197981e-07, 'epoch': 0.72}
{'loss': 1.1238, 'grad_norm': 1.3986573219299316, 'learning_rate': 2.0358834480746363e-07, 'epoch': 0.72}
{'loss': 1.1343, 'grad_norm': 1.883472204208374, 'learning_rate': 2.0219386755701812e-07, 'epoch': 0.72}
{'loss': 1.1922, 'grad_norm': 1.959173321723938, 'learning_rate': 2.0080297107760408e-07, 'epoch': 0.72}
{'loss': 1.068, 'grad_norm': 1.4558504819869995, 'learning_rate': 1.9941567209312766e-07, 'epoch': 0.72}
{'loss': 1.0096, 'grad_norm': 1.296785593032837, 'learning_rate': 1.9803198728423936e-07, 'epoch': 0.72}
{'loss': 1.0494, 'grad_norm': 1.45875084400177, 'learning_rate': 1.9665193328813345e-07, 'epoch': 0.72}
{'loss': 1.0681, 'grad_norm': 2.0234267711639404, 'learning_rate': 1.9527552669834797e-07, 'epoch': 0.72}
{'loss': 1.2018, 'grad_norm': 1.4007333517074585, 'learning_rate': 1.9390278406456506e-07, 'epoch': 0.72}
{'loss': 1.1134, 'grad_norm': 1.3256486654281616, 'learning_rate': 1.9253372189241212e-07, 'epoch': 0.73}
{'loss': 1.0856, 'grad_norm': 1.3854942321777344, 'learning_rate': 1.9116835664326324e-07, 'epoch': 0.73}
{'loss': 1.168, 'grad_norm': 3.3600826263427734, 'learning_rate': 1.898067047340415e-07, 'epoch': 0.73}
{'loss': 1.0946, 'grad_norm': 1.3252280950546265, 'learning_rate': 1.884487825370211e-07, 'epoch': 0.73}
{'loss': 1.1505, 'grad_norm': 1.3764479160308838, 'learning_rate': 1.8709460637963122e-07, 'epoch': 0.73}
{'loss': 1.084, 'grad_norm': 1.3825085163116455, 'learning_rate': 1.8574419254425878e-07, 'epoch': 0.73}
{'loss': 1.123, 'grad_norm': 1.3921116590499878, 'learning_rate': 1.8439755726805362e-07, 'epoch': 0.73}
{'loss': 1.0856, 'grad_norm': 1.3273546695709229, 'learning_rate': 1.830547167427326e-07, 'epoch': 0.73}
{'loss': 1.0692, 'grad_norm': 1.3226258754730225, 'learning_rate': 1.8171568711438512e-07, 'epoch': 0.73}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-700/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-700/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-700/model.safetensors.index.json.
2024-11-30 21:24:46,378 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-700/pytorch_model_fsdp.bin
2024-11-30 21:25:32,472 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-700/pytorch_model_fsdp.bin
2024-11-30 21:26:02,901 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-700/optimizer.bin
2024-11-30 21:27:43,367 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-700/optimizer.bin
                                                                                                             
{'loss': 1.1035, 'grad_norm': 1.3592312335968018, 'learning_rate': 1.8038048448327908e-07, 'epoch': 0.73}
{'loss': 1.1184, 'grad_norm': 1.385799765586853, 'learning_rate': 1.790491249036672e-07, 'epoch': 0.74}
{'loss': 1.0668, 'grad_norm': 1.3663750886917114, 'learning_rate': 1.777216243835939e-07, 'epoch': 0.74}
{'loss': 1.1126, 'grad_norm': 1.624414324760437, 'learning_rate': 1.7639799888470303e-07, 'epoch': 0.74}
{'loss': 1.1698, 'grad_norm': 1.373185634613037, 'learning_rate': 1.750782643220457e-07, 'epoch': 0.74}
{'loss': 1.1589, 'grad_norm': 1.4867254495620728, 'learning_rate': 1.7376243656388922e-07, 'epoch': 0.74}
{'loss': 1.0919, 'grad_norm': 1.4099520444869995, 'learning_rate': 1.7245053143152605e-07, 'epoch': 0.74}
{'loss': 1.0426, 'grad_norm': 1.338454008102417, 'learning_rate': 1.7114256469908379e-07, 'epoch': 0.74}
{'loss': 1.1091, 'grad_norm': 1.3803753852844238, 'learning_rate': 1.698385520933349e-07, 'epoch': 0.74}
{'loss': 1.172, 'grad_norm': 2.0770175457000732, 'learning_rate': 1.6853850929350866e-07, 'epoch': 0.74}
{'loss': 1.0895, 'grad_norm': 1.371037483215332, 'learning_rate': 1.6724245193110177e-07, 'epoch': 0.74}
{'loss': 1.0946, 'grad_norm': 2.29046893119812, 'learning_rate': 1.6595039558969082e-07, 'epoch': 0.75}
{'loss': 1.1681, 'grad_norm': 1.5740257501602173, 'learning_rate': 1.6466235580474473e-07, 'epoch': 0.75}
{'loss': 1.1234, 'grad_norm': 1.6992624998092651, 'learning_rate': 1.633783480634378e-07, 'epoch': 0.75}
{'loss': 1.2079, 'grad_norm': 1.3800467252731323, 'learning_rate': 1.6209838780446438e-07, 'epoch': 0.75}
{'loss': 1.1358, 'grad_norm': 1.4889637231826782, 'learning_rate': 1.6082249041785195e-07, 'epoch': 0.75}
{'loss': 1.1134, 'grad_norm': 1.279651165008545, 'learning_rate': 1.5955067124477677e-07, 'epoch': 0.75}
{'loss': 1.1605, 'grad_norm': 1.2912602424621582, 'learning_rate': 1.5828294557737959e-07, 'epoch': 0.75}
{'loss': 1.1197, 'grad_norm': 1.4761180877685547, 'learning_rate': 1.570193286585813e-07, 'epoch': 0.75}
{'loss': 1.1603, 'grad_norm': 1.4706209897994995, 'learning_rate': 1.5575983568189998e-07, 'epoch': 0.75}
{'loss': 1.0745, 'grad_norm': 5.001953125, 'learning_rate': 1.5450448179126823e-07, 'epoch': 0.76}
{'loss': 1.0663, 'grad_norm': 1.3800678253173828, 'learning_rate': 1.5325328208085074e-07, 'epoch': 0.76}
{'loss': 1.1211, 'grad_norm': 1.3944848775863647, 'learning_rate': 1.520062515948632e-07, 'epoch': 0.76}
{'loss': 1.1562, 'grad_norm': 1.4344524145126343, 'learning_rate': 1.5076340532739123e-07, 'epoch': 0.76}
{'loss': 1.1463, 'grad_norm': 1.3785345554351807, 'learning_rate': 1.4952475822221005e-07, 'epoch': 0.76}
{'loss': 1.0908, 'grad_norm': 1.2634081840515137, 'learning_rate': 1.4829032517260488e-07, 'epoch': 0.76}
{'loss': 1.1736, 'grad_norm': 1.3785531520843506, 'learning_rate': 1.4706012102119187e-07, 'epoch': 0.76}
{'loss': 1.1554, 'grad_norm': 1.5074028968811035, 'learning_rate': 1.4583416055973973e-07, 'epoch': 0.76}
{'loss': 1.1529, 'grad_norm': 1.3152947425842285, 'learning_rate': 1.4461245852899128e-07, 'epoch': 0.76}
{'loss': 1.0659, 'grad_norm': 1.3634711503982544, 'learning_rate': 1.433950296184872e-07, 'epoch': 0.76}
{'loss': 1.1119, 'grad_norm': 1.3235942125320435, 'learning_rate': 1.421818884663886e-07, 'epoch': 0.77}
{'loss': 1.057, 'grad_norm': 1.2865357398986816, 'learning_rate': 1.4097304965930156e-07, 'epoch': 0.77}
{'loss': 1.2255, 'grad_norm': 1.8436073064804077, 'learning_rate': 1.3976852773210123e-07, 'epoch': 0.77}
{'loss': 1.1766, 'grad_norm': 1.4437534809112549, 'learning_rate': 1.3856833716775745e-07, 'epoch': 0.77}
{'loss': 1.1258, 'grad_norm': 1.3415988683700562, 'learning_rate': 1.3737249239716041e-07, 'epoch': 0.77}
{'loss': 1.1765, 'grad_norm': 1.3307641744613647, 'learning_rate': 1.3618100779894725e-07, 'epoch': 0.77}
{'loss': 1.1586, 'grad_norm': 1.486362099647522, 'learning_rate': 1.3499389769932906e-07, 'epoch': 0.77}
{'loss': 1.035, 'grad_norm': 1.4883021116256714, 'learning_rate': 1.3381117637191886e-07, 'epoch': 0.77}
{'loss': 1.2125, 'grad_norm': 1.5095936059951782, 'learning_rate': 1.3263285803755965e-07, 'epoch': 0.77}
{'loss': 1.0875, 'grad_norm': 1.3781737089157104, 'learning_rate': 1.3145895686415353e-07, 'epoch': 0.78}
{'loss': 1.0548, 'grad_norm': 1.8256901502609253, 'learning_rate': 1.3028948696649162e-07, 'epoch': 0.78}
{'loss': 1.0779, 'grad_norm': 1.6327755451202393, 'learning_rate': 1.2912446240608381e-07, 'epoch': 0.78}
{'loss': 1.0878, 'grad_norm': 1.4557565450668335, 'learning_rate': 1.279638971909905e-07, 'epoch': 0.78}
{'loss': 1.1989, 'grad_norm': 1.6435645818710327, 'learning_rate': 1.268078052756531e-07, 'epoch': 0.78}
{'loss': 1.1524, 'grad_norm': 1.3405214548110962, 'learning_rate': 1.256562005607272e-07, 'epoch': 0.78}
{'loss': 1.0628, 'grad_norm': 1.475021481513977, 'learning_rate': 1.245090968929148e-07, 'epoch': 0.78}
{'loss': 1.1229, 'grad_norm': 1.8506531715393066, 'learning_rate': 1.2336650806479827e-07, 'epoch': 0.78}
{'loss': 1.1272, 'grad_norm': 1.419731855392456, 'learning_rate': 1.2222844781467428e-07, 'epoch': 0.78}
{'loss': 1.0868, 'grad_norm': 1.4201738834381104, 'learning_rate': 1.2109492982638837e-07, 'epoch': 0.78}
{'loss': 1.1025, 'grad_norm': 3.1253836154937744, 'learning_rate': 1.199659677291709e-07, 'epoch': 0.79}
{'loss': 1.1563, 'grad_norm': 1.410901665687561, 'learning_rate': 1.1884157509747305e-07, 'epoch': 0.79}
{'loss': 1.113, 'grad_norm': 1.7312721014022827, 'learning_rate': 1.1772176545080332e-07, 'epoch': 0.79}
{'loss': 1.021, 'grad_norm': 1.332049012184143, 'learning_rate': 1.166065522535653e-07, 'epoch': 0.79}
{'loss': 1.0718, 'grad_norm': 2.3469271659851074, 'learning_rate': 1.1549594891489561e-07, 'epoch': 0.79}
{'loss': 1.1071, 'grad_norm': 1.3626885414123535, 'learning_rate': 1.1438996878850265e-07, 'epoch': 0.79}
{'loss': 1.1576, 'grad_norm': 1.460586667060852, 'learning_rate': 1.1328862517250609e-07, 'epoch': 0.79}
{'loss': 1.0511, 'grad_norm': 1.4998201131820679, 'learning_rate': 1.1219193130927706e-07, 'epoch': 0.79}
{'loss': 1.0403, 'grad_norm': 2.5249083042144775, 'learning_rate': 1.1109990038527878e-07, 'epoch': 0.79}
{'loss': 1.0571, 'grad_norm': 1.3027900457382202, 'learning_rate': 1.1001254553090811e-07, 'epoch': 0.8}
{'loss': 1.1033, 'grad_norm': 1.3061881065368652, 'learning_rate': 1.0892987982033757e-07, 'epoch': 0.8}
{'loss': 1.2425, 'grad_norm': 1.3867131471633911, 'learning_rate': 1.078519162713582e-07, 'epoch': 0.8}
{'loss': 1.1369, 'grad_norm': 2.1184682846069336, 'learning_rate': 1.0677866784522316e-07, 'epoch': 0.8}
{'loss': 1.1016, 'grad_norm': 1.515998125076294, 'learning_rate': 1.057101474464916e-07, 'epoch': 0.8}
{'loss': 1.0934, 'grad_norm': 2.4989230632781982, 'learning_rate': 1.0464636792287379e-07, 'epoch': 0.8}
{'loss': 1.1757, 'grad_norm': 1.6517677307128906, 'learning_rate': 1.0358734206507641e-07, 'epoch': 0.8}
{'loss': 1.155, 'grad_norm': 1.577856183052063, 'learning_rate': 1.02533082606649e-07, 'epoch': 0.8}
{'loss': 1.1088, 'grad_norm': 1.44896399974823, 'learning_rate': 1.0148360222383045e-07, 'epoch': 0.8}
{'loss': 1.2231, 'grad_norm': 1.3551278114318848, 'learning_rate': 1.0043891353539718e-07, 'epoch': 0.8}
{'loss': 1.0537, 'grad_norm': 1.3730111122131348, 'learning_rate': 9.939902910251085e-08, 'epoch': 0.81}
{'loss': 1.0439, 'grad_norm': 2.4456734657287598, 'learning_rate': 9.836396142856762e-08, 'epoch': 0.81}
{'loss': 1.1638, 'grad_norm': 1.339796543121338, 'learning_rate': 9.733372295904773e-08, 'epoch': 0.81}
{'loss': 1.086, 'grad_norm': 1.4327524900436401, 'learning_rate': 9.630832608136597e-08, 'epoch': 0.81}
{'loss': 1.1709, 'grad_norm': 1.4519152641296387, 'learning_rate': 9.528778312472252e-08, 'epoch': 0.81}
{'loss': 1.088, 'grad_norm': 1.2985788583755493, 'learning_rate': 9.42721063599548e-08, 'epoch': 0.81}
{'loss': 1.145, 'grad_norm': 1.4749294519424438, 'learning_rate': 9.326130799939013e-08, 'epoch': 0.81}
{'loss': 1.0605, 'grad_norm': 1.449473261833191, 'learning_rate': 9.225540019669858e-08, 'epoch': 0.81}
{'loss': 1.0208, 'grad_norm': 1.451642632484436, 'learning_rate': 9.125439504674698e-08, 'epoch': 0.81}
{'loss': 1.1183, 'grad_norm': 3.0351035594940186, 'learning_rate': 9.025830458545359e-08, 'epoch': 0.82}
{'loss': 1.1349, 'grad_norm': 1.3147614002227783, 'learning_rate': 8.92671407896431e-08, 'epoch': 0.82}
{'loss': 1.0729, 'grad_norm': 1.4112811088562012, 'learning_rate': 8.828091557690287e-08, 'epoch': 0.82}
{'loss': 1.1455, 'grad_norm': 1.513427972793579, 'learning_rate': 8.729964080543972e-08, 'epoch': 0.82}
{'loss': 1.0735, 'grad_norm': 2.844594717025757, 'learning_rate': 8.632332827393702e-08, 'epoch': 0.82}
{'loss': 1.0516, 'grad_norm': 1.2864694595336914, 'learning_rate': 8.535198972141294e-08, 'epoch': 0.82}
{'loss': 1.1253, 'grad_norm': 1.3433232307434082, 'learning_rate': 8.43856368270796e-08, 'epoch': 0.82}
{'loss': 1.1039, 'grad_norm': 1.3522552251815796, 'learning_rate': 8.342428121020218e-08, 'epoch': 0.82}
{'loss': 1.0445, 'grad_norm': 1.684749960899353, 'learning_rate': 8.246793442995953e-08, 'epoch': 0.82}
{'loss': 1.1492, 'grad_norm': 2.8067526817321777, 'learning_rate': 8.151660798530524e-08, 'epoch': 0.82}
{'loss': 1.2507, 'grad_norm': 1.526605486869812, 'learning_rate': 8.057031331482878e-08, 'epoch': 0.83}
{'loss': 1.0751, 'grad_norm': 1.393904209136963, 'learning_rate': 7.962906179661871e-08, 'epoch': 0.83}
{'loss': 1.0713, 'grad_norm': 1.3977487087249756, 'learning_rate': 7.869286474812581e-08, 'epoch': 0.83}
{'loss': 1.1001, 'grad_norm': 1.3779118061065674, 'learning_rate': 7.776173342602633e-08, 'epoch': 0.83}
{'loss': 1.1037, 'grad_norm': 1.3611139059066772, 'learning_rate': 7.683567902608729e-08, 'epoch': 0.83}
{'loss': 1.0493, 'grad_norm': 1.3359087705612183, 'learning_rate': 7.591471268303157e-08, 'epoch': 0.83}
{'loss': 1.144, 'grad_norm': 1.358471155166626, 'learning_rate': 7.499884547040425e-08, 'epoch': 0.83}
{'loss': 1.029, 'grad_norm': 3.771933078765869, 'learning_rate': 7.408808840043912e-08, 'epoch': 0.83}
{'loss': 1.066, 'grad_norm': 1.3413604497909546, 'learning_rate': 7.318245242392657e-08, 'epoch': 0.83}
{'loss': 1.0627, 'grad_norm': 1.3771204948425293, 'learning_rate': 7.22819484300819e-08, 'epoch': 0.84}
{'loss': 1.0956, 'grad_norm': 1.4561355113983154, 'learning_rate': 7.138658724641417e-08, 'epoch': 0.84}
{'loss': 1.1301, 'grad_norm': 1.327978491783142, 'learning_rate': 7.049637963859617e-08, 'epoch': 0.84}
{'loss': 1.0564, 'grad_norm': 1.3443745374679565, 'learning_rate': 6.961133631033511e-08, 'epoch': 0.84}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-800/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-800/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-800/model.safetensors.index.json.
2024-11-30 21:42:42,341 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-800/pytorch_model_fsdp.bin
2024-11-30 21:43:24,147 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-800/pytorch_model_fsdp.bin
2024-11-30 21:43:54,869 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-800/optimizer.bin
2024-11-30 21:45:38,458 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-800/optimizer.bin
                                                                                                             
{'loss': 1.0686, 'grad_norm': 1.5528508424758911, 'learning_rate': 6.873146790324358e-08, 'epoch': 0.84}
{'loss': 1.1923, 'grad_norm': 1.3804346323013306, 'learning_rate': 6.785678499671183e-08, 'epoch': 0.84}
{'loss': 1.1477, 'grad_norm': 1.6604335308074951, 'learning_rate': 6.698729810778064e-08, 'epoch': 0.84}
{'loss': 1.0493, 'grad_norm': 1.9689428806304932, 'learning_rate': 6.612301769101464e-08, 'epoch': 0.84}
{'loss': 1.0865, 'grad_norm': 2.1819546222686768, 'learning_rate': 6.526395413837672e-08, 'epoch': 0.84}
{'loss': 1.1426, 'grad_norm': 1.3907197713851929, 'learning_rate': 6.441011777910299e-08, 'epoch': 0.84}
{'loss': 1.2031, 'grad_norm': 1.4419920444488525, 'learning_rate': 6.3561518879579e-08, 'epoch': 0.85}
{'loss': 1.1086, 'grad_norm': 1.2994612455368042, 'learning_rate': 6.271816764321541e-08, 'epoch': 0.85}
{'loss': 1.0014, 'grad_norm': 1.4233558177947998, 'learning_rate': 6.188007421032631e-08, 'epoch': 0.85}
{'loss': 1.0645, 'grad_norm': 1.4046592712402344, 'learning_rate': 6.104724865800664e-08, 'epoch': 0.85}
{'loss': 1.1318, 'grad_norm': 1.3820323944091797, 'learning_rate': 6.021970100001134e-08, 'epoch': 0.85}
{'loss': 1.0776, 'grad_norm': 1.5945476293563843, 'learning_rate': 5.9397441186634754e-08, 'epoch': 0.85}
{'loss': 1.1455, 'grad_norm': 1.453859806060791, 'learning_rate': 5.8580479104591075e-08, 'epoch': 0.85}
{'loss': 1.1274, 'grad_norm': 1.3346664905548096, 'learning_rate': 5.776882457689547e-08, 'epoch': 0.85}
{'loss': 1.081, 'grad_norm': 1.597977638244629, 'learning_rate': 5.6962487362746006e-08, 'epoch': 0.85}
{'loss': 1.1547, 'grad_norm': 1.3264515399932861, 'learning_rate': 5.6161477157406104e-08, 'epoch': 0.86}
{'loss': 1.1206, 'grad_norm': 6.175407886505127, 'learning_rate': 5.5365803592088426e-08, 'epoch': 0.86}
{'loss': 1.1189, 'grad_norm': 1.3620686531066895, 'learning_rate': 5.457547623383846e-08, 'epoch': 0.86}
{'loss': 1.0805, 'grad_norm': 3.3289923667907715, 'learning_rate': 5.379050458541995e-08, 'epoch': 0.86}
{'loss': 1.107, 'grad_norm': 1.448613166809082, 'learning_rate': 5.301089808520048e-08, 'epoch': 0.86}
{'loss': 1.0896, 'grad_norm': 1.4215328693389893, 'learning_rate': 5.223666610703797e-08, 'epoch': 0.86}
{'loss': 1.1364, 'grad_norm': 1.298403024673462, 'learning_rate': 5.146781796016797e-08, 'epoch': 0.86}
{'loss': 1.1755, 'grad_norm': 1.4047670364379883, 'learning_rate': 5.070436288909169e-08, 'epoch': 0.86}
{'loss': 1.1034, 'grad_norm': 2.0961999893188477, 'learning_rate': 4.9946310073465056e-08, 'epoch': 0.86}
{'loss': 1.1549, 'grad_norm': 2.3725318908691406, 'learning_rate': 4.9193668627988073e-08, 'epoch': 0.86}
{'loss': 1.0831, 'grad_norm': 1.3725816011428833, 'learning_rate': 4.844644760229544e-08, 'epoch': 0.87}
{'loss': 1.0427, 'grad_norm': 1.316699743270874, 'learning_rate': 4.770465598084733e-08, 'epoch': 0.87}
{'loss': 1.1018, 'grad_norm': 4.606015205383301, 'learning_rate': 4.6968302682822036e-08, 'epoch': 0.87}
{'loss': 1.1823, 'grad_norm': 1.4944013357162476, 'learning_rate': 4.62373965620082e-08, 'epoch': 0.87}
{'loss': 1.1811, 'grad_norm': 1.3956806659698486, 'learning_rate': 4.551194640669859e-08, 'epoch': 0.87}
{'loss': 1.142, 'grad_norm': 1.7316486835479736, 'learning_rate': 4.47919609395842e-08, 'epoch': 0.87}
{'loss': 1.0948, 'grad_norm': 2.425104856491089, 'learning_rate': 4.407744881764969e-08, 'epoch': 0.87}
{'loss': 1.0623, 'grad_norm': 1.330708622932434, 'learning_rate': 4.3368418632069137e-08, 'epoch': 0.87}
{'loss': 1.1486, 'grad_norm': 1.4343355894088745, 'learning_rate': 4.266487890810255e-08, 'epoch': 0.87}
{'loss': 1.1854, 'grad_norm': 1.45816969871521, 'learning_rate': 4.196683810499379e-08, 'epoch': 0.87}
{'loss': 1.104, 'grad_norm': 1.330538034439087, 'learning_rate': 4.127430461586845e-08, 'epoch': 0.88}
{'loss': 1.1063, 'grad_norm': 1.3767799139022827, 'learning_rate': 4.058728676763312e-08, 'epoch': 0.88}
{'loss': 1.199, 'grad_norm': 1.3525201082229614, 'learning_rate': 3.990579282087536e-08, 'epoch': 0.88}
{'loss': 1.0442, 'grad_norm': 1.4653611183166504, 'learning_rate': 3.9229830969764124e-08, 'epoch': 0.88}
{'loss': 1.1386, 'grad_norm': 2.36956524848938, 'learning_rate': 3.855940934195145e-08, 'epoch': 0.88}
{'loss': 1.1576, 'grad_norm': 1.518660068511963, 'learning_rate': 3.789453599847464e-08, 'epoch': 0.88}
{'loss': 1.161, 'grad_norm': 1.3230714797973633, 'learning_rate': 3.723521893365933e-08, 'epoch': 0.88}
{'loss': 1.0683, 'grad_norm': 2.4157936573028564, 'learning_rate': 3.658146607502344e-08, 'epoch': 0.88}
{'loss': 1.118, 'grad_norm': 1.3783823251724243, 'learning_rate': 3.5933285283181845e-08, 'epoch': 0.88}
{'loss': 1.1726, 'grad_norm': 1.4902067184448242, 'learning_rate': 3.52906843517517e-08, 'epoch': 0.89}
{'loss': 1.1031, 'grad_norm': 2.4256699085235596, 'learning_rate': 3.465367100725908e-08, 'epoch': 0.89}
{'loss': 1.0684, 'grad_norm': 1.3413046598434448, 'learning_rate': 3.4022252909045427e-08, 'epoch': 0.89}
{'loss': 1.0636, 'grad_norm': 1.672523856163025, 'learning_rate': 3.339643764917632e-08, 'epoch': 0.89}
{'loss': 1.1424, 'grad_norm': 1.3379656076431274, 'learning_rate': 3.277623275234953e-08, 'epoch': 0.89}
{'loss': 1.1954, 'grad_norm': 1.3575438261032104, 'learning_rate': 3.2161645675804764e-08, 'epoch': 0.89}
{'loss': 1.1371, 'grad_norm': 1.5034481287002563, 'learning_rate': 3.1552683809234095e-08, 'epoch': 0.89}
{'loss': 1.0905, 'grad_norm': 1.445383071899414, 'learning_rate': 3.0949354474692935e-08, 'epoch': 0.89}
{'loss': 1.0734, 'grad_norm': 1.379984974861145, 'learning_rate': 3.0351664926512085e-08, 'epoch': 0.89}
{'loss': 1.1619, 'grad_norm': 1.3010412454605103, 'learning_rate': 2.97596223512106e-08, 'epoch': 0.89}
{'loss': 1.1035, 'grad_norm': 1.34500253200531, 'learning_rate': 2.9173233867409053e-08, 'epoch': 0.9}
{'loss': 1.1061, 'grad_norm': 1.5507264137268066, 'learning_rate': 2.8592506525744464e-08, 'epoch': 0.9}
{'loss': 1.1192, 'grad_norm': 1.3278143405914307, 'learning_rate': 2.8017447308784914e-08, 'epoch': 0.9}
{'loss': 1.0991, 'grad_norm': 1.2881431579589844, 'learning_rate': 2.744806313094622e-08, 'epoch': 0.9}
{'loss': 1.0415, 'grad_norm': 1.3271667957305908, 'learning_rate': 2.688436083840817e-08, 'epoch': 0.9}
{'loss': 1.1579, 'grad_norm': 1.3388561010360718, 'learning_rate': 2.6326347209032817e-08, 'epoch': 0.9}
{'loss': 1.0897, 'grad_norm': 1.2861751317977905, 'learning_rate': 2.5774028952282424e-08, 'epoch': 0.9}
{'loss': 1.1704, 'grad_norm': 2.290670156478882, 'learning_rate': 2.522741270913914e-08, 'epoch': 0.9}
{'loss': 1.0854, 'grad_norm': 1.385036826133728, 'learning_rate': 2.4686505052025186e-08, 'epoch': 0.9}
{'loss': 1.1255, 'grad_norm': 1.3763989210128784, 'learning_rate': 2.4151312484723464e-08, 'epoch': 0.91}
{'loss': 1.0371, 'grad_norm': 1.307916522026062, 'learning_rate': 2.3621841442299784e-08, 'epoch': 0.91}
{'loss': 1.1683, 'grad_norm': 1.4202288389205933, 'learning_rate': 2.309809829102527e-08, 'epoch': 0.91}
{'loss': 1.0998, 'grad_norm': 1.3332490921020508, 'learning_rate': 2.2580089328299746e-08, 'epoch': 0.91}
{'loss': 1.0902, 'grad_norm': 1.3389654159545898, 'learning_rate': 2.206782078257613e-08, 'epoch': 0.91}
{'loss': 1.1671, 'grad_norm': 1.3875162601470947, 'learning_rate': 2.156129881328572e-08, 'epoch': 0.91}
{'loss': 1.145, 'grad_norm': 1.6596513986587524, 'learning_rate': 2.1060529510763648e-08, 'epoch': 0.91}
{'loss': 1.2098, 'grad_norm': 1.4077032804489136, 'learning_rate': 2.0565518896176137e-08, 'epoch': 0.91}
{'loss': 1.1546, 'grad_norm': 1.3269124031066895, 'learning_rate': 2.0076272921447923e-08, 'epoch': 0.91}
{'loss': 1.1378, 'grad_norm': 1.55902099609375, 'learning_rate': 1.9592797469190568e-08, 'epoch': 0.91}
{'loss': 1.1596, 'grad_norm': 1.4042515754699707, 'learning_rate': 1.9115098352631864e-08, 'epoch': 0.92}
{'loss': 1.1297, 'grad_norm': 1.3726861476898193, 'learning_rate': 1.8643181315545986e-08, 'epoch': 0.92}
{'loss': 1.1159, 'grad_norm': 1.458703637123108, 'learning_rate': 1.8177052032184282e-08, 'epoch': 0.92}
{'loss': 1.1151, 'grad_norm': 1.3846162557601929, 'learning_rate': 1.771671610720715e-08, 'epoch': 0.92}
{'loss': 1.1207, 'grad_norm': 1.4253169298171997, 'learning_rate': 1.7262179075616613e-08, 'epoch': 0.92}
{'loss': 1.1809, 'grad_norm': 1.3476823568344116, 'learning_rate': 1.681344640268978e-08, 'epoch': 0.92}
{'loss': 1.0455, 'grad_norm': 2.8380744457244873, 'learning_rate': 1.63705234839131e-08, 'epoch': 0.92}
{'loss': 1.1181, 'grad_norm': 1.6318374872207642, 'learning_rate': 1.5933415644917513e-08, 'epoch': 0.92}
{'loss': 1.0908, 'grad_norm': 1.4089199304580688, 'learning_rate': 1.5502128141414493e-08, 'epoch': 0.92}
{'loss': 1.1516, 'grad_norm': 1.6181522607803345, 'learning_rate': 1.5076666159132612e-08, 'epoch': 0.93}
{'loss': 1.1445, 'grad_norm': 1.3306185007095337, 'learning_rate': 1.465703481375552e-08, 'epoch': 0.93}
{'loss': 1.1737, 'grad_norm': 1.3268017768859863, 'learning_rate': 1.424323915086012e-08, 'epoch': 0.93}
{'loss': 1.1106, 'grad_norm': 2.1657238006591797, 'learning_rate': 1.3835284145856273e-08, 'epoch': 0.93}
{'loss': 1.1222, 'grad_norm': 1.4339584112167358, 'learning_rate': 1.343317470392641e-08, 'epoch': 0.93}
{'loss': 1.1012, 'grad_norm': 1.3976752758026123, 'learning_rate': 1.3036915659967118e-08, 'epoch': 0.93}
{'loss': 1.0914, 'grad_norm': 1.3307081460952759, 'learning_rate': 1.2646511778530822e-08, 'epoch': 0.93}
{'loss': 1.1141, 'grad_norm': 1.336745023727417, 'learning_rate': 1.226196775376831e-08, 'epoch': 0.93}
{'loss': 1.0532, 'grad_norm': 1.3235846757888794, 'learning_rate': 1.1883288209372511e-08, 'epoch': 0.93}
{'loss': 1.0712, 'grad_norm': 1.302215576171875, 'learning_rate': 1.1510477698522813e-08, 'epoch': 0.93}
{'loss': 1.1447, 'grad_norm': 1.7266119718551636, 'learning_rate': 1.1143540703830334e-08, 'epoch': 0.94}
{'loss': 1.1703, 'grad_norm': 1.4202823638916016, 'learning_rate': 1.0782481637284013e-08, 'epoch': 0.94}
{'loss': 1.1267, 'grad_norm': 1.4767225980758667, 'learning_rate': 1.0427304840197493e-08, 'epoch': 0.94}
{'loss': 1.0854, 'grad_norm': 1.3878824710845947, 'learning_rate': 1.0078014583157157e-08, 'epoch': 0.94}
{'loss': 1.1195, 'grad_norm': 1.404737114906311, 'learning_rate': 9.734615065970454e-09, 'epoch': 0.94}
{'loss': 1.1156, 'grad_norm': 1.3278034925460815, 'learning_rate': 9.397110417615706e-09, 'epoch': 0.94}
{'loss': 1.0292, 'grad_norm': 1.3830106258392334, 'learning_rate': 9.065504696192161e-09, 'epoch': 0.94}
{'loss': 1.1782, 'grad_norm': 1.3586174249649048, 'learning_rate': 8.739801888871468e-09, 'epoch': 0.94}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-900/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-900/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-900/model.safetensors.index.json.
2024-11-30 22:00:48,425 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-900/pytorch_model_fsdp.bin
2024-11-30 22:01:30,792 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-900/pytorch_model_fsdp.bin
2024-11-30 22:02:01,623 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-900/optimizer.bin
2024-11-30 22:03:25,866 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-900/optimizer.bin
                                                                                                             
{'loss': 1.1321, 'grad_norm': 1.2879804372787476, 'learning_rate': 8.420005911849659e-09, 'epoch': 0.94}
{'loss': 1.1292, 'grad_norm': 1.3095626831054688, 'learning_rate': 8.106120610299916e-09, 'epoch': 0.95}
{'loss': 1.1071, 'grad_norm': 1.3546383380889893, 'learning_rate': 7.798149758326488e-09, 'epoch': 0.95}
{'loss': 1.231, 'grad_norm': 1.4577304124832153, 'learning_rate': 7.496097058919348e-09, 'epoch': 0.95}
{'loss': 1.1023, 'grad_norm': 1.4337210655212402, 'learning_rate': 7.199966143909553e-09, 'epoch': 0.95}
{'loss': 1.101, 'grad_norm': 1.4237016439437866, 'learning_rate': 6.909760573925561e-09, 'epoch': 0.95}
{'loss': 1.1056, 'grad_norm': 1.3058758974075317, 'learning_rate': 6.625483838350487e-09, 'epoch': 0.95}
{'loss': 1.137, 'grad_norm': 1.35457181930542, 'learning_rate': 6.34713935528014e-09, 'epoch': 0.95}
{'loss': 1.1384, 'grad_norm': 1.4116020202636719, 'learning_rate': 6.074730471482048e-09, 'epoch': 0.95}
{'loss': 1.0476, 'grad_norm': 1.302923560142517, 'learning_rate': 5.8082604623548855e-09, 'epoch': 0.95}
{'loss': 1.1623, 'grad_norm': 1.337903380393982, 'learning_rate': 5.547732531889448e-09, 'epoch': 0.95}
{'loss': 1.1768, 'grad_norm': 1.3807066679000854, 'learning_rate': 5.293149812629849e-09, 'epoch': 0.96}
{'loss': 1.0965, 'grad_norm': 1.447983741760254, 'learning_rate': 5.04451536563616e-09, 'epoch': 0.96}
{'loss': 1.1736, 'grad_norm': 1.3502581119537354, 'learning_rate': 4.801832180447163e-09, 'epoch': 0.96}
{'loss': 1.1326, 'grad_norm': 1.7848103046417236, 'learning_rate': 4.565103175044882e-09, 'epoch': 0.96}
{'loss': 1.0894, 'grad_norm': 1.3322575092315674, 'learning_rate': 4.334331195819219e-09, 'epoch': 0.96}
{'loss': 1.0994, 'grad_norm': 1.6411346197128296, 'learning_rate': 4.109519017533758e-09, 'epoch': 0.96}
{'loss': 1.1322, 'grad_norm': 1.3490989208221436, 'learning_rate': 3.890669343292463e-09, 'epoch': 0.96}
{'loss': 1.1861, 'grad_norm': 1.9577617645263672, 'learning_rate': 3.6777848045071446e-09, 'epoch': 0.96}
{'loss': 1.1201, 'grad_norm': 2.5552902221679688, 'learning_rate': 3.47086796086582e-09, 'epoch': 0.96}
{'loss': 1.0918, 'grad_norm': 2.0492730140686035, 'learning_rate': 3.2699213003019588e-09, 'epoch': 0.97}
{'loss': 1.0993, 'grad_norm': 1.3589677810668945, 'learning_rate': 3.0749472389644535e-09, 'epoch': 0.97}
{'loss': 1.1644, 'grad_norm': 2.2198057174682617, 'learning_rate': 2.8859481211888635e-09, 'epoch': 0.97}
{'loss': 1.2469, 'grad_norm': 2.4734420776367188, 'learning_rate': 2.702926219468882e-09, 'epoch': 0.97}
{'loss': 1.0974, 'grad_norm': 1.336507797241211, 'learning_rate': 2.525883734429135e-09, 'epoch': 0.97}
{'loss': 1.1339, 'grad_norm': 1.3636499643325806, 'learning_rate': 2.3548227947988165e-09, 'epoch': 0.97}
{'loss': 1.1044, 'grad_norm': 1.7492423057556152, 'learning_rate': 2.1897454573860384e-09, 'epoch': 0.97}
{'loss': 1.054, 'grad_norm': 1.4241336584091187, 'learning_rate': 2.030653707052965e-09, 'epoch': 0.97}
{'loss': 1.2138, 'grad_norm': 1.3689281940460205, 'learning_rate': 1.8775494566921623e-09, 'epoch': 0.97}
{'loss': 1.0735, 'grad_norm': 1.60419499874115, 'learning_rate': 1.7304345472035631e-09, 'epoch': 0.97}
{'loss': 1.1533, 'grad_norm': 1.4980380535125732, 'learning_rate': 1.5893107474720947e-09, 'epoch': 0.98}
{'loss': 1.1349, 'grad_norm': 1.3407578468322754, 'learning_rate': 1.454179754346696e-09, 'epoch': 0.98}
{'loss': 1.1493, 'grad_norm': 3.4754061698913574, 'learning_rate': 1.3250431926197792e-09, 'epoch': 0.98}
{'loss': 1.0999, 'grad_norm': 1.4066343307495117, 'learning_rate': 1.2019026150077438e-09, 'epoch': 0.98}
{'loss': 1.1189, 'grad_norm': 1.3344956636428833, 'learning_rate': 1.084759502132271e-09, 'epoch': 0.98}
{'loss': 1.114, 'grad_norm': 1.2957440614700317, 'learning_rate': 9.73615262502503e-10, 'epoch': 0.98}
{'loss': 1.0701, 'grad_norm': 1.3066610097885132, 'learning_rate': 8.684712324981136e-10, 'epoch': 0.98}
{'loss': 1.1466, 'grad_norm': 1.3623522520065308, 'learning_rate': 7.693286763533757e-10, 'epoch': 0.98}
{'loss': 1.0746, 'grad_norm': 1.5345715284347534, 'learning_rate': 6.761887861417293e-10, 'epoch': 0.98}
{'loss': 1.0883, 'grad_norm': 1.3776084184646606, 'learning_rate': 5.89052681761626e-10, 'epoch': 0.98}
{'loss': 1.1402, 'grad_norm': 1.3916276693344116, 'learning_rate': 5.079214109229291e-10, 'epoch': 0.99}
{'loss': 1.111, 'grad_norm': 1.4794354438781738, 'learning_rate': 4.3279594913447904e-10, 'epoch': 0.99}
{'loss': 1.1017, 'grad_norm': 1.398354411125183, 'learning_rate': 3.636771996922694e-10, 'epoch': 0.99}
{'loss': 1.0649, 'grad_norm': 1.2602471113204956, 'learning_rate': 3.005659936685112e-10, 'epoch': 0.99}
{'loss': 1.1291, 'grad_norm': 1.3811615705490112, 'learning_rate': 2.43463089901752e-10, 'epoch': 0.99}
{'loss': 1.0501, 'grad_norm': 1.2980703115463257, 'learning_rate': 1.9236917498782757e-10, 'epoch': 0.99}
{'loss': 1.0719, 'grad_norm': 1.46356201171875, 'learning_rate': 1.4728486327136857e-10, 'epoch': 0.99}
{'loss': 1.1649, 'grad_norm': 1.4443113803863525, 'learning_rate': 1.0821069683852879e-10, 'epoch': 0.99}
{'loss': 1.1233, 'grad_norm': 1.3924908638000488, 'learning_rate': 7.514714551060119e-11, 'epoch': 0.99}
{'loss': 1.0422, 'grad_norm': 1.3565205335617065, 'learning_rate': 4.8094606838189335e-11, 'epoch': 1.0}
{'loss': 1.1244, 'grad_norm': 1.352023720741272, 'learning_rate': 2.7053406096433363e-11, 'epoch': 1.0}
{'loss': 1.153, 'grad_norm': 1.5556018352508545, 'learning_rate': 1.2023796281235288e-11, 'epoch': 1.0}
{'loss': 1.1428, 'grad_norm': 1.3698829412460327, 'learning_rate': 3.0059581060948303e-12, 'epoch': 1.0}
{'loss': 1.1131, 'grad_norm': 1.3391871452331543, 'learning_rate': 0.0, 'epoch': 1.0}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-954/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-954/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-954/model.safetensors.index.json.
2024-11-30 22:12:35,239 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-954/pytorch_model_fsdp.bin
2024-11-30 22:13:29,993 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-954/pytorch_model_fsdp.bin
2024-11-30 22:14:01,302 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-954/optimizer.bin
2024-11-30 22:15:26,552 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/checkpoint-954/optimizer.bin


Training completed. Do not forget to share your model on huggingface.co/models =)


100%|████████████████████████████████████████████████████████████████████| 954/954 [2:53:17<00:00, 10.90s/it]
{'train_runtime': 10406.8562, 'train_samples_per_second': 2.935, 'train_steps_per_second': 0.092, 'train_loss': 1.1593808374939725, 'epoch': 1.0}
Saving model checkpoint to /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/scaling-subsample_ratio0.25-instruct-ultrachat-train-lr1e-06-rt1-rr0.1-epochs1-bs128-wd0.01-warmup0.05-new_knowledgenewhandpicked_explicitnewslr5e06rt10rr0.1epochs1bs16wd0.01warmup0.05Llama3.18B/model.safetensors.index.json.
