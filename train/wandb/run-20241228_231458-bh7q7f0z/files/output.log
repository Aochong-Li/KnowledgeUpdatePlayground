                                                                                                                                                      
{'loss': 1.6052, 'grad_norm': 102.79218292236328, 'learning_rate': 3.448275862068965e-08, 'epoch': 0.01}
{'loss': 1.7853, 'grad_norm': 319.0646057128906, 'learning_rate': 6.89655172413793e-08, 'epoch': 0.01}
{'loss': 1.6202, 'grad_norm': 86.2231216430664, 'learning_rate': 1.0344827586206897e-07, 'epoch': 0.02}
{'loss': 1.6446, 'grad_norm': 120.29524230957031, 'learning_rate': 1.379310344827586e-07, 'epoch': 0.02}
{'loss': 1.6211, 'grad_norm': 15803.275390625, 'learning_rate': 1.7241379310344828e-07, 'epoch': 0.03}
{'loss': 1.5635, 'grad_norm': 43.78204345703125, 'learning_rate': 2.0689655172413793e-07, 'epoch': 0.03}
{'loss': 1.601, 'grad_norm': 279.64410400390625, 'learning_rate': 2.413793103448276e-07, 'epoch': 0.04}
{'loss': 1.6519, 'grad_norm': 57.51458740234375, 'learning_rate': 2.758620689655172e-07, 'epoch': 0.04}
{'loss': 1.535, 'grad_norm': 30.487398147583008, 'learning_rate': 3.103448275862069e-07, 'epoch': 0.05}
{'loss': 1.7675, 'grad_norm': 95.6241455078125, 'learning_rate': 3.4482758620689656e-07, 'epoch': 0.05}
{'loss': 1.9806, 'grad_norm': 3720.310791015625, 'learning_rate': 3.793103448275862e-07, 'epoch': 0.06}
{'loss': 1.6098, 'grad_norm': 8.334023475646973, 'learning_rate': 4.1379310344827586e-07, 'epoch': 0.06}
{'loss': 1.8395, 'grad_norm': 60.747371673583984, 'learning_rate': 4.482758620689655e-07, 'epoch': 0.07}
{'loss': 1.9183, 'grad_norm': 101.61367797851562, 'learning_rate': 4.827586206896552e-07, 'epoch': 0.07}
{'loss': 1.6628, 'grad_norm': 14.349799156188965, 'learning_rate': 5.172413793103448e-07, 'epoch': 0.08}
{'loss': 1.4812, 'grad_norm': 8.159919738769531, 'learning_rate': 5.517241379310344e-07, 'epoch': 0.08}
{'loss': 1.5404, 'grad_norm': 32.51009750366211, 'learning_rate': 5.86206896551724e-07, 'epoch': 0.09}
{'loss': 1.4847, 'grad_norm': 7.451282024383545, 'learning_rate': 6.206896551724138e-07, 'epoch': 0.09}
{'loss': 1.445, 'grad_norm': 17.15509605407715, 'learning_rate': 6.551724137931034e-07, 'epoch': 0.1}
{'loss': 1.8347, 'grad_norm': 12.068665504455566, 'learning_rate': 6.896551724137931e-07, 'epoch': 0.1}
{'loss': 1.4871, 'grad_norm': 9.991559982299805, 'learning_rate': 7.241379310344827e-07, 'epoch': 0.11}
{'loss': 1.4759, 'grad_norm': 6.1815032958984375, 'learning_rate': 7.586206896551724e-07, 'epoch': 0.11}
{'loss': 1.5465, 'grad_norm': 9.267683982849121, 'learning_rate': 7.931034482758621e-07, 'epoch': 0.12}
{'loss': 1.5694, 'grad_norm': 12.974058151245117, 'learning_rate': 8.275862068965517e-07, 'epoch': 0.12}
{'loss': 1.5136, 'grad_norm': 13.33308219909668, 'learning_rate': 8.620689655172412e-07, 'epoch': 0.13}
{'loss': 1.6405, 'grad_norm': 132.35195922851562, 'learning_rate': 8.96551724137931e-07, 'epoch': 0.14}
{'loss': 1.4234, 'grad_norm': 10.307859420776367, 'learning_rate': 9.310344827586206e-07, 'epoch': 0.14}
{'loss': 1.4422, 'grad_norm': 7.25036096572876, 'learning_rate': 9.655172413793103e-07, 'epoch': 0.15}
{'loss': 1.5573, 'grad_norm': 5.166024684906006, 'learning_rate': 1e-06, 'epoch': 0.15}
{'loss': 1.3225, 'grad_norm': 9.11405086517334, 'learning_rate': 9.9999175360929e-07, 'epoch': 0.16}
{'loss': 1.3129, 'grad_norm': 4.1603007316589355, 'learning_rate': 9.999670147091728e-07, 'epoch': 0.16}
{'loss': 1.4293, 'grad_norm': 115.06037902832031, 'learning_rate': 9.99925784115674e-07, 'epoch': 0.17}
{'loss': 1.2635, 'grad_norm': 5.230789661407471, 'learning_rate': 9.998680631888088e-07, 'epoch': 0.17}
{'loss': 1.5255, 'grad_norm': 7.828071117401123, 'learning_rate': 9.997938538325338e-07, 'epoch': 0.18}
{'loss': 1.3525, 'grad_norm': 4.465182304382324, 'learning_rate': 9.997031584946869e-07, 'epoch': 0.18}
{'loss': 1.4927, 'grad_norm': 5.569939613342285, 'learning_rate': 9.995959801669042e-07, 'epoch': 0.19}
{'loss': 1.2515, 'grad_norm': 216.1123046875, 'learning_rate': 9.994723223845238e-07, 'epoch': 0.19}
{'loss': 1.2695, 'grad_norm': 6.303461074829102, 'learning_rate': 9.99332189226467e-07, 'epoch': 0.2}
{'loss': 1.3962, 'grad_norm': 4.199792861938477, 'learning_rate': 9.99175585315105e-07, 'epoch': 0.2}
{'loss': 1.4839, 'grad_norm': 47.37297821044922, 'learning_rate': 9.990025158161059e-07, 'epoch': 0.21}
{'loss': 1.2285, 'grad_norm': 3.2277753353118896, 'learning_rate': 9.988129864382643e-07, 'epoch': 0.21}
{'loss': 1.1991, 'grad_norm': 6.694594383239746, 'learning_rate': 9.986070034333138e-07, 'epoch': 0.22}
{'loss': 1.2012, 'grad_norm': 5.286780834197998, 'learning_rate': 9.983845735957194e-07, 'epoch': 0.22}
{'loss': 1.4496, 'grad_norm': 7.07742166519165, 'learning_rate': 9.981457042624549e-07, 'epoch': 0.23}
{'loss': 1.3301, 'grad_norm': 10.596612930297852, 'learning_rate': 9.978904033127591e-07, 'epoch': 0.23}
{'loss': 1.287, 'grad_norm': 3.6942999362945557, 'learning_rate': 9.976186791678782e-07, 'epoch': 0.24}
{'loss': 1.1838, 'grad_norm': 3.916740894317627, 'learning_rate': 9.973305407907855e-07, 'epoch': 0.24}
{'loss': 1.4477, 'grad_norm': 320.5010986328125, 'learning_rate': 9.97025997685888e-07, 'epoch': 0.25}
{'loss': 1.3116, 'grad_norm': 7.968719959259033, 'learning_rate': 9.96705059898711e-07, 'epoch': 0.25}
{'loss': 1.4019, 'grad_norm': 119.56977081298828, 'learning_rate': 9.963677380155682e-07, 'epoch': 0.26}
{'loss': 1.2182, 'grad_norm': 5.012618541717529, 'learning_rate': 9.960140431632121e-07, 'epoch': 0.26}
{'loss': 1.3484, 'grad_norm': 4.978724479675293, 'learning_rate': 9.95643987008466e-07, 'epoch': 0.27}
{'loss': 1.3943, 'grad_norm': 21.63007926940918, 'learning_rate': 9.952575817578406e-07, 'epoch': 0.28}
{'loss': 1.4789, 'grad_norm': 5.3744893074035645, 'learning_rate': 9.948548401571306e-07, 'epoch': 0.28}
{'loss': 1.1348, 'grad_norm': 3.164102792739868, 'learning_rate': 9.944357754909945e-07, 'epoch': 0.29}
{'loss': 1.29, 'grad_norm': 3.175567388534546, 'learning_rate': 9.940004015825158e-07, 'epoch': 0.29}
{'loss': 1.318, 'grad_norm': 4.950306415557861, 'learning_rate': 9.935487327927486e-07, 'epoch': 0.3}
{'loss': 1.3156, 'grad_norm': 5.51246976852417, 'learning_rate': 9.930807840202416e-07, 'epoch': 0.3}
{'loss': 1.1845, 'grad_norm': 5.7519989013671875, 'learning_rate': 9.925965707005484e-07, 'epoch': 0.31}
{'loss': 1.3279, 'grad_norm': 58.5655517578125, 'learning_rate': 9.920961088057183e-07, 'epoch': 0.31}
{'loss': 1.3118, 'grad_norm': 3.503225564956665, 'learning_rate': 9.91579414843768e-07, 'epoch': 0.32}
{'loss': 1.3186, 'grad_norm': 5.400946617126465, 'learning_rate': 9.910465058581394e-07, 'epoch': 0.32}
{'loss': 1.3841, 'grad_norm': 5.609443187713623, 'learning_rate': 9.904973994271347e-07, 'epoch': 0.33}
{'loss': 1.3687, 'grad_norm': 4.351179599761963, 'learning_rate': 9.899321136633388e-07, 'epoch': 0.33}
{'loss': 1.3662, 'grad_norm': 5.163286209106445, 'learning_rate': 9.89350667213021e-07, 'epoch': 0.34}
{'loss': 1.2039, 'grad_norm': 4.414697170257568, 'learning_rate': 9.887530792555192e-07, 'epoch': 0.34}
{'loss': 1.411, 'grad_norm': 7.997409343719482, 'learning_rate': 9.88139369502609e-07, 'epoch': 0.35}
{'loss': 1.3517, 'grad_norm': 4.5099945068359375, 'learning_rate': 9.875095581978519e-07, 'epoch': 0.35}
{'loss': 1.3347, 'grad_norm': 3.6415324211120605, 'learning_rate': 9.868636661159283e-07, 'epoch': 0.36}
{'loss': 1.366, 'grad_norm': 4.798874378204346, 'learning_rate': 9.86201714561952e-07, 'epoch': 0.36}
{'loss': 1.1651, 'grad_norm': 3.805450201034546, 'learning_rate': 9.855237253707674e-07, 'epoch': 0.37}
{'loss': 1.2583, 'grad_norm': 7.046265602111816, 'learning_rate': 9.848297209062296e-07, 'epoch': 0.37}
{'loss': 1.4489, 'grad_norm': 33.72840118408203, 'learning_rate': 9.84119724060467e-07, 'epoch': 0.38}
{'loss': 1.2716, 'grad_norm': 4.462706565856934, 'learning_rate': 9.833937582531244e-07, 'epoch': 0.38}
{'loss': 1.3989, 'grad_norm': 4.1540069580078125, 'learning_rate': 9.82651847430593e-07, 'epoch': 0.39}
{'loss': 1.3491, 'grad_norm': 3.1181271076202393, 'learning_rate': 9.818940160652192e-07, 'epoch': 0.39}
{'loss': 1.2932, 'grad_norm': 4.438887596130371, 'learning_rate': 9.811202891544965e-07, 'epoch': 0.4}
{'loss': 1.2816, 'grad_norm': 3.381864547729492, 'learning_rate': 9.803306922202427e-07, 'epoch': 0.41}
{'loss': 1.2737, 'grad_norm': 3.3361284732818604, 'learning_rate': 9.79525251307757e-07, 'epoch': 0.41}
{'loss': 1.379, 'grad_norm': 4.329720497131348, 'learning_rate': 9.787039929849616e-07, 'epoch': 0.42}
{'loss': 1.4697, 'grad_norm': 3.6579551696777344, 'learning_rate': 9.778669443415243e-07, 'epoch': 0.42}
{'loss': 1.1199, 'grad_norm': 3.094426393508911, 'learning_rate': 9.770141329879656e-07, 'epoch': 0.43}
{'loss': 1.3689, 'grad_norm': 3.556605815887451, 'learning_rate': 9.761455870547481e-07, 'epoch': 0.43}
{'loss': 1.3021, 'grad_norm': 3.7904787063598633, 'learning_rate': 9.752613351913484e-07, 'epoch': 0.44}
{'loss': 1.4474, 'grad_norm': 15.149643898010254, 'learning_rate': 9.743614065653118e-07, 'epoch': 0.44}
{'loss': 1.3452, 'grad_norm': 3.3530666828155518, 'learning_rate': 9.734458308612905e-07, 'epoch': 0.45}
{'loss': 1.5151, 'grad_norm': 21.377002716064453, 'learning_rate': 9.725146382800642e-07, 'epoch': 0.45}
{'loss': 1.2655, 'grad_norm': 2.7901878356933594, 'learning_rate': 9.715678595375448e-07, 'epoch': 0.46}
{'loss': 1.3307, 'grad_norm': 9.277861595153809, 'learning_rate': 9.706055258637617e-07, 'epoch': 0.46}
{'loss': 1.3307, 'grad_norm': 3.0313220024108887, 'learning_rate': 9.696276690018329e-07, 'epoch': 0.47}
{'loss': 1.3152, 'grad_norm': 4.883288383483887, 'learning_rate': 9.686343212069172e-07, 'epoch': 0.47}
{'loss': 1.4157, 'grad_norm': 5.545481204986572, 'learning_rate': 9.676255152451506e-07, 'epoch': 0.48}
{'loss': 1.2184, 'grad_norm': 18.935102462768555, 'learning_rate': 9.66601284392566e-07, 'epoch': 0.48}
{'loss': 1.3672, 'grad_norm': 5.076434135437012, 'learning_rate': 9.655616624339944e-07, 'epoch': 0.49}
{'loss': 1.3723, 'grad_norm': 3.677849054336548, 'learning_rate': 9.645066836619508e-07, 'epoch': 0.49}
{'loss': 1.3034, 'grad_norm': 4.110172271728516, 'learning_rate': 9.634363828755043e-07, 'epoch': 0.5}
{'loss': 1.2843, 'grad_norm': 5.920165061950684, 'learning_rate': 9.623507953791286e-07, 'epoch': 0.5}
{'loss': 1.0911, 'grad_norm': 3.149665594100952, 'learning_rate': 9.612499569815381e-07, 'epoch': 0.51}
{'loss': 1.3607, 'grad_norm': 4.355881214141846, 'learning_rate': 9.601339039945073e-07, 'epoch': 0.51}
{'loss': 1.2893, 'grad_norm': 8.749935150146484, 'learning_rate': 9.590026732316719e-07, 'epoch': 0.52}
{'loss': 1.5068, 'grad_norm': 4.143330097198486, 'learning_rate': 9.578563020073152e-07, 'epoch': 0.52}
{'loss': 1.4654, 'grad_norm': 16.170568466186523, 'learning_rate': 9.566948281351373e-07, 'epoch': 0.53}
{'loss': 1.4693, 'grad_norm': 4.961884021759033, 'learning_rate': 9.555182899270078e-07, 'epoch': 0.54}
{'loss': 1.2257, 'grad_norm': 3.5389668941497803, 'learning_rate': 9.543267261917014e-07, 'epoch': 0.54}
{'loss': 1.5629, 'grad_norm': 48.10078430175781, 'learning_rate': 9.531201762336189e-07, 'epoch': 0.55}
{'loss': 1.277, 'grad_norm': 5.7013654708862305, 'learning_rate': 9.518986798514897e-07, 'epoch': 0.55}
{'loss': 1.3072, 'grad_norm': 5.177307605743408, 'learning_rate': 9.506622773370594e-07, 'epoch': 0.56}
{'loss': 1.4286, 'grad_norm': 3.6994917392730713, 'learning_rate': 9.494110094737607e-07, 'epoch': 0.56}
{'loss': 1.4646, 'grad_norm': 3.1759262084960938, 'learning_rate': 9.481449175353684e-07, 'epoch': 0.57}
{'loss': 1.2358, 'grad_norm': 4.35767126083374, 'learning_rate': 9.468640432846378e-07, 'epoch': 0.57}
{'loss': 1.2317, 'grad_norm': 4.2051472663879395, 'learning_rate': 9.455684289719269e-07, 'epoch': 0.58}
{'loss': 1.1379, 'grad_norm': 3.8637192249298096, 'learning_rate': 9.442581173338031e-07, 'epoch': 0.58}
{'loss': 1.2825, 'grad_norm': 4.722641944885254, 'learning_rate': 9.429331515916332e-07, 'epoch': 0.59}
{'loss': 1.2879, 'grad_norm': 16.31139373779297, 'learning_rate': 9.415935754501581e-07, 'epoch': 0.59}
{'loss': 1.1891, 'grad_norm': 3.7933871746063232, 'learning_rate': 9.402394330960505e-07, 'epoch': 0.6}
{'loss': 1.3782, 'grad_norm': 8.117697715759277, 'learning_rate': 9.388707691964584e-07, 'epoch': 0.6}
{'loss': 1.2923, 'grad_norm': 3.4859774112701416, 'learning_rate': 9.374876288975307e-07, 'epoch': 0.61}
{'loss': 1.2791, 'grad_norm': 3.53263258934021, 'learning_rate': 9.360900578229286e-07, 'epoch': 0.61}
{'loss': 1.2676, 'grad_norm': 3.2714362144470215, 'learning_rate': 9.346781020723207e-07, 'epoch': 0.62}
{'loss': 1.2732, 'grad_norm': 4.125393390655518, 'learning_rate': 9.332518082198623e-07, 'epoch': 0.62}
{'loss': 1.2188, 'grad_norm': 3.9317216873168945, 'learning_rate': 9.318112233126587e-07, 'epoch': 0.63}
{'loss': 1.1168, 'grad_norm': 3.187389850616455, 'learning_rate': 9.303563948692139e-07, 'epoch': 0.63}
{'loss': 1.2723, 'grad_norm': 3.764125108718872, 'learning_rate': 9.28887370877863e-07, 'epoch': 0.64}
{'loss': 1.3557, 'grad_norm': 5.481338024139404, 'learning_rate': 9.27404199795189e-07, 'epoch': 0.64}
{'loss': 1.157, 'grad_norm': 3.565946578979492, 'learning_rate': 9.259069305444252e-07, 'epoch': 0.65}
{'loss': 1.3595, 'grad_norm': 3.4644224643707275, 'learning_rate': 9.243956125138401e-07, 'epoch': 0.65}
{'loss': 1.117, 'grad_norm': 3.1043848991394043, 'learning_rate': 9.228702955551099e-07, 'epoch': 0.66}
{'loss': 1.2875, 'grad_norm': 9.596739768981934, 'learning_rate': 9.21331029981673e-07, 'epoch': 0.66}
{'loss': 1.2568, 'grad_norm': 2.8435404300689697, 'learning_rate': 9.197778665670706e-07, 'epoch': 0.67}
{'loss': 1.3502, 'grad_norm': 3.0136210918426514, 'learning_rate': 9.18210856543272e-07, 'epoch': 0.68}
{'loss': 1.4595, 'grad_norm': 3.407961130142212, 'learning_rate': 9.166300515989849e-07, 'epoch': 0.68}
{'loss': 1.2294, 'grad_norm': 8.361903190612793, 'learning_rate': 9.150355038779502e-07, 'epoch': 0.69}
{'loss': 1.2333, 'grad_norm': 3.2988040447235107, 'learning_rate': 9.134272659772219e-07, 'epoch': 0.69}
{'loss': 1.1677, 'grad_norm': 2.971860408782959, 'learning_rate': 9.118053909454324e-07, 'epoch': 0.7}
{'loss': 1.2771, 'grad_norm': 5.575029373168945, 'learning_rate': 9.101699322810423e-07, 'epoch': 0.7}
{'loss': 1.1017, 'grad_norm': 3.2014811038970947, 'learning_rate': 9.085209439305764e-07, 'epoch': 0.71}
{'loss': 1.157, 'grad_norm': 9.690433502197266, 'learning_rate': 9.068584802868433e-07, 'epoch': 0.71}
{'loss': 1.3159, 'grad_norm': 19.0631160736084, 'learning_rate': 9.051825961871422e-07, 'epoch': 0.72}
{'loss': 1.3664, 'grad_norm': 13.596308708190918, 'learning_rate': 9.034933469114532e-07, 'epoch': 0.72}
{'loss': 1.1778, 'grad_norm': 3.154906749725342, 'learning_rate': 9.017907881806145e-07, 'epoch': 0.73}
{'loss': 1.21, 'grad_norm': 4.482882499694824, 'learning_rate': 9.000749761544841e-07, 'epoch': 0.73}
{'loss': 1.4144, 'grad_norm': 4.5888447761535645, 'learning_rate': 8.983459674300875e-07, 'epoch': 0.74}
{'loss': 1.4299, 'grad_norm': 34.905738830566406, 'learning_rate': 8.966038190397507e-07, 'epoch': 0.74}
{'loss': 1.248, 'grad_norm': 3.7104475498199463, 'learning_rate': 8.948485884492185e-07, 'epoch': 0.75}
{'loss': 1.2485, 'grad_norm': 3.9498655796051025, 'learning_rate': 8.930803335557602e-07, 'epoch': 0.75}
{'loss': 1.1824, 'grad_norm': 3.2521746158599854, 'learning_rate': 8.912991126862586e-07, 'epoch': 0.76}
{'loss': 1.1828, 'grad_norm': 3.1649274826049805, 'learning_rate': 8.895049845952867e-07, 'epoch': 0.76}
{'loss': 1.1739, 'grad_norm': 3.179161787033081, 'learning_rate': 8.876980084631692e-07, 'epoch': 0.77}
{'loss': 1.316, 'grad_norm': 4.9411702156066895, 'learning_rate': 8.858782438940311e-07, 'epoch': 0.77}
{'loss': 1.1168, 'grad_norm': 3.888810634613037, 'learning_rate': 8.840457509138306e-07, 'epoch': 0.78}
{'loss': 1.3003, 'grad_norm': 4.086330413818359, 'learning_rate': 8.822005899683804e-07, 'epoch': 0.78}
{'loss': 1.1344, 'grad_norm': 3.5312440395355225, 'learning_rate': 8.803428219213526e-07, 'epoch': 0.79}
{'loss': 1.1591, 'grad_norm': 28.582414627075195, 'learning_rate': 8.784725080522721e-07, 'epoch': 0.79}
{'loss': 1.2815, 'grad_norm': 4.215453147888184, 'learning_rate': 8.765897100544943e-07, 'epoch': 0.8}
{'loss': 1.5616, 'grad_norm': 5.267111778259277, 'learning_rate': 8.74694490033171e-07, 'epoch': 0.81}
{'loss': 1.255, 'grad_norm': 24.142192840576172, 'learning_rate': 8.727869105032013e-07, 'epoch': 0.81}
{'loss': 1.297, 'grad_norm': 4.778336048126221, 'learning_rate': 8.708670343871696e-07, 'epoch': 0.82}
{'loss': 1.0818, 'grad_norm': 3.5019822120666504, 'learning_rate': 8.6893492501327e-07, 'epoch': 0.82}
{'loss': 1.3302, 'grad_norm': 3.4937586784362793, 'learning_rate': 8.669906461132181e-07, 'epoch': 0.83}
{'loss': 1.1883, 'grad_norm': 3.1679768562316895, 'learning_rate': 8.650342618201473e-07, 'epoch': 0.83}
{'loss': 1.3448, 'grad_norm': 5.255401134490967, 'learning_rate': 8.630658366664951e-07, 'epoch': 0.84}
{'loss': 1.3632, 'grad_norm': 3.7602593898773193, 'learning_rate': 8.610854355818727e-07, 'epoch': 0.84}
{'loss': 1.2515, 'grad_norm': 7.997136116027832, 'learning_rate': 8.590931238909245e-07, 'epoch': 0.85}
{'loss': 1.2929, 'grad_norm': 5.107179641723633, 'learning_rate': 8.570889673111732e-07, 'epoch': 0.85}
{'loss': 1.2285, 'grad_norm': 4.426243782043457, 'learning_rate': 8.550730319508515e-07, 'epoch': 0.86}
{'loss': 1.1813, 'grad_norm': 3.2735612392425537, 'learning_rate': 8.530453843067221e-07, 'epoch': 0.86}
{'loss': 0.9308, 'grad_norm': 2.717468500137329, 'learning_rate': 8.510060912618835e-07, 'epoch': 0.87}
{'loss': 1.2992, 'grad_norm': 3.5859813690185547, 'learning_rate': 8.489552200835648e-07, 'epoch': 0.87}
{'loss': 1.2581, 'grad_norm': 3.735128402709961, 'learning_rate': 8.468928384209059e-07, 'epoch': 0.88}
{'loss': 1.3566, 'grad_norm': 7.13566255569458, 'learning_rate': 8.448190143027268e-07, 'epoch': 0.88}
{'loss': 1.304, 'grad_norm': 3.5274481773376465, 'learning_rate': 8.427338161352835e-07, 'epoch': 0.89}
{'loss': 1.3266, 'grad_norm': 17.936092376708984, 'learning_rate': 8.406373127000109e-07, 'epoch': 0.89}
{'loss': 1.2793, 'grad_norm': 3.338547706604004, 'learning_rate': 8.385295731512549e-07, 'epoch': 0.9}
{'loss': 1.1569, 'grad_norm': 3.217726469039917, 'learning_rate': 8.36410667013991e-07, 'epoch': 0.9}
{'loss': 1.1616, 'grad_norm': 3.397634267807007, 'learning_rate': 8.342806641815303e-07, 'epoch': 0.91}
{'loss': 1.2066, 'grad_norm': 2.9920010566711426, 'learning_rate': 8.321396349132156e-07, 'epoch': 0.91}
{'loss': 1.1346, 'grad_norm': 4.903217315673828, 'learning_rate': 8.299876498321022e-07, 'epoch': 0.92}
{'loss': 1.339, 'grad_norm': 3.711172580718994, 'learning_rate': 8.27824779922629e-07, 'epoch': 0.92}
{'loss': 1.3562, 'grad_norm': 10.299917221069336, 'learning_rate': 8.256510965282774e-07, 'epoch': 0.93}
{'loss': 1.2302, 'grad_norm': 58.1269416809082, 'learning_rate': 8.234666713492178e-07, 'epoch': 0.94}
{'loss': 1.4142, 'grad_norm': 3.2026751041412354, 'learning_rate': 8.21271576439944e-07, 'epoch': 0.94}
{'loss': 1.3769, 'grad_norm': 7.0018630027771, 'learning_rate': 8.190658842068972e-07, 'epoch': 0.95}
{'loss': 1.1775, 'grad_norm': 4.411948204040527, 'learning_rate': 8.168496674060769e-07, 'epoch': 0.95}
{'loss': 1.215, 'grad_norm': 6.137925148010254, 'learning_rate': 8.146229991406421e-07, 'epoch': 0.96}
{'loss': 1.3001, 'grad_norm': 48.41030502319336, 'learning_rate': 8.123859528584984e-07, 'epoch': 0.96}
{'loss': 1.1941, 'grad_norm': 2.977112293243408, 'learning_rate': 8.101386023498767e-07, 'epoch': 0.97}
{'loss': 1.2723, 'grad_norm': 3.4144556522369385, 'learning_rate': 8.078810217448985e-07, 'epoch': 0.97}
{'loss': 1.3096, 'grad_norm': 3.227823257446289, 'learning_rate': 8.056132855111304e-07, 'epoch': 0.98}
{'loss': 1.0758, 'grad_norm': 3.7029213905334473, 'learning_rate': 8.033354684511286e-07, 'epoch': 0.98}
{'loss': 1.2242, 'grad_norm': 2.951388120651245, 'learning_rate': 8.010476456999711e-07, 'epoch': 0.99}
{'loss': 1.2336, 'grad_norm': 3.9517829418182373, 'learning_rate': 7.987498927227787e-07, 'epoch': 0.99}
{'loss': 1.2008, 'grad_norm': 4.72385835647583, 'learning_rate': 7.964422853122268e-07, 'epoch': 1.0}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-192/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-192/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-192/model.safetensors.index.json.
2024-12-28 23:24:05,000 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-192/pytorch_model_fsdp.bin
2024-12-28 23:24:49,377 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-192/pytorch_model_fsdp.bin
2024-12-28 23:25:21,247 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-192/optimizer.bin
2024-12-28 23:27:02,243 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-192/optimizer.bin
                                                                                                                                                      
{'loss': 1.1379, 'grad_norm': 4.77810525894165, 'learning_rate': 7.941248995860445e-07, 'epoch': 1.0}
{'loss': 1.1121, 'grad_norm': 3.1991498470306396, 'learning_rate': 7.917978119845044e-07, 'epoch': 1.01}
{'loss': 1.2574, 'grad_norm': 3.1173980236053467, 'learning_rate': 7.894610992679007e-07, 'epoch': 1.01}
{'loss': 1.295, 'grad_norm': 2.9922757148742676, 'learning_rate': 7.871148385140178e-07, 'epoch': 1.02}
{'loss': 1.3456, 'grad_norm': 47.27635192871094, 'learning_rate': 7.847591071155871e-07, 'epoch': 1.02}
{'loss': 1.2179, 'grad_norm': 4.721616744995117, 'learning_rate': 7.823939827777344e-07, 'epoch': 1.03}
{'loss': 1.2841, 'grad_norm': 17.28043556213379, 'learning_rate': 7.800195435154178e-07, 'epoch': 1.03}
{'loss': 1.3147, 'grad_norm': 3.7475509643554688, 'learning_rate': 7.776358676508521e-07, 'epoch': 1.04}
{'loss': 1.1938, 'grad_norm': 5.188084125518799, 'learning_rate': 7.752430338109277e-07, 'epoch': 1.04}
{'loss': 1.3813, 'grad_norm': 56.9965934753418, 'learning_rate': 7.728411209246155e-07, 'epoch': 1.05}
{'loss': 1.2336, 'grad_norm': 2.8068997859954834, 'learning_rate': 7.704302082203639e-07, 'epoch': 1.05}
{'loss': 1.3129, 'grad_norm': 3.145181179046631, 'learning_rate': 7.680103752234857e-07, 'epoch': 1.06}
{'loss': 1.1906, 'grad_norm': 5.765589237213135, 'learning_rate': 7.655817017535339e-07, 'epoch': 1.06}
{'loss': 1.27, 'grad_norm': 3.0364797115325928, 'learning_rate': 7.631442679216702e-07, 'epoch': 1.07}
{'loss': 1.2351, 'grad_norm': 4.563480854034424, 'learning_rate': 7.60698154128021e-07, 'epoch': 1.08}
{'loss': 1.2452, 'grad_norm': 3.3913733959198, 'learning_rate': 7.582434410590268e-07, 'epoch': 1.08}
{'loss': 1.1403, 'grad_norm': 3.325467109680176, 'learning_rate': 7.557802096847799e-07, 'epoch': 1.09}
{'loss': 1.3245, 'grad_norm': 3.573467493057251, 'learning_rate': 7.533085412563534e-07, 'epoch': 1.09}
{'loss': 1.2792, 'grad_norm': 3.713209629058838, 'learning_rate': 7.508285173031215e-07, 'epoch': 1.1}
{'loss': 1.1321, 'grad_norm': 2.701812267303467, 'learning_rate': 7.483402196300704e-07, 'epoch': 1.1}
{'loss': 1.2671, 'grad_norm': 11.849043846130371, 'learning_rate': 7.458437303150994e-07, 'epoch': 1.11}
{'loss': 1.1863, 'grad_norm': 2.861414909362793, 'learning_rate': 7.433391317063133e-07, 'epoch': 1.11}
{'loss': 1.2682, 'grad_norm': 4.975103855133057, 'learning_rate': 7.408265064193071e-07, 'epoch': 1.12}
{'loss': 1.2685, 'grad_norm': 4.844607830047607, 'learning_rate': 7.383059373344401e-07, 'epoch': 1.12}
{'loss': 1.2496, 'grad_norm': 4.831343650817871, 'learning_rate': 7.357775075941024e-07, 'epoch': 1.13}
{'loss': 1.2724, 'grad_norm': 4.339641571044922, 'learning_rate': 7.332413005999717e-07, 'epoch': 1.13}
{'loss': 1.2603, 'grad_norm': 3.703665018081665, 'learning_rate': 7.306974000102634e-07, 'epoch': 1.14}
{'loss': 1.2614, 'grad_norm': 6.478137969970703, 'learning_rate': 7.281458897369705e-07, 'epoch': 1.14}
{'loss': 1.3098, 'grad_norm': 4.59213924407959, 'learning_rate': 7.25586853943095e-07, 'epoch': 1.15}
{'loss': 1.1339, 'grad_norm': 3.4240617752075195, 'learning_rate': 7.230203770398732e-07, 'epoch': 1.15}
{'loss': 1.3611, 'grad_norm': 11.542428970336914, 'learning_rate': 7.204465436839902e-07, 'epoch': 1.16}
{'loss': 1.1852, 'grad_norm': 14.907869338989258, 'learning_rate': 7.178654387747877e-07, 'epoch': 1.16}
{'loss': 1.2935, 'grad_norm': 18.286392211914062, 'learning_rate': 7.152771474514642e-07, 'epoch': 1.17}
{'loss': 1.2146, 'grad_norm': 3.151728868484497, 'learning_rate': 7.126817550902655e-07, 'epoch': 1.17}
{'loss': 1.0516, 'grad_norm': 3.0019876956939697, 'learning_rate': 7.100793473016698e-07, 'epoch': 1.18}
{'loss': 1.2309, 'grad_norm': 3.719151735305786, 'learning_rate': 7.074700099275622e-07, 'epoch': 1.18}
{'loss': 1.3002, 'grad_norm': 31.674062728881836, 'learning_rate': 7.04853829038405e-07, 'epoch': 1.19}
{'loss': 1.3397, 'grad_norm': 24.80022621154785, 'learning_rate': 7.022308909303974e-07, 'epoch': 1.19}
{'loss': 1.3034, 'grad_norm': 10.326229095458984, 'learning_rate': 6.996012821226288e-07, 'epoch': 1.2}
{'loss': 1.3239, 'grad_norm': 3.9646241664886475, 'learning_rate': 6.969650893542261e-07, 'epoch': 1.21}
{'loss': 1.319, 'grad_norm': 19.330467224121094, 'learning_rate': 6.943223995814913e-07, 'epoch': 1.21}
{'loss': 1.2219, 'grad_norm': 3.0788848400115967, 'learning_rate': 6.916732999750343e-07, 'epoch': 1.22}
{'loss': 1.2811, 'grad_norm': 3.7512807846069336, 'learning_rate': 6.890178779168963e-07, 'epoch': 1.22}
{'loss': 1.146, 'grad_norm': 2.7955751419067383, 'learning_rate': 6.863562209976685e-07, 'epoch': 1.23}
{'loss': 1.268, 'grad_norm': 4.697347640991211, 'learning_rate': 6.836884170136025e-07, 'epoch': 1.23}
{'loss': 1.2051, 'grad_norm': 3.3765625953674316, 'learning_rate': 6.810145539637145e-07, 'epoch': 1.24}
{'loss': 1.2562, 'grad_norm': 3.169059991836548, 'learning_rate': 6.783347200468817e-07, 'epoch': 1.24}
{'loss': 1.1393, 'grad_norm': 5.110404014587402, 'learning_rate': 6.756490036589345e-07, 'epoch': 1.25}
{'loss': 1.1024, 'grad_norm': 2.9077680110931396, 'learning_rate': 6.729574933897396e-07, 'epoch': 1.25}
{'loss': 1.1294, 'grad_norm': 2.9983885288238525, 'learning_rate': 6.702602780202778e-07, 'epoch': 1.26}
{'loss': 1.2399, 'grad_norm': 3.2340524196624756, 'learning_rate': 6.675574465197165e-07, 'epoch': 1.26}
{'loss': 1.2375, 'grad_norm': 3.8156278133392334, 'learning_rate': 6.64849088042474e-07, 'epoch': 1.27}
{'loss': 1.2421, 'grad_norm': 5.126315116882324, 'learning_rate': 6.621352919252788e-07, 'epoch': 1.27}
{'loss': 1.175, 'grad_norm': 4.4200873374938965, 'learning_rate': 6.594161476842233e-07, 'epoch': 1.28}
{'loss': 1.2799, 'grad_norm': 3.528700113296509, 'learning_rate': 6.566917450118108e-07, 'epoch': 1.28}
{'loss': 1.2062, 'grad_norm': 3.2925713062286377, 'learning_rate': 6.53962173773997e-07, 'epoch': 1.29}
{'loss': 1.0037, 'grad_norm': 2.5777854919433594, 'learning_rate': 6.512275240072252e-07, 'epoch': 1.29}
{'loss': 1.2101, 'grad_norm': 3.0105273723602295, 'learning_rate': 6.484878859154574e-07, 'epoch': 1.3}
{'loss': 1.2157, 'grad_norm': 109.3761215209961, 'learning_rate': 6.457433498671978e-07, 'epoch': 1.3}
{'loss': 1.224, 'grad_norm': 48.08209228515625, 'learning_rate': 6.429940063925127e-07, 'epoch': 1.31}
{'loss': 1.3252, 'grad_norm': 5.001408100128174, 'learning_rate': 6.402399461800442e-07, 'epoch': 1.31}
{'loss': 1.3035, 'grad_norm': 3.2981815338134766, 'learning_rate': 6.374812600740187e-07, 'epoch': 1.32}
{'loss': 1.213, 'grad_norm': 16.964370727539062, 'learning_rate': 6.347180390712497e-07, 'epoch': 1.32}
{'loss': 1.0098, 'grad_norm': 3.1105329990386963, 'learning_rate': 6.319503743181371e-07, 'epoch': 1.33}
{'loss': 1.2244, 'grad_norm': 2.993335247039795, 'learning_rate': 6.291783571076611e-07, 'epoch': 1.34}
{'loss': 1.3229, 'grad_norm': 3.9063308238983154, 'learning_rate': 6.26402078876369e-07, 'epoch': 1.34}
{'loss': 1.2454, 'grad_norm': 4.31946325302124, 'learning_rate': 6.236216312013614e-07, 'epoch': 1.35}
{'loss': 1.183, 'grad_norm': 3.2575271129608154, 'learning_rate': 6.208371057972694e-07, 'epoch': 1.35}
{'loss': 1.1406, 'grad_norm': 4.000702857971191, 'learning_rate': 6.18048594513231e-07, 'epoch': 1.36}
{'loss': 1.2185, 'grad_norm': 3.3246755599975586, 'learning_rate': 6.1525618932986e-07, 'epoch': 1.36}
{'loss': 1.1841, 'grad_norm': 3.8732805252075195, 'learning_rate': 6.124599823562134e-07, 'epoch': 1.37}
{'loss': 1.1712, 'grad_norm': 3.3027920722961426, 'learning_rate': 6.096600658267518e-07, 'epoch': 1.37}
{'loss': 0.9549, 'grad_norm': 2.6113576889038086, 'learning_rate': 6.068565320982981e-07, 'epoch': 1.38}
{'loss': 1.2278, 'grad_norm': 9.85068416595459, 'learning_rate': 6.0404947364699e-07, 'epoch': 1.38}
{'loss': 1.1802, 'grad_norm': 5.931153297424316, 'learning_rate': 6.012389830652306e-07, 'epoch': 1.39}
{'loss': 1.2559, 'grad_norm': 3.5755414962768555, 'learning_rate': 5.984251530586336e-07, 'epoch': 1.39}
{'loss': 1.1448, 'grad_norm': 2.99442458152771, 'learning_rate': 5.956080764429653e-07, 'epoch': 1.4}
{'loss': 1.1318, 'grad_norm': 2.9835257530212402, 'learning_rate': 5.927878461410836e-07, 'epoch': 1.4}
{'loss': 1.2198, 'grad_norm': 4.929498672485352, 'learning_rate': 5.899645551798725e-07, 'epoch': 1.41}
{'loss': 1.1826, 'grad_norm': 5.604678630828857, 'learning_rate': 5.871382966871728e-07, 'epoch': 1.41}
{'loss': 1.1209, 'grad_norm': 3.2297234535217285, 'learning_rate': 5.843091638887124e-07, 'epoch': 1.42}
{'loss': 1.2859, 'grad_norm': 60.04494094848633, 'learning_rate': 5.814772501050286e-07, 'epoch': 1.42}
{'loss': 1.1993, 'grad_norm': 4.5756707191467285, 'learning_rate': 5.786426487483914e-07, 'epoch': 1.43}
{'loss': 1.1139, 'grad_norm': 13.09739875793457, 'learning_rate': 5.758054533197222e-07, 'epoch': 1.43}
{'loss': 1.0523, 'grad_norm': 2.8689541816711426, 'learning_rate': 5.729657574055089e-07, 'epoch': 1.44}
{'loss': 1.2171, 'grad_norm': 3.6107003688812256, 'learning_rate': 5.701236546747197e-07, 'epoch': 1.44}
{'loss': 1.2817, 'grad_norm': 10.78864860534668, 'learning_rate': 5.672792388757127e-07, 'epoch': 1.45}
{'loss': 1.2714, 'grad_norm': 33.3421516418457, 'learning_rate': 5.644326038331439e-07, 'epoch': 1.45}
{'loss': 1.0534, 'grad_norm': 3.4318645000457764, 'learning_rate': 5.615838434448725e-07, 'epoch': 1.46}
{'loss': 1.1878, 'grad_norm': 3.109238624572754, 'learning_rate': 5.587330516788633e-07, 'epoch': 1.46}
{'loss': 1.1639, 'grad_norm': 9.11410140991211, 'learning_rate': 5.558803225700872e-07, 'epoch': 1.47}
{'loss': 1.1527, 'grad_norm': 8.91729736328125, 'learning_rate': 5.530257502174196e-07, 'epoch': 1.48}
{'loss': 0.9325, 'grad_norm': 3.3535640239715576, 'learning_rate': 5.501694287805361e-07, 'epoch': 1.48}
{'loss': 1.1856, 'grad_norm': 3.3539648056030273, 'learning_rate': 5.473114524768068e-07, 'epoch': 1.49}
{'loss': 1.144, 'grad_norm': 4.124519348144531, 'learning_rate': 5.444519155781889e-07, 'epoch': 1.49}
{'loss': 1.2684, 'grad_norm': 32.89224624633789, 'learning_rate': 5.415909124081163e-07, 'epoch': 1.5}
{'loss': 1.2008, 'grad_norm': 3.35490083694458, 'learning_rate': 5.387285373383892e-07, 'epoch': 1.5}
{'loss': 1.071, 'grad_norm': 3.2378125190734863, 'learning_rate': 5.358648847860598e-07, 'epoch': 1.51}
{'loss': 1.1255, 'grad_norm': 2.943767786026001, 'learning_rate': 5.330000492103198e-07, 'epoch': 1.51}
{'loss': 1.1223, 'grad_norm': 3.450679063796997, 'learning_rate': 5.301341251093827e-07, 'epoch': 1.52}
{'loss': 1.2379, 'grad_norm': 4.319966793060303, 'learning_rate': 5.272672070173682e-07, 'epoch': 1.52}
{'loss': 1.1658, 'grad_norm': 4.074895858764648, 'learning_rate': 5.243993895011833e-07, 'epoch': 1.53}
{'loss': 1.2383, 'grad_norm': 9.326786994934082, 'learning_rate': 5.215307671574027e-07, 'epoch': 1.53}
{'loss': 1.1978, 'grad_norm': 5.732307434082031, 'learning_rate': 5.18661434609149e-07, 'epoch': 1.54}
{'loss': 1.3078, 'grad_norm': 3.901563882827759, 'learning_rate': 5.157914865029715e-07, 'epoch': 1.54}
{'loss': 1.2156, 'grad_norm': 3.3313794136047363, 'learning_rate': 5.129210175057236e-07, 'epoch': 1.55}
{'loss': 1.2531, 'grad_norm': 3.463009834289551, 'learning_rate': 5.100501223014407e-07, 'epoch': 1.55}
{'loss': 1.1107, 'grad_norm': 3.541440486907959, 'learning_rate': 5.07178895588217e-07, 'epoch': 1.56}
{'loss': 1.0932, 'grad_norm': 3.932835817337036, 'learning_rate': 5.04307432075082e-07, 'epoch': 1.56}
{'loss': 1.1395, 'grad_norm': 3.198293924331665, 'learning_rate': 5.014358264788755e-07, 'epoch': 1.57}
{'loss': 1.0052, 'grad_norm': 2.9443624019622803, 'learning_rate': 4.985641735211245e-07, 'epoch': 1.57}
{'loss': 1.0865, 'grad_norm': 3.306086301803589, 'learning_rate': 4.95692567924918e-07, 'epoch': 1.58}
{'loss': 1.1632, 'grad_norm': 2.520689010620117, 'learning_rate': 4.928211044117829e-07, 'epoch': 1.58}
{'loss': 1.2003, 'grad_norm': 18.47356414794922, 'learning_rate': 4.899498776985593e-07, 'epoch': 1.59}
{'loss': 1.1966, 'grad_norm': 21.25311851501465, 'learning_rate': 4.870789824942765e-07, 'epoch': 1.59}
{'loss': 1.0783, 'grad_norm': 2.9547383785247803, 'learning_rate': 4.842085134970286e-07, 'epoch': 1.6}
{'loss': 1.0994, 'grad_norm': 15.139288902282715, 'learning_rate': 4.813385653908509e-07, 'epoch': 1.61}
{'loss': 1.3265, 'grad_norm': 3.7302446365356445, 'learning_rate': 4.784692328425973e-07, 'epoch': 1.61}
{'loss': 1.1991, 'grad_norm': 6.664465427398682, 'learning_rate': 4.756006104988167e-07, 'epoch': 1.62}
{'loss': 1.0596, 'grad_norm': 5.308722496032715, 'learning_rate': 4.727327929826318e-07, 'epoch': 1.62}
{'loss': 1.2207, 'grad_norm': 14.507226943969727, 'learning_rate': 4.698658748906174e-07, 'epoch': 1.63}
{'loss': 1.2141, 'grad_norm': 2.850034475326538, 'learning_rate': 4.6699995078968026e-07, 'epoch': 1.63}
{'loss': 1.0627, 'grad_norm': 2.7027385234832764, 'learning_rate': 4.6413511521394023e-07, 'epoch': 1.64}
{'loss': 1.3144, 'grad_norm': 2.793236017227173, 'learning_rate': 4.6127146266161083e-07, 'epoch': 1.64}
{'loss': 1.2831, 'grad_norm': 6.834115982055664, 'learning_rate': 4.5840908759188355e-07, 'epoch': 1.65}
{'loss': 1.1079, 'grad_norm': 4.11171817779541, 'learning_rate': 4.5554808442181104e-07, 'epoch': 1.65}
{'loss': 1.1891, 'grad_norm': 3.0557045936584473, 'learning_rate': 4.5268854752319323e-07, 'epoch': 1.66}
{'loss': 1.2984, 'grad_norm': 5.682373046875, 'learning_rate': 4.498305712194641e-07, 'epoch': 1.66}
{'loss': 1.1638, 'grad_norm': 2.9452571868896484, 'learning_rate': 4.469742497825804e-07, 'epoch': 1.67}
{'loss': 1.3086, 'grad_norm': 4.6547746658325195, 'learning_rate': 4.4411967742991287e-07, 'epoch': 1.67}
{'loss': 1.25, 'grad_norm': 3.655773401260376, 'learning_rate': 4.412669483211367e-07, 'epoch': 1.68}
{'loss': 1.1258, 'grad_norm': 2.9440863132476807, 'learning_rate': 4.3841615655512756e-07, 'epoch': 1.68}
{'loss': 1.1845, 'grad_norm': 3.7444169521331787, 'learning_rate': 4.3556739616685607e-07, 'epoch': 1.69}
{'loss': 1.1783, 'grad_norm': 4.694265842437744, 'learning_rate': 4.3272076112428745e-07, 'epoch': 1.69}
{'loss': 1.1984, 'grad_norm': 3.642796516418457, 'learning_rate': 4.2987634532528046e-07, 'epoch': 1.7}
{'loss': 1.1074, 'grad_norm': 11.573765754699707, 'learning_rate': 4.2703424259449104e-07, 'epoch': 1.7}
{'loss': 0.9514, 'grad_norm': 3.5571744441986084, 'learning_rate': 4.2419454668027785e-07, 'epoch': 1.71}
{'loss': 1.3179, 'grad_norm': 4.683857440948486, 'learning_rate': 4.213573512516085e-07, 'epoch': 1.71}
{'loss': 1.2199, 'grad_norm': 2.9935731887817383, 'learning_rate': 4.1852274989497145e-07, 'epoch': 1.72}
{'loss': 1.2047, 'grad_norm': 3.0357906818389893, 'learning_rate': 4.1569083611128753e-07, 'epoch': 1.72}
{'loss': 1.1549, 'grad_norm': 8.275793075561523, 'learning_rate': 4.128617033128271e-07, 'epoch': 1.73}
{'loss': 1.2207, 'grad_norm': 4.154696464538574, 'learning_rate': 4.1003544482012777e-07, 'epoch': 1.74}
{'loss': 1.3035, 'grad_norm': 11.196481704711914, 'learning_rate': 4.072121538589164e-07, 'epoch': 1.74}
{'loss': 1.1473, 'grad_norm': 3.0662782192230225, 'learning_rate': 4.043919235570347e-07, 'epoch': 1.75}
{'loss': 1.1346, 'grad_norm': 2.952537775039673, 'learning_rate': 4.015748469413664e-07, 'epoch': 1.75}
{'loss': 1.2178, 'grad_norm': 7.143223762512207, 'learning_rate': 3.9876101693476945e-07, 'epoch': 1.76}
{'loss': 1.0424, 'grad_norm': 4.403695106506348, 'learning_rate': 3.9595052635301e-07, 'epoch': 1.76}
{'loss': 1.1843, 'grad_norm': 3.131861925125122, 'learning_rate': 3.931434679017019e-07, 'epoch': 1.77}
{'loss': 1.1054, 'grad_norm': 4.037596225738525, 'learning_rate': 3.903399341732482e-07, 'epoch': 1.77}
{'loss': 1.2776, 'grad_norm': 5.1064372062683105, 'learning_rate': 3.8754001764378665e-07, 'epoch': 1.78}
{'loss': 1.1716, 'grad_norm': 3.1251981258392334, 'learning_rate': 3.8474381067014e-07, 'epoch': 1.78}
{'loss': 1.2943, 'grad_norm': 3.4299285411834717, 'learning_rate': 3.81951405486769e-07, 'epoch': 1.79}
{'loss': 1.2548, 'grad_norm': 5.536480903625488, 'learning_rate': 3.7916289420273064e-07, 'epoch': 1.79}
{'loss': 1.322, 'grad_norm': 3.2790794372558594, 'learning_rate': 3.7637836879863856e-07, 'epoch': 1.8}
{'loss': 1.2088, 'grad_norm': 3.308668375015259, 'learning_rate': 3.7359792112363085e-07, 'epoch': 1.8}
{'loss': 1.1456, 'grad_norm': 3.1478371620178223, 'learning_rate': 3.708216428923391e-07, 'epoch': 1.81}
{'loss': 1.0263, 'grad_norm': 3.9822444915771484, 'learning_rate': 3.680496256818628e-07, 'epoch': 1.81}
{'loss': 1.3707, 'grad_norm': 2.937946319580078, 'learning_rate': 3.652819609287504e-07, 'epoch': 1.82}
{'loss': 1.2322, 'grad_norm': 14.967402458190918, 'learning_rate': 3.6251873992598126e-07, 'epoch': 1.82}
{'loss': 1.0362, 'grad_norm': 3.6035959720611572, 'learning_rate': 3.5976005381995565e-07, 'epoch': 1.83}
{'loss': 1.0348, 'grad_norm': 6.006722927093506, 'learning_rate': 3.570059936074871e-07, 'epoch': 1.83}
{'loss': 1.0134, 'grad_norm': 11.856550216674805, 'learning_rate': 3.5425665013280213e-07, 'epoch': 1.84}
{'loss': 1.271, 'grad_norm': 2.622345447540283, 'learning_rate': 3.515121140845427e-07, 'epoch': 1.84}
{'loss': 1.1597, 'grad_norm': 3.536839246749878, 'learning_rate': 3.487724759927747e-07, 'epoch': 1.85}
{'loss': 1.0894, 'grad_norm': 15.945298194885254, 'learning_rate': 3.4603782622600305e-07, 'epoch': 1.85}
{'loss': 1.3231, 'grad_norm': 2.906968593597412, 'learning_rate': 3.4330825498818907e-07, 'epoch': 1.86}
{'loss': 1.2268, 'grad_norm': 3.019986391067505, 'learning_rate': 3.4058385231577673e-07, 'epoch': 1.86}
{'loss': 1.1474, 'grad_norm': 4.484886169433594, 'learning_rate': 3.3786470807472124e-07, 'epoch': 1.87}
{'loss': 1.1494, 'grad_norm': 12.287650108337402, 'learning_rate': 3.3515091195752596e-07, 'epoch': 1.88}
{'loss': 1.1382, 'grad_norm': 4.789970874786377, 'learning_rate': 3.324425534802835e-07, 'epoch': 1.88}
{'loss': 1.0916, 'grad_norm': 2.870485782623291, 'learning_rate': 3.297397219797221e-07, 'epoch': 1.89}
{'loss': 1.2342, 'grad_norm': 3.543787717819214, 'learning_rate': 3.2704250661026043e-07, 'epoch': 1.89}
{'loss': 1.1188, 'grad_norm': 4.647551536560059, 'learning_rate': 3.243509963410654e-07, 'epoch': 1.9}
{'loss': 1.1404, 'grad_norm': 2.7159018516540527, 'learning_rate': 3.2166527995311834e-07, 'epoch': 1.9}
{'loss': 1.2358, 'grad_norm': 6.816073894500732, 'learning_rate': 3.189854460362856e-07, 'epoch': 1.91}
{'loss': 1.3398, 'grad_norm': 2.7727503776550293, 'learning_rate': 3.163115829863975e-07, 'epoch': 1.91}
{'loss': 1.1854, 'grad_norm': 2.7331666946411133, 'learning_rate': 3.136437790023316e-07, 'epoch': 1.92}
{'loss': 1.307, 'grad_norm': 3.0254127979278564, 'learning_rate': 3.109821220831038e-07, 'epoch': 1.92}
{'loss': 1.2842, 'grad_norm': 3.2050516605377197, 'learning_rate': 3.083267000249658e-07, 'epoch': 1.93}
{'loss': 1.185, 'grad_norm': 2.915153980255127, 'learning_rate': 3.0567760041850855e-07, 'epoch': 1.93}
{'loss': 1.1552, 'grad_norm': 5.060583591461182, 'learning_rate': 3.0303491064577395e-07, 'epoch': 1.94}
{'loss': 1.1637, 'grad_norm': 2.843533992767334, 'learning_rate': 3.0039871787737115e-07, 'epoch': 1.94}
{'loss': 1.06, 'grad_norm': 3.4563705921173096, 'learning_rate': 2.9776910906960265e-07, 'epoch': 1.95}
{'loss': 1.1654, 'grad_norm': 2.970747470855713, 'learning_rate': 2.951461709615951e-07, 'epoch': 1.95}
{'loss': 1.1843, 'grad_norm': 6.030246257781982, 'learning_rate': 2.9252999007243784e-07, 'epoch': 1.96}
{'loss': 1.184, 'grad_norm': 3.053790807723999, 'learning_rate': 2.899206526983303e-07, 'epoch': 1.96}
{'loss': 1.198, 'grad_norm': 3.7574310302734375, 'learning_rate': 2.8731824490973445e-07, 'epoch': 1.97}
{'loss': 1.1669, 'grad_norm': 5.564631938934326, 'learning_rate': 2.847228525485359e-07, 'epoch': 1.97}
{'loss': 1.3232, 'grad_norm': 5.8531599044799805, 'learning_rate': 2.821345612252121e-07, 'epoch': 1.98}
{'loss': 1.3613, 'grad_norm': 3.598789691925049, 'learning_rate': 2.795534563160099e-07, 'epoch': 1.98}
{'loss': 1.0495, 'grad_norm': 3.801783323287964, 'learning_rate': 2.7697962296012687e-07, 'epoch': 1.99}
{'loss': 1.1286, 'grad_norm': 3.0689706802368164, 'learning_rate': 2.7441314605690485e-07, 'epoch': 1.99}
{'loss': 1.1011, 'grad_norm': 2.9490578174591064, 'learning_rate': 2.7185411026302964e-07, 'epoch': 2.0}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-385/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-385/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-385/model.safetensors.index.json.
2024-12-28 23:36:16,708 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-385/pytorch_model_fsdp.bin
2024-12-28 23:37:05,947 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-385/pytorch_model_fsdp.bin
2024-12-28 23:37:37,203 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-385/optimizer.bin
2024-12-28 23:39:02,997 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-385/optimizer.bin
                                                                                                                                                      
{'loss': 1.2702, 'grad_norm': 2.646296977996826, 'learning_rate': 2.693025999897364e-07, 'epoch': 2.01}
{'loss': 1.1723, 'grad_norm': 2.980452060699463, 'learning_rate': 2.667586994000283e-07, 'epoch': 2.01}
{'loss': 1.1326, 'grad_norm': 2.812913417816162, 'learning_rate': 2.6422249240589767e-07, 'epoch': 2.02}
{'loss': 1.1671, 'grad_norm': 3.3814878463745117, 'learning_rate': 2.616940626655598e-07, 'epoch': 2.02}
{'loss': 1.1183, 'grad_norm': 2.882044553756714, 'learning_rate': 2.591734935806929e-07, 'epoch': 2.03}
{'loss': 1.2306, 'grad_norm': 3.7043404579162598, 'learning_rate': 2.5666086829368675e-07, 'epoch': 2.03}
{'loss': 1.0502, 'grad_norm': 3.189521074295044, 'learning_rate': 2.5415626968490074e-07, 'epoch': 2.04}
{'loss': 1.1693, 'grad_norm': 6.571725368499756, 'learning_rate': 2.516597803699294e-07, 'epoch': 2.04}
{'loss': 1.1262, 'grad_norm': 3.511439561843872, 'learning_rate': 2.491714826968785e-07, 'epoch': 2.05}
{'loss': 1.1788, 'grad_norm': 22.598413467407227, 'learning_rate': 2.4669145874364653e-07, 'epoch': 2.05}
{'loss': 0.9834, 'grad_norm': 2.935572624206543, 'learning_rate': 2.4421979031522006e-07, 'epoch': 2.06}
{'loss': 1.3023, 'grad_norm': 3.033736228942871, 'learning_rate': 2.417565589409733e-07, 'epoch': 2.06}
{'loss': 1.0224, 'grad_norm': 2.936612367630005, 'learning_rate': 2.3930184587197897e-07, 'epoch': 2.07}
{'loss': 1.2407, 'grad_norm': 13.83437442779541, 'learning_rate': 2.3685573207832987e-07, 'epoch': 2.07}
{'loss': 1.2661, 'grad_norm': 3.2657337188720703, 'learning_rate': 2.3441829824646602e-07, 'epoch': 2.08}
{'loss': 1.2184, 'grad_norm': 3.733532428741455, 'learning_rate': 2.319896247765143e-07, 'epoch': 2.08}
{'loss': 1.1907, 'grad_norm': 7.9947428703308105, 'learning_rate': 2.2956979177963598e-07, 'epoch': 2.09}
{'loss': 1.2274, 'grad_norm': 3.3569071292877197, 'learning_rate': 2.271588790753845e-07, 'epoch': 2.09}
{'loss': 1.0017, 'grad_norm': 4.725426197052002, 'learning_rate': 2.2475696618907235e-07, 'epoch': 2.1}
{'loss': 1.172, 'grad_norm': 3.9506757259368896, 'learning_rate': 2.2236413234914803e-07, 'epoch': 2.1}
{'loss': 1.1393, 'grad_norm': 2.6891632080078125, 'learning_rate': 2.1998045648458242e-07, 'epoch': 2.11}
{'loss': 1.1009, 'grad_norm': 10.867244720458984, 'learning_rate': 2.176060172222654e-07, 'epoch': 2.11}
{'loss': 1.3394, 'grad_norm': 3.201815605163574, 'learning_rate': 2.1524089288441311e-07, 'epoch': 2.12}
{'loss': 1.2153, 'grad_norm': 3.4361889362335205, 'learning_rate': 2.1288516148598213e-07, 'epoch': 2.12}
{'loss': 1.0113, 'grad_norm': 10.536150932312012, 'learning_rate': 2.105389007320992e-07, 'epoch': 2.13}
{'loss': 1.1502, 'grad_norm': 2.6138720512390137, 'learning_rate': 2.0820218801549577e-07, 'epoch': 2.14}
{'loss': 1.277, 'grad_norm': 2.719639539718628, 'learning_rate': 2.058751004139555e-07, 'epoch': 2.14}
{'loss': 1.2336, 'grad_norm': 43.44449996948242, 'learning_rate': 2.0355771468777323e-07, 'epoch': 2.15}
{'loss': 1.1465, 'grad_norm': 3.6897246837615967, 'learning_rate': 2.012501072772213e-07, 'epoch': 2.15}
{'loss': 1.0358, 'grad_norm': 2.711792469024658, 'learning_rate': 1.9895235430002892e-07, 'epoch': 2.16}
{'loss': 1.2873, 'grad_norm': 8.751582145690918, 'learning_rate': 1.966645315488713e-07, 'epoch': 2.16}
{'loss': 1.226, 'grad_norm': 6.168318271636963, 'learning_rate': 1.9438671448886962e-07, 'epoch': 2.17}
{'loss': 1.1927, 'grad_norm': 3.133498191833496, 'learning_rate': 1.921189782551016e-07, 'epoch': 2.17}
{'loss': 1.2575, 'grad_norm': 4.179511070251465, 'learning_rate': 1.8986139765012327e-07, 'epoch': 2.18}
{'loss': 1.3347, 'grad_norm': 3.9980063438415527, 'learning_rate': 1.8761404714150158e-07, 'epoch': 2.18}
{'loss': 1.3269, 'grad_norm': 2.9980075359344482, 'learning_rate': 1.853770008593578e-07, 'epoch': 2.19}
{'loss': 1.1705, 'grad_norm': 4.273828983306885, 'learning_rate': 1.831503325939231e-07, 'epoch': 2.19}
{'loss': 1.217, 'grad_norm': 3.741363525390625, 'learning_rate': 1.809341157931028e-07, 'epoch': 2.2}
{'loss': 1.1482, 'grad_norm': 3.554133653640747, 'learning_rate': 1.7872842356005597e-07, 'epoch': 2.2}
{'loss': 1.1937, 'grad_norm': 3.6824989318847656, 'learning_rate': 1.765333286507824e-07, 'epoch': 2.21}
{'loss': 1.216, 'grad_norm': 4.719395160675049, 'learning_rate': 1.743489034717226e-07, 'epoch': 2.21}
{'loss': 1.1314, 'grad_norm': 4.436357498168945, 'learning_rate': 1.7217522007737106e-07, 'epoch': 2.22}
{'loss': 1.1906, 'grad_norm': 3.4443979263305664, 'learning_rate': 1.700123501678979e-07, 'epoch': 2.22}
{'loss': 1.2187, 'grad_norm': 3.431889057159424, 'learning_rate': 1.6786036508678437e-07, 'epoch': 2.23}
{'loss': 1.125, 'grad_norm': 15.518860816955566, 'learning_rate': 1.6571933581846965e-07, 'epoch': 2.23}
{'loss': 1.2126, 'grad_norm': 2.9181249141693115, 'learning_rate': 1.6358933298600907e-07, 'epoch': 2.24}
{'loss': 1.2891, 'grad_norm': 3.411756992340088, 'learning_rate': 1.6147042684874508e-07, 'epoch': 2.24}
{'loss': 1.0466, 'grad_norm': 8.603639602661133, 'learning_rate': 1.5936268729998913e-07, 'epoch': 2.25}
{'loss': 1.1454, 'grad_norm': 3.440690040588379, 'learning_rate': 1.5726618386471656e-07, 'epoch': 2.25}
{'loss': 1.1984, 'grad_norm': 2.8858156204223633, 'learning_rate': 1.55180985697273e-07, 'epoch': 2.26}
{'loss': 1.2738, 'grad_norm': 3.0024986267089844, 'learning_rate': 1.531071615790942e-07, 'epoch': 2.26}
{'loss': 1.067, 'grad_norm': 27.43575096130371, 'learning_rate': 1.5104477991643515e-07, 'epoch': 2.27}
{'loss': 1.1009, 'grad_norm': 3.768587827682495, 'learning_rate': 1.489939087381164e-07, 'epoch': 2.28}
{'loss': 1.2386, 'grad_norm': 2.651737689971924, 'learning_rate': 1.46954615693278e-07, 'epoch': 2.28}
{'loss': 1.1827, 'grad_norm': 7.5917510986328125, 'learning_rate': 1.449269680491484e-07, 'epoch': 2.29}
{'loss': 1.1303, 'grad_norm': 4.1332688331604, 'learning_rate': 1.4291103268882677e-07, 'epoch': 2.29}
{'loss': 1.3164, 'grad_norm': 3.525923728942871, 'learning_rate': 1.4090687610907548e-07, 'epoch': 2.3}
{'loss': 1.0384, 'grad_norm': 3.8469109535217285, 'learning_rate': 1.3891456441812744e-07, 'epoch': 2.3}
{'loss': 1.166, 'grad_norm': 3.3879144191741943, 'learning_rate': 1.36934163333505e-07, 'epoch': 2.31}
{'loss': 1.0887, 'grad_norm': 3.1493046283721924, 'learning_rate': 1.3496573817985262e-07, 'epoch': 2.31}
{'loss': 1.1315, 'grad_norm': 3.5080835819244385, 'learning_rate': 1.3300935388678196e-07, 'epoch': 2.32}
{'loss': 1.2609, 'grad_norm': 3.0942575931549072, 'learning_rate': 1.3106507498672998e-07, 'epoch': 2.32}
{'loss': 1.2573, 'grad_norm': 3.28053617477417, 'learning_rate': 1.2913296561283054e-07, 'epoch': 2.33}
{'loss': 1.181, 'grad_norm': 3.4648261070251465, 'learning_rate': 1.2721308949679866e-07, 'epoch': 2.33}
{'loss': 1.2474, 'grad_norm': 3.3079476356506348, 'learning_rate': 1.2530550996682904e-07, 'epoch': 2.34}
{'loss': 1.072, 'grad_norm': 4.915229320526123, 'learning_rate': 1.2341028994550556e-07, 'epoch': 2.34}
{'loss': 1.11, 'grad_norm': 8.340065002441406, 'learning_rate': 1.2152749194772783e-07, 'epoch': 2.35}
{'loss': 1.248, 'grad_norm': 3.6623637676239014, 'learning_rate': 1.196571780786474e-07, 'epoch': 2.35}
{'loss': 1.0698, 'grad_norm': 10.609620094299316, 'learning_rate': 1.1779941003161953e-07, 'epoch': 2.36}
{'loss': 1.2211, 'grad_norm': 3.1051790714263916, 'learning_rate': 1.159542490861693e-07, 'epoch': 2.36}
{'loss': 1.1729, 'grad_norm': 2.9295177459716797, 'learning_rate': 1.1412175610596897e-07, 'epoch': 2.37}
{'loss': 1.1205, 'grad_norm': 3.492654323577881, 'learning_rate': 1.1230199153683078e-07, 'epoch': 2.37}
{'loss': 1.1433, 'grad_norm': 2.833961248397827, 'learning_rate': 1.1049501540471323e-07, 'epoch': 2.38}
{'loss': 1.1665, 'grad_norm': 3.9659931659698486, 'learning_rate': 1.0870088731374139e-07, 'epoch': 2.38}
{'loss': 1.2329, 'grad_norm': 2.994687557220459, 'learning_rate': 1.0691966644423984e-07, 'epoch': 2.39}
{'loss': 1.2024, 'grad_norm': 5.647343635559082, 'learning_rate': 1.0515141155078138e-07, 'epoch': 2.39}
{'loss': 1.1761, 'grad_norm': 10.03384780883789, 'learning_rate': 1.0339618096024943e-07, 'epoch': 2.4}
{'loss': 1.1555, 'grad_norm': 2.9865331649780273, 'learning_rate': 1.016540325699124e-07, 'epoch': 2.41}
{'loss': 0.9933, 'grad_norm': 5.583277225494385, 'learning_rate': 9.992502384551576e-08, 'epoch': 2.41}
{'loss': 1.0832, 'grad_norm': 3.379274368286133, 'learning_rate': 9.820921181938546e-08, 'epoch': 2.42}
{'loss': 1.295, 'grad_norm': 8.858270645141602, 'learning_rate': 9.650665308854678e-08, 'epoch': 2.42}
{'loss': 1.2188, 'grad_norm': 3.4184906482696533, 'learning_rate': 9.48174038128578e-08, 'epoch': 2.43}
{'loss': 1.462, 'grad_norm': 3.1055965423583984, 'learning_rate': 9.314151971315664e-08, 'epoch': 2.43}
{'loss': 1.3015, 'grad_norm': 4.2782416343688965, 'learning_rate': 9.147905606942363e-08, 'epoch': 2.44}
{'loss': 1.2891, 'grad_norm': 2.948333263397217, 'learning_rate': 8.983006771895763e-08, 'epoch': 2.44}
{'loss': 1.2596, 'grad_norm': 4.93668270111084, 'learning_rate': 8.81946090545676e-08, 'epoch': 2.45}
{'loss': 1.1529, 'grad_norm': 3.189464569091797, 'learning_rate': 8.657273402277798e-08, 'epoch': 2.45}
{'loss': 1.2562, 'grad_norm': 4.329966068267822, 'learning_rate': 8.496449612204982e-08, 'epoch': 2.46}
{'loss': 1.0819, 'grad_norm': 2.832188367843628, 'learning_rate': 8.336994840101513e-08, 'epoch': 2.46}
{'loss': 1.1313, 'grad_norm': 3.531838893890381, 'learning_rate': 8.1789143456728e-08, 'epoch': 2.47}
{'loss': 1.3421, 'grad_norm': 5.404696941375732, 'learning_rate': 8.022213343292955e-08, 'epoch': 2.47}
{'loss': 1.315, 'grad_norm': 5.203176498413086, 'learning_rate': 7.866897001832695e-08, 'epoch': 2.48}
{'loss': 1.0996, 'grad_norm': 4.931277275085449, 'learning_rate': 7.712970444489003e-08, 'epoch': 2.48}
{'loss': 1.1778, 'grad_norm': 3.59830904006958, 'learning_rate': 7.560438748615982e-08, 'epoch': 2.49}
{'loss': 1.1852, 'grad_norm': 3.5998146533966064, 'learning_rate': 7.409306945557487e-08, 'epoch': 2.49}
{'loss': 1.2889, 'grad_norm': 9.394905090332031, 'learning_rate': 7.259580020481092e-08, 'epoch': 2.5}
{'loss': 1.1781, 'grad_norm': 3.5627024173736572, 'learning_rate': 7.111262912213706e-08, 'epoch': 2.5}
{'loss': 1.2314, 'grad_norm': 3.2491252422332764, 'learning_rate': 6.96436051307861e-08, 'epoch': 2.51}
{'loss': 1.139, 'grad_norm': 3.190960645675659, 'learning_rate': 6.81887766873413e-08, 'epoch': 2.51}
{'loss': 1.2565, 'grad_norm': 3.088359832763672, 'learning_rate': 6.674819178013769e-08, 'epoch': 2.52}
{'loss': 1.1627, 'grad_norm': 4.718509197235107, 'learning_rate': 6.532189792767922e-08, 'epoch': 2.52}
{'loss': 1.0089, 'grad_norm': 4.949405670166016, 'learning_rate': 6.390994217707141e-08, 'epoch': 2.53}
{'loss': 1.2202, 'grad_norm': 3.6999454498291016, 'learning_rate': 6.251237110246943e-08, 'epoch': 2.54}
{'loss': 1.0962, 'grad_norm': 2.7679572105407715, 'learning_rate': 6.112923080354165e-08, 'epoch': 2.54}
{'loss': 1.2272, 'grad_norm': 3.898911952972412, 'learning_rate': 5.976056690394959e-08, 'epoch': 2.55}
{'loss': 1.1512, 'grad_norm': 6.092650413513184, 'learning_rate': 5.840642454984196e-08, 'epoch': 2.55}
{'loss': 1.2537, 'grad_norm': 2.8283541202545166, 'learning_rate': 5.706684840836673e-08, 'epoch': 2.56}
{'loss': 1.0827, 'grad_norm': 11.699830055236816, 'learning_rate': 5.574188266619695e-08, 'epoch': 2.56}
{'loss': 1.2113, 'grad_norm': 3.836068630218506, 'learning_rate': 5.4431571028073054e-08, 'epoch': 2.57}
{'loss': 1.1471, 'grad_norm': 2.9005730152130127, 'learning_rate': 5.31359567153622e-08, 'epoch': 2.57}
{'loss': 1.2582, 'grad_norm': 3.8626627922058105, 'learning_rate': 5.185508246463161e-08, 'epoch': 2.58}
{'loss': 1.0823, 'grad_norm': 2.7979955673217773, 'learning_rate': 5.058899052623933e-08, 'epoch': 2.58}
{'loss': 1.078, 'grad_norm': 3.0962021350860596, 'learning_rate': 4.933772266294067e-08, 'epoch': 2.59}
{'loss': 1.1428, 'grad_norm': 3.226694345474243, 'learning_rate': 4.810132014851026e-08, 'epoch': 2.59}
{'loss': 0.9786, 'grad_norm': 2.748579978942871, 'learning_rate': 4.6879823766381e-08, 'epoch': 2.6}
{'loss': 1.0041, 'grad_norm': 7.2965593338012695, 'learning_rate': 4.5673273808298494e-08, 'epoch': 2.6}
{'loss': 1.1305, 'grad_norm': 2.90806245803833, 'learning_rate': 4.4481710072992284e-08, 'epoch': 2.61}
{'loss': 1.1284, 'grad_norm': 3.6144707202911377, 'learning_rate': 4.3305171864862655e-08, 'epoch': 2.61}
{'loss': 1.2414, 'grad_norm': 10.120213508605957, 'learning_rate': 4.214369799268497e-08, 'epoch': 2.62}
{'loss': 1.3249, 'grad_norm': 3.476280927658081, 'learning_rate': 4.099732676832818e-08, 'epoch': 2.62}
{'loss': 1.067, 'grad_norm': 3.42769455909729, 'learning_rate': 3.9866096005492676e-08, 'epoch': 2.63}
{'loss': 1.1425, 'grad_norm': 3.3620996475219727, 'learning_rate': 3.8750043018461854e-08, 'epoch': 2.63}
{'loss': 1.1906, 'grad_norm': 3.293219566345215, 'learning_rate': 3.7649204620871346e-08, 'epoch': 2.64}
{'loss': 1.2974, 'grad_norm': 3.5243451595306396, 'learning_rate': 3.656361712449557e-08, 'epoch': 2.64}
{'loss': 1.2812, 'grad_norm': 3.4705545902252197, 'learning_rate': 3.549331633804908e-08, 'epoch': 2.65}
{'loss': 1.2333, 'grad_norm': 4.219572067260742, 'learning_rate': 3.443833756600567e-08, 'epoch': 2.65}
{'loss': 1.1746, 'grad_norm': 4.243337631225586, 'learning_rate': 3.3398715607433795e-08, 'epoch': 2.66}
{'loss': 1.0879, 'grad_norm': 7.4626851081848145, 'learning_rate': 3.237448475484922e-08, 'epoch': 2.66}
{'loss': 1.2203, 'grad_norm': 3.2362098693847656, 'learning_rate': 3.1365678793082826e-08, 'epoch': 2.67}
{'loss': 0.977, 'grad_norm': 2.8673505783081055, 'learning_rate': 3.037233099816705e-08, 'epoch': 2.68}
{'loss': 1.3435, 'grad_norm': 3.118212938308716, 'learning_rate': 2.9394474136238246e-08, 'epoch': 2.68}
{'loss': 0.9725, 'grad_norm': 2.565702438354492, 'learning_rate': 2.843214046245507e-08, 'epoch': 2.69}
{'loss': 1.0482, 'grad_norm': 3.0347962379455566, 'learning_rate': 2.748536171993565e-08, 'epoch': 2.69}
{'loss': 1.1811, 'grad_norm': 10.111466407775879, 'learning_rate': 2.6554169138709558e-08, 'epoch': 2.7}
{'loss': 0.9971, 'grad_norm': 2.952338457107544, 'learning_rate': 2.5638593434688218e-08, 'epoch': 2.7}
{'loss': 1.1186, 'grad_norm': 2.8031628131866455, 'learning_rate': 2.4738664808651498e-08, 'epoch': 2.71}
{'loss': 1.172, 'grad_norm': 3.4805686473846436, 'learning_rate': 2.3854412945251756e-08, 'epoch': 2.71}
{'loss': 1.2062, 'grad_norm': 3.709684371948242, 'learning_rate': 2.2985867012034365e-08, 'epoch': 2.72}
{'loss': 1.2818, 'grad_norm': 2.8988709449768066, 'learning_rate': 2.213305565847573e-08, 'epoch': 2.72}
{'loss': 1.1329, 'grad_norm': 3.9523205757141113, 'learning_rate': 2.1296007015038365e-08, 'epoch': 2.73}
{'loss': 1.1398, 'grad_norm': 3.658893585205078, 'learning_rate': 2.047474869224286e-08, 'epoch': 2.73}
{'loss': 1.1347, 'grad_norm': 3.5505545139312744, 'learning_rate': 1.966930777975734e-08, 'epoch': 2.74}
{'loss': 1.0596, 'grad_norm': 5.715295791625977, 'learning_rate': 1.8879710845503604e-08, 'epoch': 2.74}
{'loss': 1.131, 'grad_norm': 2.723365545272827, 'learning_rate': 1.81059839347808e-08, 'epoch': 2.75}
{'loss': 1.1319, 'grad_norm': 5.084562301635742, 'learning_rate': 1.7348152569406748e-08, 'epoch': 2.75}
{'loss': 1.1082, 'grad_norm': 3.0016591548919678, 'learning_rate': 1.660624174687547e-08, 'epoch': 2.76}
{'loss': 1.2463, 'grad_norm': 3.704747438430786, 'learning_rate': 1.588027593953306e-08, 'epoch': 2.76}
{'loss': 1.0458, 'grad_norm': 2.5303616523742676, 'learning_rate': 1.517027909377028e-08, 'epoch': 2.77}
{'loss': 1.2421, 'grad_norm': 9.015241622924805, 'learning_rate': 1.4476274629232677e-08, 'epoch': 2.77}
{'loss': 1.2598, 'grad_norm': 4.010219573974609, 'learning_rate': 1.3798285438048118e-08, 'epoch': 2.78}
{'loss': 1.1194, 'grad_norm': 4.49216365814209, 'learning_rate': 1.3136333884071704e-08, 'epoch': 2.78}
{'loss': 1.1522, 'grad_norm': 5.2555251121521, 'learning_rate': 1.2490441802148032e-08, 'epoch': 2.79}
{'loss': 1.2363, 'grad_norm': 2.721212148666382, 'learning_rate': 1.186063049739089e-08, 'epoch': 2.79}
{'loss': 1.3476, 'grad_norm': 2.7506279945373535, 'learning_rate': 1.1246920744480692e-08, 'epoch': 2.8}
{'loss': 1.1839, 'grad_norm': 3.1960206031799316, 'learning_rate': 1.0649332786979049e-08, 'epoch': 2.81}
{'loss': 1.201, 'grad_norm': 2.7416162490844727, 'learning_rate': 1.0067886336661113e-08, 'epoch': 2.81}
{'loss': 1.3106, 'grad_norm': 3.086073637008667, 'learning_rate': 9.502600572865282e-09, 'epoch': 2.82}
{'loss': 1.0251, 'grad_norm': 3.1026110649108887, 'learning_rate': 8.953494141860584e-09, 'epoch': 2.82}
{'loss': 1.106, 'grad_norm': 4.793617248535156, 'learning_rate': 8.42058515623184e-09, 'epoch': 2.83}
{'loss': 1.2146, 'grad_norm': 3.0573678016662598, 'learning_rate': 7.903891194281753e-09, 'epoch': 2.83}
{'loss': 1.0939, 'grad_norm': 4.82611608505249, 'learning_rate': 7.403429299451536e-09, 'epoch': 2.84}
{'loss': 1.0625, 'grad_norm': 2.983140707015991, 'learning_rate': 6.919215979758475e-09, 'epoch': 2.84}
{'loss': 1.3231, 'grad_norm': 2.8847134113311768, 'learning_rate': 6.451267207251421e-09, 'epoch': 2.85}
{'loss': 1.1649, 'grad_norm': 2.9406940937042236, 'learning_rate': 5.999598417484042e-09, 'epoch': 2.85}
{'loss': 1.2707, 'grad_norm': 3.21688175201416, 'learning_rate': 5.5642245090055664e-09, 'epoch': 2.86}
{'loss': 1.2108, 'grad_norm': 2.9098026752471924, 'learning_rate': 5.145159842869396e-09, 'epoch': 2.86}
{'loss': 1.1377, 'grad_norm': 4.068234443664551, 'learning_rate': 4.742418242159485e-09, 'epoch': 2.87}
{'loss': 1.2412, 'grad_norm': 9.825258255004883, 'learning_rate': 4.356012991534097e-09, 'epoch': 2.87}
{'loss': 1.2568, 'grad_norm': 4.365063190460205, 'learning_rate': 3.985956836787985e-09, 'epoch': 2.88}
{'loss': 1.1464, 'grad_norm': 2.7458016872406006, 'learning_rate': 3.6322619844317282e-09, 'epoch': 2.88}
{'loss': 1.1977, 'grad_norm': 2.618762969970703, 'learning_rate': 3.294940101289001e-09, 'epoch': 2.89}
{'loss': 1.1471, 'grad_norm': 2.954148769378662, 'learning_rate': 2.974002314112045e-09, 'epoch': 2.89}
{'loss': 1.1474, 'grad_norm': 3.2245516777038574, 'learning_rate': 2.6694592092144642e-09, 'epoch': 2.9}
{'loss': 1.1425, 'grad_norm': 4.889795780181885, 'learning_rate': 2.3813208321218357e-09, 'epoch': 2.9}
{'loss': 1.2269, 'grad_norm': 5.218661785125732, 'learning_rate': 2.1095966872407556e-09, 'epoch': 2.91}
{'loss': 1.1997, 'grad_norm': 3.010258197784424, 'learning_rate': 1.8542957375451417e-09, 'epoch': 2.91}
{'loss': 1.1593, 'grad_norm': 3.764587163925171, 'learning_rate': 1.6154264042805287e-09, 'epoch': 2.92}
{'loss': 1.1473, 'grad_norm': 3.1870181560516357, 'learning_rate': 1.3929965666861776e-09, 'epoch': 2.92}
{'loss': 1.137, 'grad_norm': 5.347409248352051, 'learning_rate': 1.187013561735617e-09, 'epoch': 2.93}
{'loss': 1.0944, 'grad_norm': 3.6549577713012695, 'learning_rate': 9.97484183894115e-10, 'epoch': 2.94}
{'loss': 1.2011, 'grad_norm': 2.690525531768799, 'learning_rate': 8.244146848949141e-10, 'epoch': 2.94}
{'loss': 1.1608, 'grad_norm': 4.4609856605529785, 'learning_rate': 6.678107735328398e-10, 'epoch': 2.95}
{'loss': 1.1208, 'grad_norm': 2.7929182052612305, 'learning_rate': 5.276776154760631e-10, 'epoch': 2.95}
{'loss': 1.1587, 'grad_norm': 2.608928680419922, 'learning_rate': 4.0401983309568124e-10, 'epoch': 2.96}
{'loss': 1.2146, 'grad_norm': 3.6110002994537354, 'learning_rate': 2.968415053131723e-10, 'epoch': 2.96}
{'loss': 1.0334, 'grad_norm': 3.7601566314697266, 'learning_rate': 2.061461674661147e-10, 'epoch': 2.97}
{'loss': 1.1011, 'grad_norm': 4.849578857421875, 'learning_rate': 1.3193681119116895e-10, 'epoch': 2.97}
{'loss': 1.1083, 'grad_norm': 4.217580318450928, 'learning_rate': 7.421588432576786e-11, 'epoch': 2.98}
{'loss': 1.1553, 'grad_norm': 3.5907833576202393, 'learning_rate': 3.298529082718105e-11, 'epoch': 2.98}
{'loss': 1.3249, 'grad_norm': 2.70306658744812, 'learning_rate': 8.246390709787388e-12, 'epoch': 2.99}
{'loss': 0.9409, 'grad_norm': 2.5158205032348633, 'learning_rate': 0.0, 'epoch': 2.99}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-576/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-576/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-576/model.safetensors.index.json.
2024-12-28 23:50:08,817 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-576/pytorch_model_fsdp.bin
2024-12-28 23:50:53,864 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-576/pytorch_model_fsdp.bin
2024-12-28 23:51:25,767 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-576/optimizer.bin
2024-12-28 23:52:56,351 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-576/optimizer.bin
Saving model checkpoint to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-576
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-576/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-576/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-576/model.safetensors.index.json.
2024-12-28 23:54:56,838 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-576/pytorch_model_fsdp.bin
2024-12-28 23:55:52,473 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-576/pytorch_model_fsdp.bin
2024-12-28 23:56:23,258 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-576/optimizer.bin
2024-12-28 23:57:51,688 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/checkpoint-576/optimizer.bin


Training completed. Do not forget to share your model on huggingface.co/models =)


100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 576/576 [42:49<00:00,  4.46s/it]
{'train_runtime': 2576.1011, 'train_samples_per_second': 1.793, 'train_steps_per_second': 0.224, 'train_loss': 1.2375421678233478, 'epoch': 2.99}
Saving model checkpoint to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint614/model.safetensors.index.json.
