                                                                                                                                                                                               
{'loss': 1.6363, 'grad_norm': 86.06877136230469, 'learning_rate': 3.448275862068965e-08, 'epoch': 0.01}
{'loss': 1.9135, 'grad_norm': 289.56072998046875, 'learning_rate': 6.89655172413793e-08, 'epoch': 0.01}
{'loss': 1.9123, 'grad_norm': 140534.171875, 'learning_rate': 1.0344827586206897e-07, 'epoch': 0.02}
{'loss': 1.6206, 'grad_norm': 89.80058288574219, 'learning_rate': 1.379310344827586e-07, 'epoch': 0.02}
{'loss': 1.8772, 'grad_norm': 25794.765625, 'learning_rate': 1.7241379310344828e-07, 'epoch': 0.03}
{'loss': 1.6493, 'grad_norm': 60.31624984741211, 'learning_rate': 2.0689655172413793e-07, 'epoch': 0.03}
{'loss': 1.9842, 'grad_norm': 20540.033203125, 'learning_rate': 2.413793103448276e-07, 'epoch': 0.04}
{'loss': 1.5518, 'grad_norm': 65.03086853027344, 'learning_rate': 2.758620689655172e-07, 'epoch': 0.04}
{'loss': 1.593, 'grad_norm': 38.14746856689453, 'learning_rate': 3.103448275862069e-07, 'epoch': 0.05}
{'loss': 1.6014, 'grad_norm': 108.12223052978516, 'learning_rate': 3.4482758620689656e-07, 'epoch': 0.05}
{'loss': 1.9148, 'grad_norm': 20785.45703125, 'learning_rate': 3.793103448275862e-07, 'epoch': 0.06}
{'loss': 1.7089, 'grad_norm': 17.796546936035156, 'learning_rate': 4.1379310344827586e-07, 'epoch': 0.06}
{'loss': 1.9105, 'grad_norm': 693.2757568359375, 'learning_rate': 4.482758620689655e-07, 'epoch': 0.07}
{'loss': 1.8247, 'grad_norm': 2592.135498046875, 'learning_rate': 4.827586206896552e-07, 'epoch': 0.07}
{'loss': 1.6398, 'grad_norm': 15.46496295928955, 'learning_rate': 5.172413793103448e-07, 'epoch': 0.08}
{'loss': 1.5116, 'grad_norm': 6.4672040939331055, 'learning_rate': 5.517241379310344e-07, 'epoch': 0.08}
{'loss': 1.4963, 'grad_norm': 1176.349365234375, 'learning_rate': 5.86206896551724e-07, 'epoch': 0.09}
{'loss': 1.5588, 'grad_norm': 18.112468719482422, 'learning_rate': 6.206896551724138e-07, 'epoch': 0.09}
{'loss': 1.3567, 'grad_norm': 8.297967910766602, 'learning_rate': 6.551724137931034e-07, 'epoch': 0.1}
{'loss': 1.7881, 'grad_norm': 21.321992874145508, 'learning_rate': 6.896551724137931e-07, 'epoch': 0.1}
{'loss': 1.5769, 'grad_norm': 12.485980033874512, 'learning_rate': 7.241379310344827e-07, 'epoch': 0.11}
{'loss': 1.333, 'grad_norm': 6.068640232086182, 'learning_rate': 7.586206896551724e-07, 'epoch': 0.11}
{'loss': 1.4492, 'grad_norm': 7.495642185211182, 'learning_rate': 7.931034482758621e-07, 'epoch': 0.12}
{'loss': 1.5029, 'grad_norm': 35.990352630615234, 'learning_rate': 8.275862068965517e-07, 'epoch': 0.12}
{'loss': 1.3471, 'grad_norm': 8.662744522094727, 'learning_rate': 8.620689655172412e-07, 'epoch': 0.13}
{'loss': 1.6202, 'grad_norm': 121.72834014892578, 'learning_rate': 8.96551724137931e-07, 'epoch': 0.14}
{'loss': 1.2644, 'grad_norm': 5.373439788818359, 'learning_rate': 9.310344827586206e-07, 'epoch': 0.14}
{'loss': 1.5555, 'grad_norm': 9.864956855773926, 'learning_rate': 9.655172413793103e-07, 'epoch': 0.15}
{'loss': 1.4184, 'grad_norm': 6.31303071975708, 'learning_rate': 1e-06, 'epoch': 0.15}
{'loss': 1.5417, 'grad_norm': 4.377779483795166, 'learning_rate': 9.9999175360929e-07, 'epoch': 0.16}
{'loss': 1.3433, 'grad_norm': 12.541275978088379, 'learning_rate': 9.999670147091728e-07, 'epoch': 0.16}
{'loss': 1.4185, 'grad_norm': 5.750135898590088, 'learning_rate': 9.99925784115674e-07, 'epoch': 0.17}
{'loss': 1.4426, 'grad_norm': 4.701195240020752, 'learning_rate': 9.998680631888088e-07, 'epoch': 0.17}
{'loss': 1.4866, 'grad_norm': 19.61929702758789, 'learning_rate': 9.997938538325338e-07, 'epoch': 0.18}
{'loss': 1.3816, 'grad_norm': 37.8394660949707, 'learning_rate': 9.997031584946869e-07, 'epoch': 0.18}
{'loss': 1.5224, 'grad_norm': 88.44841766357422, 'learning_rate': 9.995959801669042e-07, 'epoch': 0.19}
{'loss': 1.4451, 'grad_norm': 7.066860198974609, 'learning_rate': 9.994723223845238e-07, 'epoch': 0.19}
{'loss': 1.4515, 'grad_norm': 5.3919243812561035, 'learning_rate': 9.99332189226467e-07, 'epoch': 0.2}
{'loss': 1.3084, 'grad_norm': 4.031851291656494, 'learning_rate': 9.99175585315105e-07, 'epoch': 0.2}
{'loss': 1.3018, 'grad_norm': 14.150941848754883, 'learning_rate': 9.990025158161059e-07, 'epoch': 0.21}
{'loss': 1.4037, 'grad_norm': 8.274596214294434, 'learning_rate': 9.988129864382643e-07, 'epoch': 0.21}
{'loss': 1.392, 'grad_norm': 6.5410332679748535, 'learning_rate': 9.986070034333138e-07, 'epoch': 0.22}
{'loss': 1.284, 'grad_norm': 4.153669357299805, 'learning_rate': 9.983845735957194e-07, 'epoch': 0.22}
{'loss': 1.521, 'grad_norm': 28.99458885192871, 'learning_rate': 9.981457042624549e-07, 'epoch': 0.23}
{'loss': 1.3063, 'grad_norm': 7.728817462921143, 'learning_rate': 9.978904033127591e-07, 'epoch': 0.23}
{'loss': 1.2572, 'grad_norm': 3.599886178970337, 'learning_rate': 9.976186791678782e-07, 'epoch': 0.24}
{'loss': 1.1973, 'grad_norm': 3.012237548828125, 'learning_rate': 9.973305407907855e-07, 'epoch': 0.24}
{'loss': 1.4129, 'grad_norm': 6.254131317138672, 'learning_rate': 9.97025997685888e-07, 'epoch': 0.25}
{'loss': 1.3563, 'grad_norm': 4.7631683349609375, 'learning_rate': 9.96705059898711e-07, 'epoch': 0.25}
{'loss': 1.5672, 'grad_norm': 7.435479640960693, 'learning_rate': 9.963677380155682e-07, 'epoch': 0.26}
{'loss': 1.4958, 'grad_norm': 7.611259937286377, 'learning_rate': 9.960140431632121e-07, 'epoch': 0.26}
{'loss': 1.3695, 'grad_norm': 4.227647304534912, 'learning_rate': 9.95643987008466e-07, 'epoch': 0.27}
{'loss': 1.3388, 'grad_norm': 3.3894753456115723, 'learning_rate': 9.952575817578406e-07, 'epoch': 0.28}
{'loss': 1.3305, 'grad_norm': 3.1791632175445557, 'learning_rate': 9.948548401571306e-07, 'epoch': 0.28}
{'loss': 1.5076, 'grad_norm': 3.2395131587982178, 'learning_rate': 9.944357754909945e-07, 'epoch': 0.29}
{'loss': 1.3453, 'grad_norm': 6.124417781829834, 'learning_rate': 9.940004015825158e-07, 'epoch': 0.29}
{'loss': 1.5086, 'grad_norm': 4.454812526702881, 'learning_rate': 9.935487327927486e-07, 'epoch': 0.3}
{'loss': 1.1533, 'grad_norm': 3.588496685028076, 'learning_rate': 9.930807840202416e-07, 'epoch': 0.3}
{'loss': 1.423, 'grad_norm': 3.9131033420562744, 'learning_rate': 9.925965707005484e-07, 'epoch': 0.31}
{'loss': 1.4309, 'grad_norm': 4.221859931945801, 'learning_rate': 9.920961088057183e-07, 'epoch': 0.31}
{'loss': 1.3541, 'grad_norm': 3.606921434402466, 'learning_rate': 9.91579414843768e-07, 'epoch': 0.32}
{'loss': 1.4156, 'grad_norm': 4.012797832489014, 'learning_rate': 9.910465058581394e-07, 'epoch': 0.32}
{'loss': 1.5421, 'grad_norm': 4.419676303863525, 'learning_rate': 9.904973994271347e-07, 'epoch': 0.33}
{'loss': 1.2737, 'grad_norm': 2.8881471157073975, 'learning_rate': 9.899321136633388e-07, 'epoch': 0.33}
{'loss': 1.2874, 'grad_norm': 5568.611328125, 'learning_rate': 9.89350667213021e-07, 'epoch': 0.34}
{'loss': 1.3926, 'grad_norm': 3.951688051223755, 'learning_rate': 9.887530792555192e-07, 'epoch': 0.34}
{'loss': 1.4078, 'grad_norm': 7.691710472106934, 'learning_rate': 9.88139369502609e-07, 'epoch': 0.35}
{'loss': 1.2375, 'grad_norm': 5.294528961181641, 'learning_rate': 9.875095581978519e-07, 'epoch': 0.35}
{'loss': 1.368, 'grad_norm': 7.049592018127441, 'learning_rate': 9.868636661159283e-07, 'epoch': 0.36}
{'loss': 1.3663, 'grad_norm': 5.100051403045654, 'learning_rate': 9.86201714561952e-07, 'epoch': 0.36}
{'loss': 1.2861, 'grad_norm': 3.355480432510376, 'learning_rate': 9.855237253707674e-07, 'epoch': 0.37}
{'loss': 1.383, 'grad_norm': 5.655385971069336, 'learning_rate': 9.848297209062296e-07, 'epoch': 0.37}
{'loss': 1.3968, 'grad_norm': 21.043224334716797, 'learning_rate': 9.84119724060467e-07, 'epoch': 0.38}
{'loss': 1.2623, 'grad_norm': 3.613191843032837, 'learning_rate': 9.833937582531244e-07, 'epoch': 0.38}
{'loss': 1.262, 'grad_norm': 40.98866271972656, 'learning_rate': 9.82651847430593e-07, 'epoch': 0.39}
{'loss': 1.2884, 'grad_norm': 3.2890961170196533, 'learning_rate': 9.818940160652192e-07, 'epoch': 0.39}
{'loss': 1.389, 'grad_norm': 12.939948081970215, 'learning_rate': 9.811202891544965e-07, 'epoch': 0.4}
{'loss': 1.3548, 'grad_norm': 4.1397480964660645, 'learning_rate': 9.803306922202427e-07, 'epoch': 0.41}
{'loss': 1.218, 'grad_norm': 13.417027473449707, 'learning_rate': 9.79525251307757e-07, 'epoch': 0.41}
{'loss': 1.4377, 'grad_norm': 3.7042064666748047, 'learning_rate': 9.787039929849616e-07, 'epoch': 0.42}
{'loss': 1.1166, 'grad_norm': 3.8365273475646973, 'learning_rate': 9.778669443415243e-07, 'epoch': 0.42}
{'loss': 1.0915, 'grad_norm': 4.763855457305908, 'learning_rate': 9.770141329879656e-07, 'epoch': 0.43}
{'loss': 1.0897, 'grad_norm': 3.336395263671875, 'learning_rate': 9.761455870547481e-07, 'epoch': 0.43}
{'loss': 1.0267, 'grad_norm': 3.388810396194458, 'learning_rate': 9.752613351913484e-07, 'epoch': 0.44}
{'loss': 1.5333, 'grad_norm': 6.591409206390381, 'learning_rate': 9.743614065653118e-07, 'epoch': 0.44}
{'loss': 1.3682, 'grad_norm': 3.5658624172210693, 'learning_rate': 9.734458308612905e-07, 'epoch': 0.45}
{'loss': 1.4096, 'grad_norm': 5.158599376678467, 'learning_rate': 9.725146382800642e-07, 'epoch': 0.45}
{'loss': 1.408, 'grad_norm': 3.113602876663208, 'learning_rate': 9.715678595375448e-07, 'epoch': 0.46}
{'loss': 1.3203, 'grad_norm': 15.949844360351562, 'learning_rate': 9.706055258637617e-07, 'epoch': 0.46}
{'loss': 1.058, 'grad_norm': 3.332575559616089, 'learning_rate': 9.696276690018329e-07, 'epoch': 0.47}
{'loss': 1.4025, 'grad_norm': 4.668982982635498, 'learning_rate': 9.686343212069172e-07, 'epoch': 0.47}
{'loss': 1.2162, 'grad_norm': 3.7527501583099365, 'learning_rate': 9.676255152451506e-07, 'epoch': 0.48}
{'loss': 1.3679, 'grad_norm': 13.366371154785156, 'learning_rate': 9.66601284392566e-07, 'epoch': 0.48}
{'loss': 1.4291, 'grad_norm': 4.513446807861328, 'learning_rate': 9.655616624339944e-07, 'epoch': 0.49}
{'loss': 1.2713, 'grad_norm': 4.051785945892334, 'learning_rate': 9.645066836619508e-07, 'epoch': 0.49}
{'loss': 1.2389, 'grad_norm': 4.391263008117676, 'learning_rate': 9.634363828755043e-07, 'epoch': 0.5}
{'loss': 1.3401, 'grad_norm': 9.672200202941895, 'learning_rate': 9.623507953791286e-07, 'epoch': 0.5}
{'loss': 1.2882, 'grad_norm': 3.525205373764038, 'learning_rate': 9.612499569815381e-07, 'epoch': 0.51}
{'loss': 1.3036, 'grad_norm': 5.097316741943359, 'learning_rate': 9.601339039945073e-07, 'epoch': 0.51}
{'loss': 1.3753, 'grad_norm': 3.093858242034912, 'learning_rate': 9.590026732316719e-07, 'epoch': 0.52}
{'loss': 1.3344, 'grad_norm': 2.9269566535949707, 'learning_rate': 9.578563020073152e-07, 'epoch': 0.52}
{'loss': 1.3455, 'grad_norm': 4.543457508087158, 'learning_rate': 9.566948281351373e-07, 'epoch': 0.53}
{'loss': 1.3638, 'grad_norm': 4.189098358154297, 'learning_rate': 9.555182899270078e-07, 'epoch': 0.54}
{'loss': 1.3197, 'grad_norm': 3.766282320022583, 'learning_rate': 9.543267261917014e-07, 'epoch': 0.54}
{'loss': 1.2948, 'grad_norm': 3.948251485824585, 'learning_rate': 9.531201762336189e-07, 'epoch': 0.55}
{'loss': 1.3209, 'grad_norm': 6.703128814697266, 'learning_rate': 9.518986798514897e-07, 'epoch': 0.55}
{'loss': 1.4093, 'grad_norm': 5.260262966156006, 'learning_rate': 9.506622773370594e-07, 'epoch': 0.56}
{'loss': 1.2457, 'grad_norm': 3.7843832969665527, 'learning_rate': 9.494110094737607e-07, 'epoch': 0.56}
{'loss': 1.0745, 'grad_norm': 3.5886647701263428, 'learning_rate': 9.481449175353684e-07, 'epoch': 0.57}
{'loss': 1.203, 'grad_norm': 3.736538887023926, 'learning_rate': 9.468640432846378e-07, 'epoch': 0.57}
{'loss': 1.2833, 'grad_norm': 4.561366558074951, 'learning_rate': 9.455684289719269e-07, 'epoch': 0.58}
{'loss': 1.3361, 'grad_norm': 3.2529966831207275, 'learning_rate': 9.442581173338031e-07, 'epoch': 0.58}
{'loss': 1.5115, 'grad_norm': 3.8094546794891357, 'learning_rate': 9.429331515916332e-07, 'epoch': 0.59}
{'loss': 1.2721, 'grad_norm': 3.7095088958740234, 'learning_rate': 9.415935754501581e-07, 'epoch': 0.59}
{'loss': 1.3467, 'grad_norm': 4.098691940307617, 'learning_rate': 9.402394330960505e-07, 'epoch': 0.6}
{'loss': 1.3967, 'grad_norm': 10.468095779418945, 'learning_rate': 9.388707691964584e-07, 'epoch': 0.6}
{'loss': 1.3328, 'grad_norm': 4.734163284301758, 'learning_rate': 9.374876288975307e-07, 'epoch': 0.61}
{'loss': 1.2861, 'grad_norm': 5.119931221008301, 'learning_rate': 9.360900578229286e-07, 'epoch': 0.61}
{'loss': 1.3886, 'grad_norm': 3.6576523780822754, 'learning_rate': 9.346781020723207e-07, 'epoch': 0.62}
{'loss': 1.1516, 'grad_norm': 5.92439079284668, 'learning_rate': 9.332518082198623e-07, 'epoch': 0.62}
{'loss': 1.2438, 'grad_norm': 8.754724502563477, 'learning_rate': 9.318112233126587e-07, 'epoch': 0.63}
{'loss': 1.3703, 'grad_norm': 3.3020901679992676, 'learning_rate': 9.303563948692139e-07, 'epoch': 0.63}
{'loss': 1.203, 'grad_norm': 3.7820675373077393, 'learning_rate': 9.28887370877863e-07, 'epoch': 0.64}
{'loss': 1.2933, 'grad_norm': 3.6822941303253174, 'learning_rate': 9.27404199795189e-07, 'epoch': 0.64}
{'loss': 1.3194, 'grad_norm': 3.9633374214172363, 'learning_rate': 9.259069305444252e-07, 'epoch': 0.65}
{'loss': 1.1012, 'grad_norm': 3.644605875015259, 'learning_rate': 9.243956125138401e-07, 'epoch': 0.65}
{'loss': 1.1456, 'grad_norm': 2.8495635986328125, 'learning_rate': 9.228702955551099e-07, 'epoch': 0.66}
{'loss': 1.3952, 'grad_norm': 7.685378551483154, 'learning_rate': 9.21331029981673e-07, 'epoch': 0.66}
{'loss': 1.2295, 'grad_norm': 2.8500869274139404, 'learning_rate': 9.197778665670706e-07, 'epoch': 0.67}
{'loss': 1.097, 'grad_norm': 24.731403350830078, 'learning_rate': 9.18210856543272e-07, 'epoch': 0.68}
{'loss': 1.3173, 'grad_norm': 3.2460744380950928, 'learning_rate': 9.166300515989849e-07, 'epoch': 0.68}
{'loss': 1.3801, 'grad_norm': 8.257628440856934, 'learning_rate': 9.150355038779502e-07, 'epoch': 0.69}
{'loss': 1.1682, 'grad_norm': 3.025071620941162, 'learning_rate': 9.134272659772219e-07, 'epoch': 0.69}
{'loss': 1.2149, 'grad_norm': 2.921734094619751, 'learning_rate': 9.118053909454324e-07, 'epoch': 0.7}
{'loss': 1.2288, 'grad_norm': 3.602294921875, 'learning_rate': 9.101699322810423e-07, 'epoch': 0.7}
{'loss': 1.3459, 'grad_norm': 2.9912660121917725, 'learning_rate': 9.085209439305764e-07, 'epoch': 0.71}
{'loss': 1.3729, 'grad_norm': 4.562050819396973, 'learning_rate': 9.068584802868433e-07, 'epoch': 0.71}
{'loss': 1.2152, 'grad_norm': 21.64031219482422, 'learning_rate': 9.051825961871422e-07, 'epoch': 0.72}
{'loss': 1.3381, 'grad_norm': 12.432116508483887, 'learning_rate': 9.034933469114532e-07, 'epoch': 0.72}
{'loss': 1.1893, 'grad_norm': 10.814836502075195, 'learning_rate': 9.017907881806145e-07, 'epoch': 0.73}
{'loss': 1.2231, 'grad_norm': 18.067842483520508, 'learning_rate': 9.000749761544841e-07, 'epoch': 0.73}
{'loss': 1.2431, 'grad_norm': 3.9499354362487793, 'learning_rate': 8.983459674300875e-07, 'epoch': 0.74}
{'loss': 1.219, 'grad_norm': 53.108734130859375, 'learning_rate': 8.966038190397507e-07, 'epoch': 0.74}
{'loss': 1.3031, 'grad_norm': 3.6113078594207764, 'learning_rate': 8.948485884492185e-07, 'epoch': 0.75}
{'loss': 1.3718, 'grad_norm': 3.6194839477539062, 'learning_rate': 8.930803335557602e-07, 'epoch': 0.75}
{'loss': 1.2939, 'grad_norm': 3.8217501640319824, 'learning_rate': 8.912991126862586e-07, 'epoch': 0.76}
{'loss': 1.3304, 'grad_norm': 28.589433670043945, 'learning_rate': 8.895049845952867e-07, 'epoch': 0.76}
{'loss': 1.4246, 'grad_norm': 2.9819912910461426, 'learning_rate': 8.876980084631692e-07, 'epoch': 0.77}
{'loss': 1.3815, 'grad_norm': 4.580561637878418, 'learning_rate': 8.858782438940311e-07, 'epoch': 0.77}
{'loss': 1.1976, 'grad_norm': 6.03347110748291, 'learning_rate': 8.840457509138306e-07, 'epoch': 0.78}
{'loss': 1.2521, 'grad_norm': 4.217213153839111, 'learning_rate': 8.822005899683804e-07, 'epoch': 0.78}
{'loss': 1.2943, 'grad_norm': 2.8611700534820557, 'learning_rate': 8.803428219213526e-07, 'epoch': 0.79}
{'loss': 1.4423, 'grad_norm': 6.159505367279053, 'learning_rate': 8.784725080522721e-07, 'epoch': 0.79}
{'loss': 1.2325, 'grad_norm': 5.746830463409424, 'learning_rate': 8.765897100544943e-07, 'epoch': 0.8}
{'loss': 1.2172, 'grad_norm': 4.192638874053955, 'learning_rate': 8.74694490033171e-07, 'epoch': 0.81}
{'loss': 1.3975, 'grad_norm': 66.35984802246094, 'learning_rate': 8.727869105032013e-07, 'epoch': 0.81}
{'loss': 1.4261, 'grad_norm': 6.445343971252441, 'learning_rate': 8.708670343871696e-07, 'epoch': 0.82}
{'loss': 1.1194, 'grad_norm': 3.7540595531463623, 'learning_rate': 8.6893492501327e-07, 'epoch': 0.82}
{'loss': 1.1108, 'grad_norm': 4.970043659210205, 'learning_rate': 8.669906461132181e-07, 'epoch': 0.83}
{'loss': 1.1707, 'grad_norm': 2.8102951049804688, 'learning_rate': 8.650342618201473e-07, 'epoch': 0.83}
{'loss': 1.4462, 'grad_norm': 5.043874740600586, 'learning_rate': 8.630658366664951e-07, 'epoch': 0.84}
{'loss': 1.1285, 'grad_norm': 3.7043840885162354, 'learning_rate': 8.610854355818727e-07, 'epoch': 0.84}
{'loss': 1.1533, 'grad_norm': 4.526189804077148, 'learning_rate': 8.590931238909245e-07, 'epoch': 0.85}
{'loss': 1.4638, 'grad_norm': 5.633303165435791, 'learning_rate': 8.570889673111732e-07, 'epoch': 0.85}
{'loss': 1.24, 'grad_norm': 4.420906066894531, 'learning_rate': 8.550730319508515e-07, 'epoch': 0.86}
{'loss': 1.4719, 'grad_norm': 3.29626727104187, 'learning_rate': 8.530453843067221e-07, 'epoch': 0.86}
{'loss': 1.2872, 'grad_norm': 2.8910322189331055, 'learning_rate': 8.510060912618835e-07, 'epoch': 0.87}
{'loss': 1.3063, 'grad_norm': 3.8007869720458984, 'learning_rate': 8.489552200835648e-07, 'epoch': 0.87}
{'loss': 1.2271, 'grad_norm': 13.25190544128418, 'learning_rate': 8.468928384209059e-07, 'epoch': 0.88}
{'loss': 1.3077, 'grad_norm': 5.1406779289245605, 'learning_rate': 8.448190143027268e-07, 'epoch': 0.88}
{'loss': 1.2933, 'grad_norm': 6.500189781188965, 'learning_rate': 8.427338161352835e-07, 'epoch': 0.89}
{'loss': 1.3015, 'grad_norm': 3.227196216583252, 'learning_rate': 8.406373127000109e-07, 'epoch': 0.89}
{'loss': 1.174, 'grad_norm': 3.2981114387512207, 'learning_rate': 8.385295731512549e-07, 'epoch': 0.9}
{'loss': 1.1474, 'grad_norm': 3.4518239498138428, 'learning_rate': 8.36410667013991e-07, 'epoch': 0.9}
{'loss': 1.4769, 'grad_norm': 3.047546863555908, 'learning_rate': 8.342806641815303e-07, 'epoch': 0.91}
{'loss': 1.2589, 'grad_norm': 3.1979849338531494, 'learning_rate': 8.321396349132156e-07, 'epoch': 0.91}
{'loss': 1.2189, 'grad_norm': 3.722100019454956, 'learning_rate': 8.299876498321022e-07, 'epoch': 0.92}
{'loss': 1.3263, 'grad_norm': 3.422353744506836, 'learning_rate': 8.27824779922629e-07, 'epoch': 0.92}
{'loss': 1.3957, 'grad_norm': 7.0451836585998535, 'learning_rate': 8.256510965282774e-07, 'epoch': 0.93}
{'loss': 1.307, 'grad_norm': 19.665681838989258, 'learning_rate': 8.234666713492178e-07, 'epoch': 0.94}
{'loss': 1.1228, 'grad_norm': 3.255563259124756, 'learning_rate': 8.21271576439944e-07, 'epoch': 0.94}
{'loss': 1.2462, 'grad_norm': 6.554731845855713, 'learning_rate': 8.190658842068972e-07, 'epoch': 0.95}
{'loss': 1.2533, 'grad_norm': 3.7602083683013916, 'learning_rate': 8.168496674060769e-07, 'epoch': 0.95}
{'loss': 1.2242, 'grad_norm': 4.000855922698975, 'learning_rate': 8.146229991406421e-07, 'epoch': 0.96}
{'loss': 1.2534, 'grad_norm': 3.018752336502075, 'learning_rate': 8.123859528584984e-07, 'epoch': 0.96}
{'loss': 1.2743, 'grad_norm': 2.8892102241516113, 'learning_rate': 8.101386023498767e-07, 'epoch': 0.97}
{'loss': 1.2699, 'grad_norm': 3.499385356903076, 'learning_rate': 8.078810217448985e-07, 'epoch': 0.97}
{'loss': 1.19, 'grad_norm': 3.662698745727539, 'learning_rate': 8.056132855111304e-07, 'epoch': 0.98}
{'loss': 1.3529, 'grad_norm': 4.298923969268799, 'learning_rate': 8.033354684511286e-07, 'epoch': 0.98}
{'loss': 1.1621, 'grad_norm': 2.996273994445801, 'learning_rate': 8.010476456999711e-07, 'epoch': 0.99}
{'loss': 1.2492, 'grad_norm': 2.998067617416382, 'learning_rate': 7.987498927227787e-07, 'epoch': 0.99}
{'loss': 1.2313, 'grad_norm': 5.614193439483643, 'learning_rate': 7.964422853122268e-07, 'epoch': 1.0}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-192/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-192/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-192/model.safetensors.index.json.
2024-12-31 02:04:46,065 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-192/pytorch_model_fsdp.bin
2024-12-31 02:05:35,044 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-192/pytorch_model_fsdp.bin
2024-12-31 02:06:03,052 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-192/optimizer.bin
2024-12-31 02:07:26,510 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-192/optimizer.bin
                                                                                                                                                                                               
{'loss': 1.1738, 'grad_norm': 4.309472560882568, 'learning_rate': 7.941248995860445e-07, 'epoch': 1.0}
{'loss': 1.156, 'grad_norm': 3.1294329166412354, 'learning_rate': 7.917978119845044e-07, 'epoch': 1.01}
{'loss': 1.2552, 'grad_norm': 48.48625946044922, 'learning_rate': 7.894610992679007e-07, 'epoch': 1.01}
{'loss': 1.1935, 'grad_norm': 3.6698153018951416, 'learning_rate': 7.871148385140178e-07, 'epoch': 1.02}
{'loss': 1.2592, 'grad_norm': 5.339808940887451, 'learning_rate': 7.847591071155871e-07, 'epoch': 1.02}
{'loss': 1.2463, 'grad_norm': 7.8559489250183105, 'learning_rate': 7.823939827777344e-07, 'epoch': 1.03}
{'loss': 1.2285, 'grad_norm': 19.064048767089844, 'learning_rate': 7.800195435154178e-07, 'epoch': 1.03}
{'loss': 1.2604, 'grad_norm': 3.2029948234558105, 'learning_rate': 7.776358676508521e-07, 'epoch': 1.04}
{'loss': 1.1995, 'grad_norm': 13.00615119934082, 'learning_rate': 7.752430338109277e-07, 'epoch': 1.04}
{'loss': 1.2895, 'grad_norm': 12.620049476623535, 'learning_rate': 7.728411209246155e-07, 'epoch': 1.05}
{'loss': 1.1513, 'grad_norm': 2.872232437133789, 'learning_rate': 7.704302082203639e-07, 'epoch': 1.05}
{'loss': 1.0512, 'grad_norm': 3.091080665588379, 'learning_rate': 7.680103752234857e-07, 'epoch': 1.06}
{'loss': 1.1221, 'grad_norm': 4.195025444030762, 'learning_rate': 7.655817017535339e-07, 'epoch': 1.06}
{'loss': 1.1936, 'grad_norm': 3.0557405948638916, 'learning_rate': 7.631442679216702e-07, 'epoch': 1.07}
{'loss': 1.1107, 'grad_norm': 3.1537985801696777, 'learning_rate': 7.60698154128021e-07, 'epoch': 1.08}
{'loss': 1.3556, 'grad_norm': 3.364454507827759, 'learning_rate': 7.582434410590268e-07, 'epoch': 1.08}
{'loss': 1.3086, 'grad_norm': 3.211444854736328, 'learning_rate': 7.557802096847799e-07, 'epoch': 1.09}
{'loss': 1.3041, 'grad_norm': 3.717759370803833, 'learning_rate': 7.533085412563534e-07, 'epoch': 1.09}
{'loss': 1.1851, 'grad_norm': 4.171828746795654, 'learning_rate': 7.508285173031215e-07, 'epoch': 1.1}
{'loss': 1.1821, 'grad_norm': 5.148148059844971, 'learning_rate': 7.483402196300704e-07, 'epoch': 1.1}
{'loss': 1.0175, 'grad_norm': 3.013925790786743, 'learning_rate': 7.458437303150994e-07, 'epoch': 1.11}
{'loss': 1.1817, 'grad_norm': 3.1570870876312256, 'learning_rate': 7.433391317063133e-07, 'epoch': 1.11}
{'loss': 1.2293, 'grad_norm': 3.2743947505950928, 'learning_rate': 7.408265064193071e-07, 'epoch': 1.12}
{'loss': 1.3061, 'grad_norm': 4.386049747467041, 'learning_rate': 7.383059373344401e-07, 'epoch': 1.12}
{'loss': 1.3133, 'grad_norm': 3.649392604827881, 'learning_rate': 7.357775075941024e-07, 'epoch': 1.13}
{'loss': 1.2137, 'grad_norm': 4.4709954261779785, 'learning_rate': 7.332413005999717e-07, 'epoch': 1.13}
{'loss': 1.2444, 'grad_norm': 3.5098865032196045, 'learning_rate': 7.306974000102634e-07, 'epoch': 1.14}
{'loss': 1.3677, 'grad_norm': 4.303476810455322, 'learning_rate': 7.281458897369705e-07, 'epoch': 1.14}
{'loss': 1.1967, 'grad_norm': 4.807163715362549, 'learning_rate': 7.25586853943095e-07, 'epoch': 1.15}
{'loss': 1.1644, 'grad_norm': 5.192865371704102, 'learning_rate': 7.230203770398732e-07, 'epoch': 1.15}
{'loss': 1.308, 'grad_norm': 6.542685508728027, 'learning_rate': 7.204465436839902e-07, 'epoch': 1.16}
{'loss': 1.0617, 'grad_norm': 6.869588851928711, 'learning_rate': 7.178654387747877e-07, 'epoch': 1.16}
{'loss': 1.0066, 'grad_norm': 3.967907428741455, 'learning_rate': 7.152771474514642e-07, 'epoch': 1.17}
{'loss': 1.2762, 'grad_norm': 3.2390658855438232, 'learning_rate': 7.126817550902655e-07, 'epoch': 1.17}
{'loss': 0.7823, 'grad_norm': 2.4789042472839355, 'learning_rate': 7.100793473016698e-07, 'epoch': 1.18}
{'loss': 1.1768, 'grad_norm': 19.58527946472168, 'learning_rate': 7.074700099275622e-07, 'epoch': 1.18}
{'loss': 1.1925, 'grad_norm': 47.62346267700195, 'learning_rate': 7.04853829038405e-07, 'epoch': 1.19}
{'loss': 1.2389, 'grad_norm': 3.469428300857544, 'learning_rate': 7.022308909303974e-07, 'epoch': 1.19}
{'loss': 1.3222, 'grad_norm': 3.874833822250366, 'learning_rate': 6.996012821226288e-07, 'epoch': 1.2}
{'loss': 1.2352, 'grad_norm': 4.674045085906982, 'learning_rate': 6.969650893542261e-07, 'epoch': 1.21}
{'loss': 1.1747, 'grad_norm': 4.104248523712158, 'learning_rate': 6.943223995814913e-07, 'epoch': 1.21}
{'loss': 1.2905, 'grad_norm': 3.000074625015259, 'learning_rate': 6.916732999750343e-07, 'epoch': 1.22}
{'loss': 1.1547, 'grad_norm': 5.420166492462158, 'learning_rate': 6.890178779168963e-07, 'epoch': 1.22}
{'loss': 1.2038, 'grad_norm': 2.985180139541626, 'learning_rate': 6.863562209976685e-07, 'epoch': 1.23}
{'loss': 1.1075, 'grad_norm': 5.027806758880615, 'learning_rate': 6.836884170136025e-07, 'epoch': 1.23}
{'loss': 1.1204, 'grad_norm': 3.6253042221069336, 'learning_rate': 6.810145539637145e-07, 'epoch': 1.24}
{'loss': 1.1225, 'grad_norm': 2.9145002365112305, 'learning_rate': 6.783347200468817e-07, 'epoch': 1.24}
{'loss': 1.3996, 'grad_norm': 5.661989688873291, 'learning_rate': 6.756490036589345e-07, 'epoch': 1.25}
{'loss': 1.0815, 'grad_norm': 3.2664525508880615, 'learning_rate': 6.729574933897396e-07, 'epoch': 1.25}
{'loss': 1.1423, 'grad_norm': 7.461069583892822, 'learning_rate': 6.702602780202778e-07, 'epoch': 1.26}
{'loss': 1.335, 'grad_norm': 3.8216495513916016, 'learning_rate': 6.675574465197165e-07, 'epoch': 1.26}
{'loss': 1.2523, 'grad_norm': 3.253669500350952, 'learning_rate': 6.64849088042474e-07, 'epoch': 1.27}
{'loss': 1.3358, 'grad_norm': 3.7058799266815186, 'learning_rate': 6.621352919252788e-07, 'epoch': 1.27}
{'loss': 1.2119, 'grad_norm': 5.24587869644165, 'learning_rate': 6.594161476842233e-07, 'epoch': 1.28}
{'loss': 1.1706, 'grad_norm': 3.767378807067871, 'learning_rate': 6.566917450118108e-07, 'epoch': 1.28}
{'loss': 1.2493, 'grad_norm': 5.259856700897217, 'learning_rate': 6.53962173773997e-07, 'epoch': 1.29}
{'loss': 1.2643, 'grad_norm': 3.6175246238708496, 'learning_rate': 6.512275240072252e-07, 'epoch': 1.29}
{'loss': 1.0907, 'grad_norm': 2.750710964202881, 'learning_rate': 6.484878859154574e-07, 'epoch': 1.3}
{'loss': 1.2441, 'grad_norm': 8.447158813476562, 'learning_rate': 6.457433498671978e-07, 'epoch': 1.3}
{'loss': 1.1799, 'grad_norm': 4.199581146240234, 'learning_rate': 6.429940063925127e-07, 'epoch': 1.31}
{'loss': 1.1379, 'grad_norm': 3.351046323776245, 'learning_rate': 6.402399461800442e-07, 'epoch': 1.31}
{'loss': 1.0836, 'grad_norm': 4.753584861755371, 'learning_rate': 6.374812600740187e-07, 'epoch': 1.32}
{'loss': 1.4106, 'grad_norm': 2.875314712524414, 'learning_rate': 6.347180390712497e-07, 'epoch': 1.32}
{'loss': 1.2649, 'grad_norm': 3.5995070934295654, 'learning_rate': 6.319503743181371e-07, 'epoch': 1.33}
{'loss': 1.1629, 'grad_norm': 2.9003448486328125, 'learning_rate': 6.291783571076611e-07, 'epoch': 1.34}
{'loss': 1.3103, 'grad_norm': 3.599303722381592, 'learning_rate': 6.26402078876369e-07, 'epoch': 1.34}
{'loss': 1.1548, 'grad_norm': 3.4444103240966797, 'learning_rate': 6.236216312013614e-07, 'epoch': 1.35}
{'loss': 1.2388, 'grad_norm': 2.833723783493042, 'learning_rate': 6.208371057972694e-07, 'epoch': 1.35}
{'loss': 1.2115, 'grad_norm': 9.254194259643555, 'learning_rate': 6.18048594513231e-07, 'epoch': 1.36}
{'loss': 1.2688, 'grad_norm': 12.947043418884277, 'learning_rate': 6.1525618932986e-07, 'epoch': 1.36}
{'loss': 1.2961, 'grad_norm': 3.5259439945220947, 'learning_rate': 6.124599823562134e-07, 'epoch': 1.37}
{'loss': 1.0889, 'grad_norm': 3.925966739654541, 'learning_rate': 6.096600658267518e-07, 'epoch': 1.37}
{'loss': 1.1455, 'grad_norm': 44.02193832397461, 'learning_rate': 6.068565320982981e-07, 'epoch': 1.38}
{'loss': 1.1701, 'grad_norm': 4.322670936584473, 'learning_rate': 6.0404947364699e-07, 'epoch': 1.38}
{'loss': 1.0683, 'grad_norm': 5.434887886047363, 'learning_rate': 6.012389830652306e-07, 'epoch': 1.39}
{'loss': 1.2724, 'grad_norm': 4.805496692657471, 'learning_rate': 5.984251530586336e-07, 'epoch': 1.39}
{'loss': 1.2755, 'grad_norm': 3.0196375846862793, 'learning_rate': 5.956080764429653e-07, 'epoch': 1.4}
{'loss': 1.2235, 'grad_norm': 4.38873291015625, 'learning_rate': 5.927878461410836e-07, 'epoch': 1.4}
{'loss': 1.0929, 'grad_norm': 4.020870208740234, 'learning_rate': 5.899645551798725e-07, 'epoch': 1.41}
{'loss': 1.3235, 'grad_norm': 6.950734615325928, 'learning_rate': 5.871382966871728e-07, 'epoch': 1.41}
{'loss': 1.2072, 'grad_norm': 4.241021156311035, 'learning_rate': 5.843091638887124e-07, 'epoch': 1.42}
{'loss': 1.1317, 'grad_norm': 5.013844966888428, 'learning_rate': 5.814772501050286e-07, 'epoch': 1.42}
{'loss': 1.2121, 'grad_norm': 3.594465970993042, 'learning_rate': 5.786426487483914e-07, 'epoch': 1.43}
{'loss': 1.3877, 'grad_norm': 8.095749855041504, 'learning_rate': 5.758054533197222e-07, 'epoch': 1.43}
{'loss': 1.1748, 'grad_norm': 2.6264398097991943, 'learning_rate': 5.729657574055089e-07, 'epoch': 1.44}
{'loss': 1.1659, 'grad_norm': 3.8319180011749268, 'learning_rate': 5.701236546747197e-07, 'epoch': 1.44}
{'loss': 1.0587, 'grad_norm': 2.906202793121338, 'learning_rate': 5.672792388757127e-07, 'epoch': 1.45}
{'loss': 1.1727, 'grad_norm': 13.451154708862305, 'learning_rate': 5.644326038331439e-07, 'epoch': 1.45}
{'loss': 0.9838, 'grad_norm': 3.5280990600585938, 'learning_rate': 5.615838434448725e-07, 'epoch': 1.46}
{'loss': 1.1154, 'grad_norm': 2.805335283279419, 'learning_rate': 5.587330516788633e-07, 'epoch': 1.46}
{'loss': 1.3275, 'grad_norm': 2.7822458744049072, 'learning_rate': 5.558803225700872e-07, 'epoch': 1.47}
{'loss': 1.1923, 'grad_norm': 3.4177796840667725, 'learning_rate': 5.530257502174196e-07, 'epoch': 1.48}
{'loss': 1.1402, 'grad_norm': 2.9571850299835205, 'learning_rate': 5.501694287805361e-07, 'epoch': 1.48}
{'loss': 1.2631, 'grad_norm': 3.0336363315582275, 'learning_rate': 5.473114524768068e-07, 'epoch': 1.49}
{'loss': 1.2954, 'grad_norm': 3.709723711013794, 'learning_rate': 5.444519155781889e-07, 'epoch': 1.49}
{'loss': 1.2363, 'grad_norm': 3.3707213401794434, 'learning_rate': 5.415909124081163e-07, 'epoch': 1.5}
{'loss': 1.2185, 'grad_norm': 4.047619342803955, 'learning_rate': 5.387285373383892e-07, 'epoch': 1.5}
{'loss': 1.3085, 'grad_norm': 3.27148175239563, 'learning_rate': 5.358648847860598e-07, 'epoch': 1.51}
{'loss': 1.0928, 'grad_norm': 5.135400772094727, 'learning_rate': 5.330000492103198e-07, 'epoch': 1.51}
{'loss': 1.1679, 'grad_norm': 2.7465319633483887, 'learning_rate': 5.301341251093827e-07, 'epoch': 1.52}
{'loss': 1.1069, 'grad_norm': 2.6453638076782227, 'learning_rate': 5.272672070173682e-07, 'epoch': 1.52}
{'loss': 1.1691, 'grad_norm': 43.69292449951172, 'learning_rate': 5.243993895011833e-07, 'epoch': 1.53}
{'loss': 1.2298, 'grad_norm': 3.252187967300415, 'learning_rate': 5.215307671574027e-07, 'epoch': 1.53}
{'loss': 1.2287, 'grad_norm': 8.8859224319458, 'learning_rate': 5.18661434609149e-07, 'epoch': 1.54}
{'loss': 1.2263, 'grad_norm': 5.098602771759033, 'learning_rate': 5.157914865029715e-07, 'epoch': 1.54}
{'loss': 1.1319, 'grad_norm': 2.681401014328003, 'learning_rate': 5.129210175057236e-07, 'epoch': 1.55}
{'loss': 1.1988, 'grad_norm': 2.931920289993286, 'learning_rate': 5.100501223014407e-07, 'epoch': 1.55}
{'loss': 1.1749, 'grad_norm': 3.2002103328704834, 'learning_rate': 5.07178895588217e-07, 'epoch': 1.56}
{'loss': 1.1342, 'grad_norm': 3.058272361755371, 'learning_rate': 5.04307432075082e-07, 'epoch': 1.56}
{'loss': 1.1683, 'grad_norm': 3.835158348083496, 'learning_rate': 5.014358264788755e-07, 'epoch': 1.57}
{'loss': 1.1353, 'grad_norm': 2.8114869594573975, 'learning_rate': 4.985641735211245e-07, 'epoch': 1.57}
{'loss': 1.2525, 'grad_norm': 3.6575284004211426, 'learning_rate': 4.95692567924918e-07, 'epoch': 1.58}
{'loss': 0.99, 'grad_norm': 2.810415744781494, 'learning_rate': 4.928211044117829e-07, 'epoch': 1.58}
{'loss': 1.2609, 'grad_norm': 3.0434844493865967, 'learning_rate': 4.899498776985593e-07, 'epoch': 1.59}
{'loss': 1.1327, 'grad_norm': 3.1901321411132812, 'learning_rate': 4.870789824942765e-07, 'epoch': 1.59}
{'loss': 1.2448, 'grad_norm': 15.626957893371582, 'learning_rate': 4.842085134970286e-07, 'epoch': 1.6}
{'loss': 1.0531, 'grad_norm': 3.0496718883514404, 'learning_rate': 4.813385653908509e-07, 'epoch': 1.61}
{'loss': 1.0911, 'grad_norm': 3.0882911682128906, 'learning_rate': 4.784692328425973e-07, 'epoch': 1.61}
{'loss': 1.2361, 'grad_norm': 3.9408233165740967, 'learning_rate': 4.756006104988167e-07, 'epoch': 1.62}
{'loss': 1.2872, 'grad_norm': 3.8670730590820312, 'learning_rate': 4.727327929826318e-07, 'epoch': 1.62}
{'loss': 1.1662, 'grad_norm': 13.373690605163574, 'learning_rate': 4.698658748906174e-07, 'epoch': 1.63}
{'loss': 1.1643, 'grad_norm': 3.088029623031616, 'learning_rate': 4.6699995078968026e-07, 'epoch': 1.63}
{'loss': 1.1976, 'grad_norm': 2.91253662109375, 'learning_rate': 4.6413511521394023e-07, 'epoch': 1.64}
{'loss': 1.1662, 'grad_norm': 3.113680839538574, 'learning_rate': 4.6127146266161083e-07, 'epoch': 1.64}
{'loss': 1.1517, 'grad_norm': 3.439039468765259, 'learning_rate': 4.5840908759188355e-07, 'epoch': 1.65}
{'loss': 1.1133, 'grad_norm': 3.5232419967651367, 'learning_rate': 4.5554808442181104e-07, 'epoch': 1.65}
{'loss': 1.1581, 'grad_norm': 2.9034104347229004, 'learning_rate': 4.5268854752319323e-07, 'epoch': 1.66}
{'loss': 1.2168, 'grad_norm': 3.234509229660034, 'learning_rate': 4.498305712194641e-07, 'epoch': 1.66}
{'loss': 1.1343, 'grad_norm': 3.6107683181762695, 'learning_rate': 4.469742497825804e-07, 'epoch': 1.67}
{'loss': 1.1252, 'grad_norm': 2.752631187438965, 'learning_rate': 4.4411967742991287e-07, 'epoch': 1.67}
{'loss': 1.1383, 'grad_norm': 3.826356887817383, 'learning_rate': 4.412669483211367e-07, 'epoch': 1.68}
{'loss': 0.9821, 'grad_norm': 2.7897872924804688, 'learning_rate': 4.3841615655512756e-07, 'epoch': 1.68}
{'loss': 1.2631, 'grad_norm': 9.729218482971191, 'learning_rate': 4.3556739616685607e-07, 'epoch': 1.69}
{'loss': 1.2621, 'grad_norm': 3.347778081893921, 'learning_rate': 4.3272076112428745e-07, 'epoch': 1.69}
{'loss': 1.3059, 'grad_norm': 4.002532958984375, 'learning_rate': 4.2987634532528046e-07, 'epoch': 1.7}
{'loss': 1.2013, 'grad_norm': 4.199285984039307, 'learning_rate': 4.2703424259449104e-07, 'epoch': 1.7}
{'loss': 1.2335, 'grad_norm': 3.1697657108306885, 'learning_rate': 4.2419454668027785e-07, 'epoch': 1.71}
{'loss': 1.262, 'grad_norm': 4.235988140106201, 'learning_rate': 4.213573512516085e-07, 'epoch': 1.71}
{'loss': 1.1641, 'grad_norm': 5.178956508636475, 'learning_rate': 4.1852274989497145e-07, 'epoch': 1.72}
{'loss': 1.1254, 'grad_norm': 3.5763251781463623, 'learning_rate': 4.1569083611128753e-07, 'epoch': 1.72}
{'loss': 1.1095, 'grad_norm': 6.834630012512207, 'learning_rate': 4.128617033128271e-07, 'epoch': 1.73}
{'loss': 1.1281, 'grad_norm': 3.7126176357269287, 'learning_rate': 4.1003544482012777e-07, 'epoch': 1.74}
{'loss': 1.1517, 'grad_norm': 2.719367265701294, 'learning_rate': 4.072121538589164e-07, 'epoch': 1.74}
{'loss': 1.2755, 'grad_norm': 3.176758289337158, 'learning_rate': 4.043919235570347e-07, 'epoch': 1.75}
{'loss': 1.1039, 'grad_norm': 4.180492401123047, 'learning_rate': 4.015748469413664e-07, 'epoch': 1.75}
{'loss': 1.1382, 'grad_norm': 3.578453540802002, 'learning_rate': 3.9876101693476945e-07, 'epoch': 1.76}
{'loss': 1.4674, 'grad_norm': 3.4075891971588135, 'learning_rate': 3.9595052635301e-07, 'epoch': 1.76}
{'loss': 1.0413, 'grad_norm': 3.471217155456543, 'learning_rate': 3.931434679017019e-07, 'epoch': 1.77}
{'loss': 1.2054, 'grad_norm': 3.051685094833374, 'learning_rate': 3.903399341732482e-07, 'epoch': 1.77}
{'loss': 1.1022, 'grad_norm': 3.3950111865997314, 'learning_rate': 3.8754001764378665e-07, 'epoch': 1.78}
{'loss': 1.2505, 'grad_norm': 3.6220881938934326, 'learning_rate': 3.8474381067014e-07, 'epoch': 1.78}
{'loss': 0.9796, 'grad_norm': 3.0169777870178223, 'learning_rate': 3.81951405486769e-07, 'epoch': 1.79}
{'loss': 1.2216, 'grad_norm': 3.8743302822113037, 'learning_rate': 3.7916289420273064e-07, 'epoch': 1.79}
{'loss': 1.2477, 'grad_norm': 13.928035736083984, 'learning_rate': 3.7637836879863856e-07, 'epoch': 1.8}
{'loss': 1.1295, 'grad_norm': 3.4829273223876953, 'learning_rate': 3.7359792112363085e-07, 'epoch': 1.8}
{'loss': 1.2653, 'grad_norm': 3.2090566158294678, 'learning_rate': 3.708216428923391e-07, 'epoch': 1.81}
{'loss': 1.2327, 'grad_norm': 2.875082492828369, 'learning_rate': 3.680496256818628e-07, 'epoch': 1.81}
{'loss': 1.2685, 'grad_norm': 3.041349172592163, 'learning_rate': 3.652819609287504e-07, 'epoch': 1.82}
{'loss': 1.2015, 'grad_norm': 4.477668762207031, 'learning_rate': 3.6251873992598126e-07, 'epoch': 1.82}
{'loss': 1.2459, 'grad_norm': 3.2461187839508057, 'learning_rate': 3.5976005381995565e-07, 'epoch': 1.83}
{'loss': 1.1087, 'grad_norm': 2.688164472579956, 'learning_rate': 3.570059936074871e-07, 'epoch': 1.83}
{'loss': 1.0805, 'grad_norm': 4.028555870056152, 'learning_rate': 3.5425665013280213e-07, 'epoch': 1.84}
{'loss': 1.0325, 'grad_norm': 2.958481788635254, 'learning_rate': 3.515121140845427e-07, 'epoch': 1.84}
{'loss': 1.1676, 'grad_norm': 3.3123650550842285, 'learning_rate': 3.487724759927747e-07, 'epoch': 1.85}
{'loss': 1.2124, 'grad_norm': 2.80454421043396, 'learning_rate': 3.4603782622600305e-07, 'epoch': 1.85}
{'loss': 1.3104, 'grad_norm': 2.872894763946533, 'learning_rate': 3.4330825498818907e-07, 'epoch': 1.86}
{'loss': 1.2103, 'grad_norm': 3.175233840942383, 'learning_rate': 3.4058385231577673e-07, 'epoch': 1.86}
{'loss': 1.1633, 'grad_norm': 3.9929237365722656, 'learning_rate': 3.3786470807472124e-07, 'epoch': 1.87}
{'loss': 1.0204, 'grad_norm': 3.710925817489624, 'learning_rate': 3.3515091195752596e-07, 'epoch': 1.88}
{'loss': 1.1945, 'grad_norm': 3.438187837600708, 'learning_rate': 3.324425534802835e-07, 'epoch': 1.88}
{'loss': 1.1049, 'grad_norm': 2.6070799827575684, 'learning_rate': 3.297397219797221e-07, 'epoch': 1.89}
{'loss': 1.5414, 'grad_norm': 3.6459178924560547, 'learning_rate': 3.2704250661026043e-07, 'epoch': 1.89}
{'loss': 1.2984, 'grad_norm': 4.1891255378723145, 'learning_rate': 3.243509963410654e-07, 'epoch': 1.9}
{'loss': 1.2337, 'grad_norm': 2.796982526779175, 'learning_rate': 3.2166527995311834e-07, 'epoch': 1.9}
{'loss': 1.1236, 'grad_norm': 4.83262825012207, 'learning_rate': 3.189854460362856e-07, 'epoch': 1.91}
{'loss': 0.9472, 'grad_norm': 4.13643217086792, 'learning_rate': 3.163115829863975e-07, 'epoch': 1.91}
{'loss': 1.1356, 'grad_norm': 2.5454087257385254, 'learning_rate': 3.136437790023316e-07, 'epoch': 1.92}
{'loss': 1.117, 'grad_norm': 2.962794542312622, 'learning_rate': 3.109821220831038e-07, 'epoch': 1.92}
{'loss': 1.1693, 'grad_norm': 2.8253896236419678, 'learning_rate': 3.083267000249658e-07, 'epoch': 1.93}
{'loss': 1.1413, 'grad_norm': 2.7733469009399414, 'learning_rate': 3.0567760041850855e-07, 'epoch': 1.93}
{'loss': 1.0374, 'grad_norm': 3.0308303833007812, 'learning_rate': 3.0303491064577395e-07, 'epoch': 1.94}
{'loss': 1.0104, 'grad_norm': 3.088822364807129, 'learning_rate': 3.0039871787737115e-07, 'epoch': 1.94}
{'loss': 1.1352, 'grad_norm': 3.626882314682007, 'learning_rate': 2.9776910906960265e-07, 'epoch': 1.95}
{'loss': 1.1711, 'grad_norm': 3.0595510005950928, 'learning_rate': 2.951461709615951e-07, 'epoch': 1.95}
{'loss': 1.2468, 'grad_norm': 4.282385349273682, 'learning_rate': 2.9252999007243784e-07, 'epoch': 1.96}
{'loss': 1.0445, 'grad_norm': 3.3042826652526855, 'learning_rate': 2.899206526983303e-07, 'epoch': 1.96}
{'loss': 1.2187, 'grad_norm': 21.80013084411621, 'learning_rate': 2.8731824490973445e-07, 'epoch': 1.97}
{'loss': 1.0136, 'grad_norm': 3.727703809738159, 'learning_rate': 2.847228525485359e-07, 'epoch': 1.97}
{'loss': 1.2178, 'grad_norm': 3.3277018070220947, 'learning_rate': 2.821345612252121e-07, 'epoch': 1.98}
{'loss': 1.2313, 'grad_norm': 3.105801820755005, 'learning_rate': 2.795534563160099e-07, 'epoch': 1.98}
{'loss': 1.341, 'grad_norm': 9.490927696228027, 'learning_rate': 2.7697962296012687e-07, 'epoch': 1.99}
{'loss': 1.0478, 'grad_norm': 3.546011447906494, 'learning_rate': 2.7441314605690485e-07, 'epoch': 1.99}
{'loss': 1.1206, 'grad_norm': 2.8870174884796143, 'learning_rate': 2.7185411026302964e-07, 'epoch': 2.0}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-385/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-385/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-385/model.safetensors.index.json.
2024-12-31 02:16:53,619 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-385/pytorch_model_fsdp.bin
2024-12-31 02:17:43,878 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-385/pytorch_model_fsdp.bin
2024-12-31 02:18:14,734 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-385/optimizer.bin
2024-12-31 02:19:39,152 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-385/optimizer.bin
                                                                                                                                                                                               
{'loss': 1.2404, 'grad_norm': 2.6457340717315674, 'learning_rate': 2.693025999897364e-07, 'epoch': 2.01}
{'loss': 1.2595, 'grad_norm': 3.512716293334961, 'learning_rate': 2.667586994000283e-07, 'epoch': 2.01}
{'loss': 1.2553, 'grad_norm': 3.3881781101226807, 'learning_rate': 2.6422249240589767e-07, 'epoch': 2.02}
{'loss': 1.3338, 'grad_norm': 5.081942081451416, 'learning_rate': 2.616940626655598e-07, 'epoch': 2.02}
{'loss': 1.0177, 'grad_norm': 2.8641819953918457, 'learning_rate': 2.591734935806929e-07, 'epoch': 2.03}
{'loss': 1.2878, 'grad_norm': 3.4861247539520264, 'learning_rate': 2.5666086829368675e-07, 'epoch': 2.03}
{'loss': 1.0544, 'grad_norm': 3.326352596282959, 'learning_rate': 2.5415626968490074e-07, 'epoch': 2.04}
{'loss': 1.2283, 'grad_norm': 4.459047317504883, 'learning_rate': 2.516597803699294e-07, 'epoch': 2.04}
{'loss': 1.1022, 'grad_norm': 8.84162425994873, 'learning_rate': 2.491714826968785e-07, 'epoch': 2.05}
{'loss': 1.0469, 'grad_norm': 5.283607006072998, 'learning_rate': 2.4669145874364653e-07, 'epoch': 2.05}
{'loss': 1.2168, 'grad_norm': 3.282137870788574, 'learning_rate': 2.4421979031522006e-07, 'epoch': 2.06}
{'loss': 1.2733, 'grad_norm': 2.7086215019226074, 'learning_rate': 2.417565589409733e-07, 'epoch': 2.06}
{'loss': 1.0658, 'grad_norm': 2.8392152786254883, 'learning_rate': 2.3930184587197897e-07, 'epoch': 2.07}
{'loss': 1.2457, 'grad_norm': 3.860095739364624, 'learning_rate': 2.3685573207832987e-07, 'epoch': 2.07}
{'loss': 1.191, 'grad_norm': 4.9740166664123535, 'learning_rate': 2.3441829824646602e-07, 'epoch': 2.08}
{'loss': 1.1295, 'grad_norm': 3.0019524097442627, 'learning_rate': 2.319896247765143e-07, 'epoch': 2.08}
{'loss': 1.0719, 'grad_norm': 10.150921821594238, 'learning_rate': 2.2956979177963598e-07, 'epoch': 2.09}
{'loss': 1.3627, 'grad_norm': 3.5794503688812256, 'learning_rate': 2.271588790753845e-07, 'epoch': 2.09}
{'loss': 1.1331, 'grad_norm': 3.313441753387451, 'learning_rate': 2.2475696618907235e-07, 'epoch': 2.1}
{'loss': 1.1191, 'grad_norm': 4.2167229652404785, 'learning_rate': 2.2236413234914803e-07, 'epoch': 2.1}
{'loss': 1.1469, 'grad_norm': 2.8976337909698486, 'learning_rate': 2.1998045648458242e-07, 'epoch': 2.11}
{'loss': 1.0157, 'grad_norm': 4.148167610168457, 'learning_rate': 2.176060172222654e-07, 'epoch': 2.11}
{'loss': 1.1698, 'grad_norm': 17.803739547729492, 'learning_rate': 2.1524089288441311e-07, 'epoch': 2.12}
{'loss': 1.1984, 'grad_norm': 17.566041946411133, 'learning_rate': 2.1288516148598213e-07, 'epoch': 2.12}
{'loss': 1.0372, 'grad_norm': 5.691754341125488, 'learning_rate': 2.105389007320992e-07, 'epoch': 2.13}
{'loss': 1.1603, 'grad_norm': 2.695467710494995, 'learning_rate': 2.0820218801549577e-07, 'epoch': 2.14}
{'loss': 1.1501, 'grad_norm': 2.566086530685425, 'learning_rate': 2.058751004139555e-07, 'epoch': 2.14}
{'loss': 1.0363, 'grad_norm': 4.842531681060791, 'learning_rate': 2.0355771468777323e-07, 'epoch': 2.15}
{'loss': 1.2764, 'grad_norm': 3.1228182315826416, 'learning_rate': 2.012501072772213e-07, 'epoch': 2.15}
{'loss': 1.1968, 'grad_norm': 3.1718976497650146, 'learning_rate': 1.9895235430002892e-07, 'epoch': 2.16}
{'loss': 1.123, 'grad_norm': 3.291858434677124, 'learning_rate': 1.966645315488713e-07, 'epoch': 2.16}
{'loss': 1.1839, 'grad_norm': 2.8029708862304688, 'learning_rate': 1.9438671448886962e-07, 'epoch': 2.17}
{'loss': 1.0501, 'grad_norm': 3.265744924545288, 'learning_rate': 1.921189782551016e-07, 'epoch': 2.17}
{'loss': 1.1563, 'grad_norm': 2.8633148670196533, 'learning_rate': 1.8986139765012327e-07, 'epoch': 2.18}
{'loss': 1.1561, 'grad_norm': 3.111283302307129, 'learning_rate': 1.8761404714150158e-07, 'epoch': 2.18}
{'loss': 1.1169, 'grad_norm': 2.9271583557128906, 'learning_rate': 1.853770008593578e-07, 'epoch': 2.19}
{'loss': 1.1127, 'grad_norm': 2.765937328338623, 'learning_rate': 1.831503325939231e-07, 'epoch': 2.19}
{'loss': 1.0846, 'grad_norm': 3.4836792945861816, 'learning_rate': 1.809341157931028e-07, 'epoch': 2.2}
{'loss': 1.3978, 'grad_norm': 27.122356414794922, 'learning_rate': 1.7872842356005597e-07, 'epoch': 2.2}
{'loss': 1.1962, 'grad_norm': 3.4883012771606445, 'learning_rate': 1.765333286507824e-07, 'epoch': 2.21}
{'loss': 1.1366, 'grad_norm': 3.3086535930633545, 'learning_rate': 1.743489034717226e-07, 'epoch': 2.21}
{'loss': 1.3105, 'grad_norm': 4.388548851013184, 'learning_rate': 1.7217522007737106e-07, 'epoch': 2.22}
{'loss': 1.1376, 'grad_norm': 3.0816197395324707, 'learning_rate': 1.700123501678979e-07, 'epoch': 2.22}
{'loss': 1.049, 'grad_norm': 2.6399877071380615, 'learning_rate': 1.6786036508678437e-07, 'epoch': 2.23}
{'loss': 1.1643, 'grad_norm': 9.303037643432617, 'learning_rate': 1.6571933581846965e-07, 'epoch': 2.23}
{'loss': 1.21, 'grad_norm': 2.976074457168579, 'learning_rate': 1.6358933298600907e-07, 'epoch': 2.24}
{'loss': 1.4062, 'grad_norm': 3.0174367427825928, 'learning_rate': 1.6147042684874508e-07, 'epoch': 2.24}
{'loss': 1.0849, 'grad_norm': 3.5375185012817383, 'learning_rate': 1.5936268729998913e-07, 'epoch': 2.25}
{'loss': 1.1846, 'grad_norm': 2.5635316371917725, 'learning_rate': 1.5726618386471656e-07, 'epoch': 2.25}
{'loss': 1.2518, 'grad_norm': 3.9033446311950684, 'learning_rate': 1.55180985697273e-07, 'epoch': 2.26}
{'loss': 1.2419, 'grad_norm': 2.796461343765259, 'learning_rate': 1.531071615790942e-07, 'epoch': 2.26}
{'loss': 1.2965, 'grad_norm': 7.562941551208496, 'learning_rate': 1.5104477991643515e-07, 'epoch': 2.27}
{'loss': 1.2603, 'grad_norm': 3.4670228958129883, 'learning_rate': 1.489939087381164e-07, 'epoch': 2.28}
{'loss': 1.2226, 'grad_norm': 2.7478652000427246, 'learning_rate': 1.46954615693278e-07, 'epoch': 2.28}
{'loss': 1.3511, 'grad_norm': 8.900359153747559, 'learning_rate': 1.449269680491484e-07, 'epoch': 2.29}
{'loss': 1.2065, 'grad_norm': 3.037588119506836, 'learning_rate': 1.4291103268882677e-07, 'epoch': 2.29}
{'loss': 1.0734, 'grad_norm': 3.0249640941619873, 'learning_rate': 1.4090687610907548e-07, 'epoch': 2.3}
{'loss': 1.1262, 'grad_norm': 4.667529582977295, 'learning_rate': 1.3891456441812744e-07, 'epoch': 2.3}
{'loss': 1.2512, 'grad_norm': 2.781691551208496, 'learning_rate': 1.36934163333505e-07, 'epoch': 2.31}
{'loss': 1.0895, 'grad_norm': 3.2666752338409424, 'learning_rate': 1.3496573817985262e-07, 'epoch': 2.31}
{'loss': 1.275, 'grad_norm': 3.0798544883728027, 'learning_rate': 1.3300935388678196e-07, 'epoch': 2.32}
{'loss': 1.3052, 'grad_norm': 3.086085796356201, 'learning_rate': 1.3106507498672998e-07, 'epoch': 2.32}
{'loss': 1.1646, 'grad_norm': 3.7268967628479004, 'learning_rate': 1.2913296561283054e-07, 'epoch': 2.33}
{'loss': 1.2648, 'grad_norm': 3.3620800971984863, 'learning_rate': 1.2721308949679866e-07, 'epoch': 2.33}
{'loss': 1.174, 'grad_norm': 3.101649761199951, 'learning_rate': 1.2530550996682904e-07, 'epoch': 2.34}
{'loss': 1.1347, 'grad_norm': 5.019866943359375, 'learning_rate': 1.2341028994550556e-07, 'epoch': 2.34}
{'loss': 1.262, 'grad_norm': 5.451139450073242, 'learning_rate': 1.2152749194772783e-07, 'epoch': 2.35}
{'loss': 1.2046, 'grad_norm': 2.5867223739624023, 'learning_rate': 1.196571780786474e-07, 'epoch': 2.35}
{'loss': 1.1461, 'grad_norm': 17.92555046081543, 'learning_rate': 1.1779941003161953e-07, 'epoch': 2.36}
{'loss': 1.1505, 'grad_norm': 2.79825758934021, 'learning_rate': 1.159542490861693e-07, 'epoch': 2.36}
{'loss': 1.2602, 'grad_norm': 5.9046220779418945, 'learning_rate': 1.1412175610596897e-07, 'epoch': 2.37}
{'loss': 1.1806, 'grad_norm': 3.0943546295166016, 'learning_rate': 1.1230199153683078e-07, 'epoch': 2.37}
{'loss': 1.1396, 'grad_norm': 3.7046170234680176, 'learning_rate': 1.1049501540471323e-07, 'epoch': 2.38}
{'loss': 1.1394, 'grad_norm': 3.1936843395233154, 'learning_rate': 1.0870088731374139e-07, 'epoch': 2.38}
{'loss': 1.1118, 'grad_norm': 2.7143733501434326, 'learning_rate': 1.0691966644423984e-07, 'epoch': 2.39}
{'loss': 1.1123, 'grad_norm': 6.7956671714782715, 'learning_rate': 1.0515141155078138e-07, 'epoch': 2.39}
{'loss': 1.2427, 'grad_norm': 2.613603353500366, 'learning_rate': 1.0339618096024943e-07, 'epoch': 2.4}
{'loss': 1.152, 'grad_norm': 13.54310417175293, 'learning_rate': 1.016540325699124e-07, 'epoch': 2.41}
{'loss': 1.2034, 'grad_norm': 3.1888084411621094, 'learning_rate': 9.992502384551576e-08, 'epoch': 2.41}
{'loss': 1.0864, 'grad_norm': 2.8868041038513184, 'learning_rate': 9.820921181938546e-08, 'epoch': 2.42}
{'loss': 1.0703, 'grad_norm': 2.9375340938568115, 'learning_rate': 9.650665308854678e-08, 'epoch': 2.42}
{'loss': 0.9842, 'grad_norm': 3.0927600860595703, 'learning_rate': 9.48174038128578e-08, 'epoch': 2.43}
{'loss': 1.102, 'grad_norm': 2.965876817703247, 'learning_rate': 9.314151971315664e-08, 'epoch': 2.43}
{'loss': 1.3108, 'grad_norm': 2.8575024604797363, 'learning_rate': 9.147905606942363e-08, 'epoch': 2.44}
{'loss': 1.1905, 'grad_norm': 2.973698377609253, 'learning_rate': 8.983006771895763e-08, 'epoch': 2.44}
{'loss': 1.159, 'grad_norm': 2.8021748065948486, 'learning_rate': 8.81946090545676e-08, 'epoch': 2.45}
{'loss': 1.127, 'grad_norm': 3.0171637535095215, 'learning_rate': 8.657273402277798e-08, 'epoch': 2.45}
{'loss': 1.1751, 'grad_norm': 2.642024517059326, 'learning_rate': 8.496449612204982e-08, 'epoch': 2.46}
{'loss': 1.1002, 'grad_norm': 30.92097282409668, 'learning_rate': 8.336994840101513e-08, 'epoch': 2.46}
{'loss': 1.0981, 'grad_norm': 2.655081033706665, 'learning_rate': 8.1789143456728e-08, 'epoch': 2.47}
{'loss': 1.1065, 'grad_norm': 2.7267682552337646, 'learning_rate': 8.022213343292955e-08, 'epoch': 2.47}
{'loss': 1.2922, 'grad_norm': 3.592244863510132, 'learning_rate': 7.866897001832695e-08, 'epoch': 2.48}
{'loss': 1.1161, 'grad_norm': 2.8993008136749268, 'learning_rate': 7.712970444489003e-08, 'epoch': 2.48}
{'loss': 1.1818, 'grad_norm': 3.2741048336029053, 'learning_rate': 7.560438748615982e-08, 'epoch': 2.49}
{'loss': 1.1552, 'grad_norm': 3.5932769775390625, 'learning_rate': 7.409306945557487e-08, 'epoch': 2.49}
{'loss': 1.0825, 'grad_norm': 2.7744805812835693, 'learning_rate': 7.259580020481092e-08, 'epoch': 2.5}
{'loss': 1.2207, 'grad_norm': 3.2161107063293457, 'learning_rate': 7.111262912213706e-08, 'epoch': 2.5}
{'loss': 1.1443, 'grad_norm': 3.6123175621032715, 'learning_rate': 6.96436051307861e-08, 'epoch': 2.51}
{'loss': 1.1359, 'grad_norm': 3.1801774501800537, 'learning_rate': 6.81887766873413e-08, 'epoch': 2.51}
{'loss': 1.2611, 'grad_norm': 3.0491533279418945, 'learning_rate': 6.674819178013769e-08, 'epoch': 2.52}
{'loss': 1.1987, 'grad_norm': 3.2249228954315186, 'learning_rate': 6.532189792767922e-08, 'epoch': 2.52}
{'loss': 1.0916, 'grad_norm': 2.889482021331787, 'learning_rate': 6.390994217707141e-08, 'epoch': 2.53}
{'loss': 1.0697, 'grad_norm': 2.933595657348633, 'learning_rate': 6.251237110246943e-08, 'epoch': 2.54}
{'loss': 0.9636, 'grad_norm': 2.5256261825561523, 'learning_rate': 6.112923080354165e-08, 'epoch': 2.54}
{'loss': 1.3176, 'grad_norm': 5.272372722625732, 'learning_rate': 5.976056690394959e-08, 'epoch': 2.55}
{'loss': 1.3327, 'grad_norm': 3.3025143146514893, 'learning_rate': 5.840642454984196e-08, 'epoch': 2.55}
{'loss': 1.2649, 'grad_norm': 3.111809492111206, 'learning_rate': 5.706684840836673e-08, 'epoch': 2.56}
{'loss': 0.97, 'grad_norm': 5.664177894592285, 'learning_rate': 5.574188266619695e-08, 'epoch': 2.56}
{'loss': 1.261, 'grad_norm': 3.274106740951538, 'learning_rate': 5.4431571028073054e-08, 'epoch': 2.57}
{'loss': 1.1188, 'grad_norm': 3.6535956859588623, 'learning_rate': 5.31359567153622e-08, 'epoch': 2.57}
{'loss': 1.2345, 'grad_norm': 2.961348533630371, 'learning_rate': 5.185508246463161e-08, 'epoch': 2.58}
{'loss': 1.0854, 'grad_norm': 2.9189043045043945, 'learning_rate': 5.058899052623933e-08, 'epoch': 2.58}
{'loss': 1.3631, 'grad_norm': 2.780534267425537, 'learning_rate': 4.933772266294067e-08, 'epoch': 2.59}
{'loss': 1.1556, 'grad_norm': 2.6337811946868896, 'learning_rate': 4.810132014851026e-08, 'epoch': 2.59}
{'loss': 1.2609, 'grad_norm': 2.8744025230407715, 'learning_rate': 4.6879823766381e-08, 'epoch': 2.6}
{'loss': 1.1669, 'grad_norm': 3.0511929988861084, 'learning_rate': 4.5673273808298494e-08, 'epoch': 2.6}
{'loss': 1.0976, 'grad_norm': 2.5955545902252197, 'learning_rate': 4.4481710072992284e-08, 'epoch': 2.61}
{'loss': 1.227, 'grad_norm': 3.5715835094451904, 'learning_rate': 4.3305171864862655e-08, 'epoch': 2.61}
{'loss': 1.2028, 'grad_norm': 3.401841878890991, 'learning_rate': 4.214369799268497e-08, 'epoch': 2.62}
{'loss': 1.1128, 'grad_norm': 3.186689615249634, 'learning_rate': 4.099732676832818e-08, 'epoch': 2.62}
{'loss': 1.2259, 'grad_norm': 3.156135082244873, 'learning_rate': 3.9866096005492676e-08, 'epoch': 2.63}
{'loss': 1.0759, 'grad_norm': 3.597527265548706, 'learning_rate': 3.8750043018461854e-08, 'epoch': 2.63}
{'loss': 1.0695, 'grad_norm': 2.60453724861145, 'learning_rate': 3.7649204620871346e-08, 'epoch': 2.64}
{'loss': 1.1341, 'grad_norm': 3.0016210079193115, 'learning_rate': 3.656361712449557e-08, 'epoch': 2.64}
{'loss': 1.1944, 'grad_norm': 2.834320545196533, 'learning_rate': 3.549331633804908e-08, 'epoch': 2.65}
{'loss': 1.0873, 'grad_norm': 3.0037102699279785, 'learning_rate': 3.443833756600567e-08, 'epoch': 2.65}
{'loss': 1.1874, 'grad_norm': 2.8353981971740723, 'learning_rate': 3.3398715607433795e-08, 'epoch': 2.66}
{'loss': 1.1735, 'grad_norm': 2.568852186203003, 'learning_rate': 3.237448475484922e-08, 'epoch': 2.66}
{'loss': 1.0456, 'grad_norm': 4.2084455490112305, 'learning_rate': 3.1365678793082826e-08, 'epoch': 2.67}
{'loss': 1.1507, 'grad_norm': 3.358391284942627, 'learning_rate': 3.037233099816705e-08, 'epoch': 2.68}
{'loss': 1.2564, 'grad_norm': 3.139129400253296, 'learning_rate': 2.9394474136238246e-08, 'epoch': 2.68}
{'loss': 1.1114, 'grad_norm': 2.879805564880371, 'learning_rate': 2.843214046245507e-08, 'epoch': 2.69}
{'loss': 1.1036, 'grad_norm': 3.4398484230041504, 'learning_rate': 2.748536171993565e-08, 'epoch': 2.69}
{'loss': 1.0831, 'grad_norm': 3.0722310543060303, 'learning_rate': 2.6554169138709558e-08, 'epoch': 2.7}
{'loss': 1.1897, 'grad_norm': 3.4069931507110596, 'learning_rate': 2.5638593434688218e-08, 'epoch': 2.7}
{'loss': 1.0722, 'grad_norm': 2.638967275619507, 'learning_rate': 2.4738664808651498e-08, 'epoch': 2.71}
{'loss': 1.0846, 'grad_norm': 3.8348190784454346, 'learning_rate': 2.3854412945251756e-08, 'epoch': 2.71}
{'loss': 1.0874, 'grad_norm': 3.2238008975982666, 'learning_rate': 2.2985867012034365e-08, 'epoch': 2.72}
{'loss': 1.2009, 'grad_norm': 2.585268974304199, 'learning_rate': 2.213305565847573e-08, 'epoch': 2.72}
{'loss': 1.2041, 'grad_norm': 12.345589637756348, 'learning_rate': 2.1296007015038365e-08, 'epoch': 2.73}
{'loss': 1.1581, 'grad_norm': 4.489198684692383, 'learning_rate': 2.047474869224286e-08, 'epoch': 2.73}
{'loss': 1.2185, 'grad_norm': 3.2524194717407227, 'learning_rate': 1.966930777975734e-08, 'epoch': 2.74}
{'loss': 1.1007, 'grad_norm': 3.049621105194092, 'learning_rate': 1.8879710845503604e-08, 'epoch': 2.74}
{'loss': 1.1168, 'grad_norm': 2.9767322540283203, 'learning_rate': 1.81059839347808e-08, 'epoch': 2.75}
{'loss': 1.1044, 'grad_norm': 3.2717647552490234, 'learning_rate': 1.7348152569406748e-08, 'epoch': 2.75}
{'loss': 1.2569, 'grad_norm': 2.8795790672302246, 'learning_rate': 1.660624174687547e-08, 'epoch': 2.76}
{'loss': 1.1724, 'grad_norm': 3.044161319732666, 'learning_rate': 1.588027593953306e-08, 'epoch': 2.76}
{'loss': 1.2103, 'grad_norm': 4.169084072113037, 'learning_rate': 1.517027909377028e-08, 'epoch': 2.77}
{'loss': 1.2517, 'grad_norm': 4.803475856781006, 'learning_rate': 1.4476274629232677e-08, 'epoch': 2.77}
{'loss': 1.1362, 'grad_norm': 2.5705578327178955, 'learning_rate': 1.3798285438048118e-08, 'epoch': 2.78}
{'loss': 1.1212, 'grad_norm': 2.627016544342041, 'learning_rate': 1.3136333884071704e-08, 'epoch': 2.78}
{'loss': 1.0591, 'grad_norm': 2.925370931625366, 'learning_rate': 1.2490441802148032e-08, 'epoch': 2.79}
{'loss': 1.1245, 'grad_norm': 2.8145570755004883, 'learning_rate': 1.186063049739089e-08, 'epoch': 2.79}
{'loss': 1.1572, 'grad_norm': 2.9550206661224365, 'learning_rate': 1.1246920744480692e-08, 'epoch': 2.8}
{'loss': 1.1258, 'grad_norm': 2.4723007678985596, 'learning_rate': 1.0649332786979049e-08, 'epoch': 2.81}
{'loss': 1.3437, 'grad_norm': 2.831012487411499, 'learning_rate': 1.0067886336661113e-08, 'epoch': 2.81}
{'loss': 1.0763, 'grad_norm': 9.09462833404541, 'learning_rate': 9.502600572865282e-09, 'epoch': 2.82}
{'loss': 1.1922, 'grad_norm': 2.710399627685547, 'learning_rate': 8.953494141860584e-09, 'epoch': 2.82}
{'loss': 1.2408, 'grad_norm': 3.1338417530059814, 'learning_rate': 8.42058515623184e-09, 'epoch': 2.83}
{'loss': 1.1208, 'grad_norm': 2.849245309829712, 'learning_rate': 7.903891194281753e-09, 'epoch': 2.83}
{'loss': 0.9769, 'grad_norm': 7.750435829162598, 'learning_rate': 7.403429299451536e-09, 'epoch': 2.84}
{'loss': 1.2969, 'grad_norm': 3.2049925327301025, 'learning_rate': 6.919215979758475e-09, 'epoch': 2.84}
{'loss': 1.3006, 'grad_norm': 3.172333240509033, 'learning_rate': 6.451267207251421e-09, 'epoch': 2.85}
{'loss': 1.146, 'grad_norm': 3.5769741535186768, 'learning_rate': 5.999598417484042e-09, 'epoch': 2.85}
{'loss': 1.1965, 'grad_norm': 3.0317845344543457, 'learning_rate': 5.5642245090055664e-09, 'epoch': 2.86}
{'loss': 1.2234, 'grad_norm': 2.7923758029937744, 'learning_rate': 5.145159842869396e-09, 'epoch': 2.86}
{'loss': 1.0663, 'grad_norm': 2.715651512145996, 'learning_rate': 4.742418242159485e-09, 'epoch': 2.87}
{'loss': 1.1636, 'grad_norm': 7.128810405731201, 'learning_rate': 4.356012991534097e-09, 'epoch': 2.87}
{'loss': 1.1625, 'grad_norm': 2.855064630508423, 'learning_rate': 3.985956836787985e-09, 'epoch': 2.88}
{'loss': 1.0441, 'grad_norm': 6.771430969238281, 'learning_rate': 3.6322619844317282e-09, 'epoch': 2.88}
{'loss': 1.1492, 'grad_norm': 2.795178174972534, 'learning_rate': 3.294940101289001e-09, 'epoch': 2.89}
{'loss': 1.1135, 'grad_norm': 2.8987252712249756, 'learning_rate': 2.974002314112045e-09, 'epoch': 2.89}
{'loss': 1.2102, 'grad_norm': 2.9355268478393555, 'learning_rate': 2.6694592092144642e-09, 'epoch': 2.9}
{'loss': 1.1731, 'grad_norm': 4.4190192222595215, 'learning_rate': 2.3813208321218357e-09, 'epoch': 2.9}
{'loss': 1.2655, 'grad_norm': 3.0224199295043945, 'learning_rate': 2.1095966872407556e-09, 'epoch': 2.91}
{'loss': 1.0855, 'grad_norm': 3.354072332382202, 'learning_rate': 1.8542957375451417e-09, 'epoch': 2.91}
{'loss': 1.0159, 'grad_norm': 3.244537115097046, 'learning_rate': 1.6154264042805287e-09, 'epoch': 2.92}
{'loss': 1.1102, 'grad_norm': 2.8043994903564453, 'learning_rate': 1.3929965666861776e-09, 'epoch': 2.92}
{'loss': 1.2205, 'grad_norm': 7.899053573608398, 'learning_rate': 1.187013561735617e-09, 'epoch': 2.93}
{'loss': 1.261, 'grad_norm': 3.2926254272460938, 'learning_rate': 9.97484183894115e-10, 'epoch': 2.94}
{'loss': 1.2197, 'grad_norm': 2.6242642402648926, 'learning_rate': 8.244146848949141e-10, 'epoch': 2.94}
{'loss': 1.0614, 'grad_norm': 3.2847862243652344, 'learning_rate': 6.678107735328398e-10, 'epoch': 2.95}
{'loss': 1.1627, 'grad_norm': 2.752082586288452, 'learning_rate': 5.276776154760631e-10, 'epoch': 2.95}
{'loss': 1.1475, 'grad_norm': 2.6468183994293213, 'learning_rate': 4.0401983309568124e-10, 'epoch': 2.96}
{'loss': 1.1915, 'grad_norm': 2.9510574340820312, 'learning_rate': 2.968415053131723e-10, 'epoch': 2.96}
{'loss': 1.3011, 'grad_norm': 3.6343836784362793, 'learning_rate': 2.061461674661147e-10, 'epoch': 2.97}
{'loss': 0.9876, 'grad_norm': 5.91949987411499, 'learning_rate': 1.3193681119116895e-10, 'epoch': 2.97}
{'loss': 1.1824, 'grad_norm': 3.5075581073760986, 'learning_rate': 7.421588432576786e-11, 'epoch': 2.98}
{'loss': 1.1464, 'grad_norm': 3.2052488327026367, 'learning_rate': 3.298529082718105e-11, 'epoch': 2.98}
{'loss': 1.1619, 'grad_norm': 2.755441427230835, 'learning_rate': 8.246390709787388e-12, 'epoch': 2.99}
{'loss': 1.1966, 'grad_norm': 3.8929457664489746, 'learning_rate': 0.0, 'epoch': 2.99}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-576/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-576/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-576/model.safetensors.index.json.
2024-12-31 02:29:08,138 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-576/pytorch_model_fsdp.bin
2024-12-31 02:29:55,435 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-576/pytorch_model_fsdp.bin
2024-12-31 02:30:25,846 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-576/optimizer.bin
2024-12-31 02:31:45,170 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-576/optimizer.bin
Saving model checkpoint to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-576
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-576/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-576/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-576/model.safetensors.index.json.
2024-12-31 02:33:43,587 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-576/pytorch_model_fsdp.bin
2024-12-31 02:34:32,189 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-576/pytorch_model_fsdp.bin
2024-12-31 02:35:00,980 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-576/optimizer.bin
2024-12-31 02:36:30,175 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/checkpoint-576/optimizer.bin


Training completed. Do not forget to share your model on huggingface.co/models =)


100%|| 576/576 [40:48<00:00,  4.25s/it]
{'train_runtime': 2453.9646, 'train_samples_per_second': 1.883, 'train_steps_per_second': 0.235, 'train_loss': 1.2373678718383114, 'epoch': 2.99}
Saving model checkpoint to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt1rr0.1epochs5bs16wd0.01warmup0.05Llama3.18B_checkpoint1228/model.safetensors.index.json.
