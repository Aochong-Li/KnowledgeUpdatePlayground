                                                                                                                                                                                               
{'loss': 1.6901, 'grad_norm': 60.6494255065918, 'learning_rate': 3.448275862068965e-08, 'epoch': 0.01}
{'loss': 1.7851, 'grad_norm': 266.55999755859375, 'learning_rate': 6.89655172413793e-08, 'epoch': 0.01}
{'loss': 1.7813, 'grad_norm': 121680.046875, 'learning_rate': 1.0344827586206897e-07, 'epoch': 0.02}
{'loss': 1.5511, 'grad_norm': 52.21110916137695, 'learning_rate': 1.379310344827586e-07, 'epoch': 0.02}
{'loss': 1.6235, 'grad_norm': 50.899532318115234, 'learning_rate': 1.7241379310344828e-07, 'epoch': 0.03}
{'loss': 1.5522, 'grad_norm': 66.33465576171875, 'learning_rate': 2.0689655172413793e-07, 'epoch': 0.03}
{'loss': 1.6681, 'grad_norm': 194.95077514648438, 'learning_rate': 2.413793103448276e-07, 'epoch': 0.04}
{'loss': 1.4611, 'grad_norm': 14.457420349121094, 'learning_rate': 2.758620689655172e-07, 'epoch': 0.04}
{'loss': 1.4506, 'grad_norm': 44.432212829589844, 'learning_rate': 3.103448275862069e-07, 'epoch': 0.05}
{'loss': 1.7577, 'grad_norm': 100.57831573486328, 'learning_rate': 3.4482758620689656e-07, 'epoch': 0.05}
{'loss': 1.5468, 'grad_norm': 6686.1318359375, 'learning_rate': 3.793103448275862e-07, 'epoch': 0.06}
{'loss': 1.7543, 'grad_norm': 11.907800674438477, 'learning_rate': 4.1379310344827586e-07, 'epoch': 0.06}
{'loss': 1.7923, 'grad_norm': 87.53414154052734, 'learning_rate': 4.482758620689655e-07, 'epoch': 0.07}
{'loss': 1.8276, 'grad_norm': 72.32469177246094, 'learning_rate': 4.827586206896552e-07, 'epoch': 0.07}
{'loss': 1.3532, 'grad_norm': 11.136855125427246, 'learning_rate': 5.172413793103448e-07, 'epoch': 0.08}
{'loss': 1.544, 'grad_norm': 7.256572723388672, 'learning_rate': 5.517241379310344e-07, 'epoch': 0.08}
{'loss': 1.6856, 'grad_norm': 57.20630645751953, 'learning_rate': 5.86206896551724e-07, 'epoch': 0.09}
{'loss': 1.4771, 'grad_norm': 25.126937866210938, 'learning_rate': 6.206896551724138e-07, 'epoch': 0.09}
{'loss': 1.3499, 'grad_norm': 5.906829357147217, 'learning_rate': 6.551724137931034e-07, 'epoch': 0.1}
{'loss': 1.7171, 'grad_norm': 19.15669822692871, 'learning_rate': 6.896551724137931e-07, 'epoch': 0.1}
{'loss': 1.2946, 'grad_norm': 2347.26025390625, 'learning_rate': 7.241379310344827e-07, 'epoch': 0.11}
{'loss': 1.634, 'grad_norm': 8.025211334228516, 'learning_rate': 7.586206896551724e-07, 'epoch': 0.11}
{'loss': 1.5366, 'grad_norm': 9.685320854187012, 'learning_rate': 7.931034482758621e-07, 'epoch': 0.12}
{'loss': 1.403, 'grad_norm': 14.390872955322266, 'learning_rate': 8.275862068965517e-07, 'epoch': 0.12}
{'loss': 1.59, 'grad_norm': 14.475123405456543, 'learning_rate': 8.620689655172412e-07, 'epoch': 0.13}
{'loss': 1.762, 'grad_norm': 203.22694396972656, 'learning_rate': 8.96551724137931e-07, 'epoch': 0.14}
{'loss': 1.3693, 'grad_norm': 97.5871810913086, 'learning_rate': 9.310344827586206e-07, 'epoch': 0.14}
{'loss': 1.6008, 'grad_norm': 6.395929336547852, 'learning_rate': 9.655172413793103e-07, 'epoch': 0.15}
{'loss': 1.3447, 'grad_norm': 12.377436637878418, 'learning_rate': 1e-06, 'epoch': 0.15}
{'loss': 1.285, 'grad_norm': 10.467890739440918, 'learning_rate': 9.9999175360929e-07, 'epoch': 0.16}
{'loss': 1.4402, 'grad_norm': 6.747407913208008, 'learning_rate': 9.999670147091728e-07, 'epoch': 0.16}
{'loss': 1.3445, 'grad_norm': 10.409477233886719, 'learning_rate': 9.99925784115674e-07, 'epoch': 0.17}
{'loss': 1.2927, 'grad_norm': 8.370610237121582, 'learning_rate': 9.998680631888088e-07, 'epoch': 0.17}
{'loss': 1.3849, 'grad_norm': 13.551515579223633, 'learning_rate': 9.997938538325338e-07, 'epoch': 0.18}
{'loss': 1.5412, 'grad_norm': 3.9021003246307373, 'learning_rate': 9.997031584946869e-07, 'epoch': 0.18}
{'loss': 1.7097, 'grad_norm': 8.077909469604492, 'learning_rate': 9.995959801669042e-07, 'epoch': 0.19}
{'loss': 1.2674, 'grad_norm': 5.615176677703857, 'learning_rate': 9.994723223845238e-07, 'epoch': 0.19}
{'loss': 1.4225, 'grad_norm': 10.693926811218262, 'learning_rate': 9.99332189226467e-07, 'epoch': 0.2}
{'loss': 1.2847, 'grad_norm': 4.432792663574219, 'learning_rate': 9.99175585315105e-07, 'epoch': 0.2}
{'loss': 1.4167, 'grad_norm': 5.13775634765625, 'learning_rate': 9.990025158161059e-07, 'epoch': 0.21}
{'loss': 1.3896, 'grad_norm': 5.263730049133301, 'learning_rate': 9.988129864382643e-07, 'epoch': 0.21}
{'loss': 1.1465, 'grad_norm': 7.154160976409912, 'learning_rate': 9.986070034333138e-07, 'epoch': 0.22}
{'loss': 1.2885, 'grad_norm': 11.710482597351074, 'learning_rate': 9.983845735957194e-07, 'epoch': 0.22}
{'loss': 1.3202, 'grad_norm': 8.556007385253906, 'learning_rate': 9.981457042624549e-07, 'epoch': 0.23}
{'loss': 1.2805, 'grad_norm': 3.939019203186035, 'learning_rate': 9.978904033127591e-07, 'epoch': 0.23}
{'loss': 1.4012, 'grad_norm': 5.287179946899414, 'learning_rate': 9.976186791678782e-07, 'epoch': 0.24}
{'loss': 1.3759, 'grad_norm': 4.5815935134887695, 'learning_rate': 9.973305407907855e-07, 'epoch': 0.24}
{'loss': 1.391, 'grad_norm': 10.418145179748535, 'learning_rate': 9.97025997685888e-07, 'epoch': 0.25}
{'loss': 1.3559, 'grad_norm': 5.387401580810547, 'learning_rate': 9.96705059898711e-07, 'epoch': 0.25}
{'loss': 1.633, 'grad_norm': 6.576652526855469, 'learning_rate': 9.963677380155682e-07, 'epoch': 0.26}
{'loss': 1.1172, 'grad_norm': 3.6948068141937256, 'learning_rate': 9.960140431632121e-07, 'epoch': 0.26}
{'loss': 1.3301, 'grad_norm': 3.772124767303467, 'learning_rate': 9.95643987008466e-07, 'epoch': 0.27}
{'loss': 1.3752, 'grad_norm': 3.159181833267212, 'learning_rate': 9.952575817578406e-07, 'epoch': 0.28}
{'loss': 1.1356, 'grad_norm': 3.4024438858032227, 'learning_rate': 9.948548401571306e-07, 'epoch': 0.28}
{'loss': 1.3155, 'grad_norm': 4.088955402374268, 'learning_rate': 9.944357754909945e-07, 'epoch': 0.29}
{'loss': 1.2797, 'grad_norm': 3.7908072471618652, 'learning_rate': 9.940004015825158e-07, 'epoch': 0.29}
{'loss': 1.4419, 'grad_norm': 7.012497901916504, 'learning_rate': 9.935487327927486e-07, 'epoch': 0.3}
{'loss': 1.226, 'grad_norm': 3.0220558643341064, 'learning_rate': 9.930807840202416e-07, 'epoch': 0.3}
{'loss': 1.2734, 'grad_norm': 5.671291351318359, 'learning_rate': 9.925965707005484e-07, 'epoch': 0.31}
{'loss': 1.4026, 'grad_norm': 7.4794111251831055, 'learning_rate': 9.920961088057183e-07, 'epoch': 0.31}
{'loss': 1.0553, 'grad_norm': 4.276172161102295, 'learning_rate': 9.91579414843768e-07, 'epoch': 0.32}
{'loss': 1.2152, 'grad_norm': 61.95591735839844, 'learning_rate': 9.910465058581394e-07, 'epoch': 0.32}
{'loss': 1.2827, 'grad_norm': 5.5183634757995605, 'learning_rate': 9.904973994271347e-07, 'epoch': 0.33}
{'loss': 1.274, 'grad_norm': 5.299920558929443, 'learning_rate': 9.899321136633388e-07, 'epoch': 0.33}
{'loss': 1.2519, 'grad_norm': 3.2155866622924805, 'learning_rate': 9.89350667213021e-07, 'epoch': 0.34}
{'loss': 1.2396, 'grad_norm': 5.840811252593994, 'learning_rate': 9.887530792555192e-07, 'epoch': 0.34}
{'loss': 1.5612, 'grad_norm': 5.5062127113342285, 'learning_rate': 9.88139369502609e-07, 'epoch': 0.35}
{'loss': 1.3122, 'grad_norm': 136.6430206298828, 'learning_rate': 9.875095581978519e-07, 'epoch': 0.35}
{'loss': 1.2585, 'grad_norm': 61.20108413696289, 'learning_rate': 9.868636661159283e-07, 'epoch': 0.36}
{'loss': 1.4966, 'grad_norm': 4.974775314331055, 'learning_rate': 9.86201714561952e-07, 'epoch': 0.36}
{'loss': 1.4312, 'grad_norm': 3.54909610748291, 'learning_rate': 9.855237253707674e-07, 'epoch': 0.37}
{'loss': 1.6049, 'grad_norm': 6.187623500823975, 'learning_rate': 9.848297209062296e-07, 'epoch': 0.37}
{'loss': 1.4371, 'grad_norm': 27.48700523376465, 'learning_rate': 9.84119724060467e-07, 'epoch': 0.38}
{'loss': 1.3894, 'grad_norm': 5.281314849853516, 'learning_rate': 9.833937582531244e-07, 'epoch': 0.38}
{'loss': 1.2071, 'grad_norm': 6.679492950439453, 'learning_rate': 9.82651847430593e-07, 'epoch': 0.39}
{'loss': 1.3778, 'grad_norm': 5.1637163162231445, 'learning_rate': 9.818940160652192e-07, 'epoch': 0.39}
{'loss': 1.3759, 'grad_norm': 131.59017944335938, 'learning_rate': 9.811202891544965e-07, 'epoch': 0.4}
{'loss': 1.3992, 'grad_norm': 3.412752389907837, 'learning_rate': 9.803306922202427e-07, 'epoch': 0.41}
{'loss': 1.2874, 'grad_norm': 3.2376139163970947, 'learning_rate': 9.79525251307757e-07, 'epoch': 0.41}
{'loss': 1.3776, 'grad_norm': 4.329383850097656, 'learning_rate': 9.787039929849616e-07, 'epoch': 0.42}
{'loss': 1.2053, 'grad_norm': 15.176962852478027, 'learning_rate': 9.778669443415243e-07, 'epoch': 0.42}
{'loss': 1.4013, 'grad_norm': 16.701324462890625, 'learning_rate': 9.770141329879656e-07, 'epoch': 0.43}
{'loss': 1.2098, 'grad_norm': 6.743574619293213, 'learning_rate': 9.761455870547481e-07, 'epoch': 0.43}
{'loss': 1.3701, 'grad_norm': 3.3009939193725586, 'learning_rate': 9.752613351913484e-07, 'epoch': 0.44}
{'loss': 1.4715, 'grad_norm': 11.42988395690918, 'learning_rate': 9.743614065653118e-07, 'epoch': 0.44}
{'loss': 1.4653, 'grad_norm': 3.8539834022521973, 'learning_rate': 9.734458308612905e-07, 'epoch': 0.45}
{'loss': 1.4237, 'grad_norm': 8.153200149536133, 'learning_rate': 9.725146382800642e-07, 'epoch': 0.45}
{'loss': 1.2144, 'grad_norm': 2.9832422733306885, 'learning_rate': 9.715678595375448e-07, 'epoch': 0.46}
{'loss': 1.4365, 'grad_norm': 9.294716835021973, 'learning_rate': 9.706055258637617e-07, 'epoch': 0.46}
{'loss': 1.3568, 'grad_norm': 3.8333044052124023, 'learning_rate': 9.696276690018329e-07, 'epoch': 0.47}
{'loss': 1.4069, 'grad_norm': 13.40050983428955, 'learning_rate': 9.686343212069172e-07, 'epoch': 0.47}
{'loss': 1.4615, 'grad_norm': 3.9909446239471436, 'learning_rate': 9.676255152451506e-07, 'epoch': 0.48}
{'loss': 1.2649, 'grad_norm': 6.075472354888916, 'learning_rate': 9.66601284392566e-07, 'epoch': 0.48}
{'loss': 1.4088, 'grad_norm': 4.820675373077393, 'learning_rate': 9.655616624339944e-07, 'epoch': 0.49}
{'loss': 1.3948, 'grad_norm': 7.635002613067627, 'learning_rate': 9.645066836619508e-07, 'epoch': 0.49}
{'loss': 1.1899, 'grad_norm': 2.97786808013916, 'learning_rate': 9.634363828755043e-07, 'epoch': 0.5}
{'loss': 1.3031, 'grad_norm': 4.446471214294434, 'learning_rate': 9.623507953791286e-07, 'epoch': 0.5}
{'loss': 1.2821, 'grad_norm': 3.7384371757507324, 'learning_rate': 9.612499569815381e-07, 'epoch': 0.51}
{'loss': 1.228, 'grad_norm': 9.556249618530273, 'learning_rate': 9.601339039945073e-07, 'epoch': 0.51}
{'loss': 1.0375, 'grad_norm': 2.881906509399414, 'learning_rate': 9.590026732316719e-07, 'epoch': 0.52}
{'loss': 1.2525, 'grad_norm': 2.8442208766937256, 'learning_rate': 9.578563020073152e-07, 'epoch': 0.52}
{'loss': 1.2533, 'grad_norm': 4.470249652862549, 'learning_rate': 9.566948281351373e-07, 'epoch': 0.53}
{'loss': 1.4656, 'grad_norm': 5.5429511070251465, 'learning_rate': 9.555182899270078e-07, 'epoch': 0.54}
{'loss': 1.1114, 'grad_norm': 4.622176647186279, 'learning_rate': 9.543267261917014e-07, 'epoch': 0.54}
{'loss': 1.2082, 'grad_norm': 3.6376729011535645, 'learning_rate': 9.531201762336189e-07, 'epoch': 0.55}
{'loss': 1.2791, 'grad_norm': 5.452229976654053, 'learning_rate': 9.518986798514897e-07, 'epoch': 0.55}
{'loss': 1.407, 'grad_norm': 3.686861753463745, 'learning_rate': 9.506622773370594e-07, 'epoch': 0.56}
{'loss': 1.413, 'grad_norm': 32.103065490722656, 'learning_rate': 9.494110094737607e-07, 'epoch': 0.56}
{'loss': 1.1201, 'grad_norm': 8.458809852600098, 'learning_rate': 9.481449175353684e-07, 'epoch': 0.57}
{'loss': 1.3186, 'grad_norm': 7.527988433837891, 'learning_rate': 9.468640432846378e-07, 'epoch': 0.57}
{'loss': 1.2602, 'grad_norm': 3.213613271713257, 'learning_rate': 9.455684289719269e-07, 'epoch': 0.58}
{'loss': 1.1296, 'grad_norm': 4.565023899078369, 'learning_rate': 9.442581173338031e-07, 'epoch': 0.58}
{'loss': 1.317, 'grad_norm': 4.500886917114258, 'learning_rate': 9.429331515916332e-07, 'epoch': 0.59}
{'loss': 1.364, 'grad_norm': 4.033179759979248, 'learning_rate': 9.415935754501581e-07, 'epoch': 0.59}
{'loss': 1.2239, 'grad_norm': 4.433167457580566, 'learning_rate': 9.402394330960505e-07, 'epoch': 0.6}
{'loss': 1.3692, 'grad_norm': 4.188014030456543, 'learning_rate': 9.388707691964584e-07, 'epoch': 0.6}
{'loss': 1.2134, 'grad_norm': 7.24175500869751, 'learning_rate': 9.374876288975307e-07, 'epoch': 0.61}
{'loss': 1.2526, 'grad_norm': 3.407191276550293, 'learning_rate': 9.360900578229286e-07, 'epoch': 0.61}
{'loss': 1.366, 'grad_norm': 3.291419506072998, 'learning_rate': 9.346781020723207e-07, 'epoch': 0.62}
{'loss': 1.2234, 'grad_norm': 3.7375316619873047, 'learning_rate': 9.332518082198623e-07, 'epoch': 0.62}
{'loss': 1.3359, 'grad_norm': 3.284512519836426, 'learning_rate': 9.318112233126587e-07, 'epoch': 0.63}
{'loss': 1.1813, 'grad_norm': 2.967121124267578, 'learning_rate': 9.303563948692139e-07, 'epoch': 0.63}
{'loss': 1.2643, 'grad_norm': 17.12096405029297, 'learning_rate': 9.28887370877863e-07, 'epoch': 0.64}
{'loss': 1.1904, 'grad_norm': 4.185437202453613, 'learning_rate': 9.27404199795189e-07, 'epoch': 0.64}
{'loss': 1.4483, 'grad_norm': 9.467629432678223, 'learning_rate': 9.259069305444252e-07, 'epoch': 0.65}
{'loss': 1.1901, 'grad_norm': 4.200746536254883, 'learning_rate': 9.243956125138401e-07, 'epoch': 0.65}
{'loss': 1.151, 'grad_norm': 3.2094109058380127, 'learning_rate': 9.228702955551099e-07, 'epoch': 0.66}
{'loss': 1.5048, 'grad_norm': 4.922921657562256, 'learning_rate': 9.21331029981673e-07, 'epoch': 0.66}
{'loss': 1.3741, 'grad_norm': 3.0850565433502197, 'learning_rate': 9.197778665670706e-07, 'epoch': 0.67}
{'loss': 1.3311, 'grad_norm': 2.9760830402374268, 'learning_rate': 9.18210856543272e-07, 'epoch': 0.68}
{'loss': 1.1925, 'grad_norm': 3.17269229888916, 'learning_rate': 9.166300515989849e-07, 'epoch': 0.68}
{'loss': 1.3476, 'grad_norm': 4.83847713470459, 'learning_rate': 9.150355038779502e-07, 'epoch': 0.69}
{'loss': 1.1651, 'grad_norm': 5.888838291168213, 'learning_rate': 9.134272659772219e-07, 'epoch': 0.69}
{'loss': 1.1588, 'grad_norm': 9.954200744628906, 'learning_rate': 9.118053909454324e-07, 'epoch': 0.7}
{'loss': 1.4044, 'grad_norm': 6.531548976898193, 'learning_rate': 9.101699322810423e-07, 'epoch': 0.7}
{'loss': 1.3144, 'grad_norm': 3.0910298824310303, 'learning_rate': 9.085209439305764e-07, 'epoch': 0.71}
{'loss': 1.2901, 'grad_norm': 6.211158752441406, 'learning_rate': 9.068584802868433e-07, 'epoch': 0.71}
{'loss': 1.1498, 'grad_norm': 4.952664375305176, 'learning_rate': 9.051825961871422e-07, 'epoch': 0.72}
{'loss': 1.4375, 'grad_norm': 39.29832077026367, 'learning_rate': 9.034933469114532e-07, 'epoch': 0.72}
{'loss': 1.1476, 'grad_norm': 3.032668113708496, 'learning_rate': 9.017907881806145e-07, 'epoch': 0.73}
{'loss': 1.4497, 'grad_norm': 3.306856632232666, 'learning_rate': 9.000749761544841e-07, 'epoch': 0.73}
{'loss': 1.4216, 'grad_norm': 4.956119537353516, 'learning_rate': 8.983459674300875e-07, 'epoch': 0.74}
{'loss': 1.2246, 'grad_norm': 6.571772575378418, 'learning_rate': 8.966038190397507e-07, 'epoch': 0.74}
{'loss': 1.429, 'grad_norm': 5.761186599731445, 'learning_rate': 8.948485884492185e-07, 'epoch': 0.75}
{'loss': 1.2945, 'grad_norm': 6.4943084716796875, 'learning_rate': 8.930803335557602e-07, 'epoch': 0.75}
{'loss': 1.1902, 'grad_norm': 2.9250829219818115, 'learning_rate': 8.912991126862586e-07, 'epoch': 0.76}
{'loss': 1.2939, 'grad_norm': 3.2725682258605957, 'learning_rate': 8.895049845952867e-07, 'epoch': 0.76}
{'loss': 1.2253, 'grad_norm': 2.9660301208496094, 'learning_rate': 8.876980084631692e-07, 'epoch': 0.77}
{'loss': 1.1979, 'grad_norm': 6.644514560699463, 'learning_rate': 8.858782438940311e-07, 'epoch': 0.77}
{'loss': 1.1525, 'grad_norm': 4.938601016998291, 'learning_rate': 8.840457509138306e-07, 'epoch': 0.78}
{'loss': 1.1847, 'grad_norm': 3.76953125, 'learning_rate': 8.822005899683804e-07, 'epoch': 0.78}
{'loss': 1.3848, 'grad_norm': 3.419332504272461, 'learning_rate': 8.803428219213526e-07, 'epoch': 0.79}
{'loss': 1.2014, 'grad_norm': 6.587260723114014, 'learning_rate': 8.784725080522721e-07, 'epoch': 0.79}
{'loss': 1.2332, 'grad_norm': 3.511244773864746, 'learning_rate': 8.765897100544943e-07, 'epoch': 0.8}
{'loss': 1.3826, 'grad_norm': 3.9196529388427734, 'learning_rate': 8.74694490033171e-07, 'epoch': 0.81}
{'loss': 1.2433, 'grad_norm': 18.478635787963867, 'learning_rate': 8.727869105032013e-07, 'epoch': 0.81}
{'loss': 1.3674, 'grad_norm': 5.375921249389648, 'learning_rate': 8.708670343871696e-07, 'epoch': 0.82}
{'loss': 1.2951, 'grad_norm': 3.034057378768921, 'learning_rate': 8.6893492501327e-07, 'epoch': 0.82}
{'loss': 1.1894, 'grad_norm': 4.549667835235596, 'learning_rate': 8.669906461132181e-07, 'epoch': 0.83}
{'loss': 1.2749, 'grad_norm': 12.556056022644043, 'learning_rate': 8.650342618201473e-07, 'epoch': 0.83}
{'loss': 1.5008, 'grad_norm': 6.407953262329102, 'learning_rate': 8.630658366664951e-07, 'epoch': 0.84}
{'loss': 1.2423, 'grad_norm': 1554.3934326171875, 'learning_rate': 8.610854355818727e-07, 'epoch': 0.84}
{'loss': 1.2639, 'grad_norm': 5.341822624206543, 'learning_rate': 8.590931238909245e-07, 'epoch': 0.85}
{'loss': 1.4752, 'grad_norm': 8.37106704711914, 'learning_rate': 8.570889673111732e-07, 'epoch': 0.85}
{'loss': 1.3008, 'grad_norm': 3.6584339141845703, 'learning_rate': 8.550730319508515e-07, 'epoch': 0.86}
{'loss': 1.4227, 'grad_norm': 14.381053924560547, 'learning_rate': 8.530453843067221e-07, 'epoch': 0.86}
{'loss': 1.2305, 'grad_norm': 4.587585926055908, 'learning_rate': 8.510060912618835e-07, 'epoch': 0.87}
{'loss': 1.1785, 'grad_norm': 9.756779670715332, 'learning_rate': 8.489552200835648e-07, 'epoch': 0.87}
{'loss': 1.2939, 'grad_norm': 3.8396193981170654, 'learning_rate': 8.468928384209059e-07, 'epoch': 0.88}
{'loss': 1.1471, 'grad_norm': 3.600029230117798, 'learning_rate': 8.448190143027268e-07, 'epoch': 0.88}
{'loss': 1.3835, 'grad_norm': 4.919234275817871, 'learning_rate': 8.427338161352835e-07, 'epoch': 0.89}
{'loss': 1.1695, 'grad_norm': 2.8378822803497314, 'learning_rate': 8.406373127000109e-07, 'epoch': 0.89}
{'loss': 1.4003, 'grad_norm': 3.088897943496704, 'learning_rate': 8.385295731512549e-07, 'epoch': 0.9}
{'loss': 1.1912, 'grad_norm': 2.6915154457092285, 'learning_rate': 8.36410667013991e-07, 'epoch': 0.9}
{'loss': 1.201, 'grad_norm': 3.0586400032043457, 'learning_rate': 8.342806641815303e-07, 'epoch': 0.91}
{'loss': 1.2258, 'grad_norm': 72.69456481933594, 'learning_rate': 8.321396349132156e-07, 'epoch': 0.91}
{'loss': 1.2392, 'grad_norm': 5.508364677429199, 'learning_rate': 8.299876498321022e-07, 'epoch': 0.92}
{'loss': 1.3243, 'grad_norm': 4.807126045227051, 'learning_rate': 8.27824779922629e-07, 'epoch': 0.92}
{'loss': 1.2553, 'grad_norm': 13.705443382263184, 'learning_rate': 8.256510965282774e-07, 'epoch': 0.93}
{'loss': 1.115, 'grad_norm': 20.76632308959961, 'learning_rate': 8.234666713492178e-07, 'epoch': 0.94}
{'loss': 1.1455, 'grad_norm': 2.956505060195923, 'learning_rate': 8.21271576439944e-07, 'epoch': 0.94}
{'loss': 1.3374, 'grad_norm': 13.888449668884277, 'learning_rate': 8.190658842068972e-07, 'epoch': 0.95}
{'loss': 1.425, 'grad_norm': 4.237704277038574, 'learning_rate': 8.168496674060769e-07, 'epoch': 0.95}
{'loss': 1.1927, 'grad_norm': 3.977397918701172, 'learning_rate': 8.146229991406421e-07, 'epoch': 0.96}
{'loss': 1.3594, 'grad_norm': 2.9680871963500977, 'learning_rate': 8.123859528584984e-07, 'epoch': 0.96}
{'loss': 1.1659, 'grad_norm': 3.0361757278442383, 'learning_rate': 8.101386023498767e-07, 'epoch': 0.97}
{'loss': 1.2891, 'grad_norm': 3.7811741828918457, 'learning_rate': 8.078810217448985e-07, 'epoch': 0.97}
{'loss': 1.0346, 'grad_norm': 2.96803879737854, 'learning_rate': 8.056132855111304e-07, 'epoch': 0.98}
{'loss': 1.2088, 'grad_norm': 3.5147018432617188, 'learning_rate': 8.033354684511286e-07, 'epoch': 0.98}
{'loss': 1.1417, 'grad_norm': 2.9776954650878906, 'learning_rate': 8.010476456999711e-07, 'epoch': 0.99}
{'loss': 1.444, 'grad_norm': 2.9552690982818604, 'learning_rate': 7.987498927227787e-07, 'epoch': 0.99}
{'loss': 1.2903, 'grad_norm': 5.512300491333008, 'learning_rate': 7.964422853122268e-07, 'epoch': 1.0}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-192/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-192/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-192/model.safetensors.index.json.
2025-01-05 22:43:17,253 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-192/pytorch_model_fsdp.bin
2025-01-05 22:44:05,245 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-192/pytorch_model_fsdp.bin
2025-01-05 22:44:32,722 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-192/optimizer.bin
2025-01-05 22:47:38,751 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-192/optimizer.bin
                                                                                                                                                                                               
{'loss': 1.516, 'grad_norm': 4.3125996589660645, 'learning_rate': 7.941248995860445e-07, 'epoch': 1.0}
{'loss': 1.2529, 'grad_norm': 2.9760711193084717, 'learning_rate': 7.917978119845044e-07, 'epoch': 1.01}
{'loss': 1.2312, 'grad_norm': 2.9236669540405273, 'learning_rate': 7.894610992679007e-07, 'epoch': 1.01}
{'loss': 1.2053, 'grad_norm': 3.68023681640625, 'learning_rate': 7.871148385140178e-07, 'epoch': 1.02}
{'loss': 1.2796, 'grad_norm': 5.502809524536133, 'learning_rate': 7.847591071155871e-07, 'epoch': 1.02}
{'loss': 1.4014, 'grad_norm': 4.33700704574585, 'learning_rate': 7.823939827777344e-07, 'epoch': 1.03}
{'loss': 1.2515, 'grad_norm': 7.815846920013428, 'learning_rate': 7.800195435154178e-07, 'epoch': 1.03}
{'loss': 1.1741, 'grad_norm': 3.1532092094421387, 'learning_rate': 7.776358676508521e-07, 'epoch': 1.04}
{'loss': 1.2881, 'grad_norm': 3.6387617588043213, 'learning_rate': 7.752430338109277e-07, 'epoch': 1.04}
{'loss': 1.2048, 'grad_norm': 6.238170623779297, 'learning_rate': 7.728411209246155e-07, 'epoch': 1.05}
{'loss': 1.2418, 'grad_norm': 2.7779486179351807, 'learning_rate': 7.704302082203639e-07, 'epoch': 1.05}
{'loss': 1.205, 'grad_norm': 4.13209867477417, 'learning_rate': 7.680103752234857e-07, 'epoch': 1.06}
{'loss': 1.2738, 'grad_norm': 4.884899139404297, 'learning_rate': 7.655817017535339e-07, 'epoch': 1.06}
{'loss': 1.0357, 'grad_norm': 2.7674076557159424, 'learning_rate': 7.631442679216702e-07, 'epoch': 1.07}
{'loss': 1.1981, 'grad_norm': 2.660443067550659, 'learning_rate': 7.60698154128021e-07, 'epoch': 1.08}
{'loss': 1.1436, 'grad_norm': 8.39730167388916, 'learning_rate': 7.582434410590268e-07, 'epoch': 1.08}
{'loss': 1.1368, 'grad_norm': 3.1652090549468994, 'learning_rate': 7.557802096847799e-07, 'epoch': 1.09}
{'loss': 1.2622, 'grad_norm': 19.232463836669922, 'learning_rate': 7.533085412563534e-07, 'epoch': 1.09}
{'loss': 1.1708, 'grad_norm': 3.5881218910217285, 'learning_rate': 7.508285173031215e-07, 'epoch': 1.1}
{'loss': 1.2469, 'grad_norm': 2.8522989749908447, 'learning_rate': 7.483402196300704e-07, 'epoch': 1.1}
{'loss': 1.1622, 'grad_norm': 3.441481828689575, 'learning_rate': 7.458437303150994e-07, 'epoch': 1.11}
{'loss': 1.0888, 'grad_norm': 4.569231986999512, 'learning_rate': 7.433391317063133e-07, 'epoch': 1.11}
{'loss': 1.1797, 'grad_norm': 3.3615853786468506, 'learning_rate': 7.408265064193071e-07, 'epoch': 1.12}
{'loss': 1.2536, 'grad_norm': 4.364865303039551, 'learning_rate': 7.383059373344401e-07, 'epoch': 1.12}
{'loss': 1.2952, 'grad_norm': 3.9342129230499268, 'learning_rate': 7.357775075941024e-07, 'epoch': 1.13}
{'loss': 1.2048, 'grad_norm': 3.378572940826416, 'learning_rate': 7.332413005999717e-07, 'epoch': 1.13}
{'loss': 1.135, 'grad_norm': 10.264627456665039, 'learning_rate': 7.306974000102634e-07, 'epoch': 1.14}
{'loss': 1.2685, 'grad_norm': 4.1950364112854, 'learning_rate': 7.281458897369705e-07, 'epoch': 1.14}
{'loss': 1.2353, 'grad_norm': 9.199005126953125, 'learning_rate': 7.25586853943095e-07, 'epoch': 1.15}
{'loss': 1.2189, 'grad_norm': 7.5499467849731445, 'learning_rate': 7.230203770398732e-07, 'epoch': 1.15}
{'loss': 1.0255, 'grad_norm': 5.762465000152588, 'learning_rate': 7.204465436839902e-07, 'epoch': 1.16}
{'loss': 1.1683, 'grad_norm': 5.109388828277588, 'learning_rate': 7.178654387747877e-07, 'epoch': 1.16}
{'loss': 1.3482, 'grad_norm': 4.597589015960693, 'learning_rate': 7.152771474514642e-07, 'epoch': 1.17}
{'loss': 1.0652, 'grad_norm': 3.1541008949279785, 'learning_rate': 7.126817550902655e-07, 'epoch': 1.17}
{'loss': 1.1051, 'grad_norm': 3.1654489040374756, 'learning_rate': 7.100793473016698e-07, 'epoch': 1.18}
{'loss': 1.3835, 'grad_norm': 5.203097343444824, 'learning_rate': 7.074700099275622e-07, 'epoch': 1.18}
{'loss': 1.2431, 'grad_norm': 7.1941351890563965, 'learning_rate': 7.04853829038405e-07, 'epoch': 1.19}
{'loss': 1.0621, 'grad_norm': 7.229476451873779, 'learning_rate': 7.022308909303974e-07, 'epoch': 1.19}
{'loss': 1.0911, 'grad_norm': 64.73982238769531, 'learning_rate': 6.996012821226288e-07, 'epoch': 1.2}
{'loss': 1.544, 'grad_norm': 3.976623058319092, 'learning_rate': 6.969650893542261e-07, 'epoch': 1.21}
{'loss': 1.1001, 'grad_norm': 4.2976179122924805, 'learning_rate': 6.943223995814913e-07, 'epoch': 1.21}
{'loss': 1.2848, 'grad_norm': 3.4453086853027344, 'learning_rate': 6.916732999750343e-07, 'epoch': 1.22}
{'loss': 1.2652, 'grad_norm': 4.575332164764404, 'learning_rate': 6.890178779168963e-07, 'epoch': 1.22}
{'loss': 1.2586, 'grad_norm': 2.80086350440979, 'learning_rate': 6.863562209976685e-07, 'epoch': 1.23}
{'loss': 1.2433, 'grad_norm': 4.871217250823975, 'learning_rate': 6.836884170136025e-07, 'epoch': 1.23}
{'loss': 1.2803, 'grad_norm': 3.495958089828491, 'learning_rate': 6.810145539637145e-07, 'epoch': 1.24}
{'loss': 1.2276, 'grad_norm': 3.0922653675079346, 'learning_rate': 6.783347200468817e-07, 'epoch': 1.24}
{'loss': 1.2737, 'grad_norm': 3.3053300380706787, 'learning_rate': 6.756490036589345e-07, 'epoch': 1.25}
{'loss': 1.1408, 'grad_norm': 9.431020736694336, 'learning_rate': 6.729574933897396e-07, 'epoch': 1.25}
{'loss': 1.2087, 'grad_norm': 3.1692285537719727, 'learning_rate': 6.702602780202778e-07, 'epoch': 1.26}
{'loss': 1.1243, 'grad_norm': 3.459872007369995, 'learning_rate': 6.675574465197165e-07, 'epoch': 1.26}
{'loss': 1.3513, 'grad_norm': 4.39254093170166, 'learning_rate': 6.64849088042474e-07, 'epoch': 1.27}
{'loss': 1.3561, 'grad_norm': 5.16657018661499, 'learning_rate': 6.621352919252788e-07, 'epoch': 1.27}
{'loss': 1.0812, 'grad_norm': 5.630642890930176, 'learning_rate': 6.594161476842233e-07, 'epoch': 1.28}
{'loss': 1.1006, 'grad_norm': 6.59079122543335, 'learning_rate': 6.566917450118108e-07, 'epoch': 1.28}
{'loss': 1.0742, 'grad_norm': 3.024517297744751, 'learning_rate': 6.53962173773997e-07, 'epoch': 1.29}
{'loss': 1.1048, 'grad_norm': 2.6930384635925293, 'learning_rate': 6.512275240072252e-07, 'epoch': 1.29}
{'loss': 1.0037, 'grad_norm': 18.040470123291016, 'learning_rate': 6.484878859154574e-07, 'epoch': 1.3}
{'loss': 1.2166, 'grad_norm': 8.501428604125977, 'learning_rate': 6.457433498671978e-07, 'epoch': 1.3}
{'loss': 1.2887, 'grad_norm': 5.057615756988525, 'learning_rate': 6.429940063925127e-07, 'epoch': 1.31}
{'loss': 1.0742, 'grad_norm': 9.833489418029785, 'learning_rate': 6.402399461800442e-07, 'epoch': 1.31}
{'loss': 1.2033, 'grad_norm': 2.827316999435425, 'learning_rate': 6.374812600740187e-07, 'epoch': 1.32}
{'loss': 1.3538, 'grad_norm': 2.9561927318573, 'learning_rate': 6.347180390712497e-07, 'epoch': 1.32}
{'loss': 1.168, 'grad_norm': 5.037417411804199, 'learning_rate': 6.319503743181371e-07, 'epoch': 1.33}
{'loss': 1.1579, 'grad_norm': 2.6992857456207275, 'learning_rate': 6.291783571076611e-07, 'epoch': 1.34}
{'loss': 1.1152, 'grad_norm': 3.339268207550049, 'learning_rate': 6.26402078876369e-07, 'epoch': 1.34}
{'loss': 1.2077, 'grad_norm': 3.687283754348755, 'learning_rate': 6.236216312013614e-07, 'epoch': 1.35}
{'loss': 1.1991, 'grad_norm': 31.004837036132812, 'learning_rate': 6.208371057972694e-07, 'epoch': 1.35}
{'loss': 1.4012, 'grad_norm': 3.045837640762329, 'learning_rate': 6.18048594513231e-07, 'epoch': 1.36}
{'loss': 1.2648, 'grad_norm': 3.2025339603424072, 'learning_rate': 6.1525618932986e-07, 'epoch': 1.36}
{'loss': 1.123, 'grad_norm': 3.718562602996826, 'learning_rate': 6.124599823562134e-07, 'epoch': 1.37}
{'loss': 1.1344, 'grad_norm': 2.9792470932006836, 'learning_rate': 6.096600658267518e-07, 'epoch': 1.37}
{'loss': 1.2321, 'grad_norm': 3.2812509536743164, 'learning_rate': 6.068565320982981e-07, 'epoch': 1.38}
{'loss': 1.1409, 'grad_norm': 3.8097198009490967, 'learning_rate': 6.0404947364699e-07, 'epoch': 1.38}
{'loss': 1.1063, 'grad_norm': 5.063697814941406, 'learning_rate': 6.012389830652306e-07, 'epoch': 1.39}
{'loss': 1.1907, 'grad_norm': 2.8818063735961914, 'learning_rate': 5.984251530586336e-07, 'epoch': 1.39}
{'loss': 1.2312, 'grad_norm': 2.6009302139282227, 'learning_rate': 5.956080764429653e-07, 'epoch': 1.4}
{'loss': 1.36, 'grad_norm': 5.30222749710083, 'learning_rate': 5.927878461410836e-07, 'epoch': 1.4}
{'loss': 1.2601, 'grad_norm': 3.8845551013946533, 'learning_rate': 5.899645551798725e-07, 'epoch': 1.41}
{'loss': 1.1234, 'grad_norm': 5.174372673034668, 'learning_rate': 5.871382966871728e-07, 'epoch': 1.41}
{'loss': 1.0507, 'grad_norm': 2.9379119873046875, 'learning_rate': 5.843091638887124e-07, 'epoch': 1.42}
{'loss': 1.1193, 'grad_norm': 4.383249282836914, 'learning_rate': 5.814772501050286e-07, 'epoch': 1.42}
{'loss': 1.234, 'grad_norm': 3.2265467643737793, 'learning_rate': 5.786426487483914e-07, 'epoch': 1.43}
{'loss': 1.0961, 'grad_norm': 21.14222526550293, 'learning_rate': 5.758054533197222e-07, 'epoch': 1.43}
{'loss': 1.1369, 'grad_norm': 3.1788523197174072, 'learning_rate': 5.729657574055089e-07, 'epoch': 1.44}
{'loss': 1.2353, 'grad_norm': 3.379531145095825, 'learning_rate': 5.701236546747197e-07, 'epoch': 1.44}
{'loss': 1.2693, 'grad_norm': 4.655346393585205, 'learning_rate': 5.672792388757127e-07, 'epoch': 1.45}
{'loss': 1.2507, 'grad_norm': 10.643776893615723, 'learning_rate': 5.644326038331439e-07, 'epoch': 1.45}
{'loss': 1.1335, 'grad_norm': 3.311838150024414, 'learning_rate': 5.615838434448725e-07, 'epoch': 1.46}
{'loss': 1.1444, 'grad_norm': 3.3113393783569336, 'learning_rate': 5.587330516788633e-07, 'epoch': 1.46}
{'loss': 1.2575, 'grad_norm': 2.8305482864379883, 'learning_rate': 5.558803225700872e-07, 'epoch': 1.47}
{'loss': 1.1069, 'grad_norm': 12.78821086883545, 'learning_rate': 5.530257502174196e-07, 'epoch': 1.48}
{'loss': 1.1496, 'grad_norm': 2.9223835468292236, 'learning_rate': 5.501694287805361e-07, 'epoch': 1.48}
{'loss': 1.1982, 'grad_norm': 2.8254895210266113, 'learning_rate': 5.473114524768068e-07, 'epoch': 1.49}
{'loss': 1.1735, 'grad_norm': 5.236664772033691, 'learning_rate': 5.444519155781889e-07, 'epoch': 1.49}
{'loss': 1.2575, 'grad_norm': 3.186742067337036, 'learning_rate': 5.415909124081163e-07, 'epoch': 1.5}
{'loss': 1.0666, 'grad_norm': 3.1883742809295654, 'learning_rate': 5.387285373383892e-07, 'epoch': 1.5}
{'loss': 0.9953, 'grad_norm': 2.9361517429351807, 'learning_rate': 5.358648847860598e-07, 'epoch': 1.51}
{'loss': 1.3294, 'grad_norm': 2.7800941467285156, 'learning_rate': 5.330000492103198e-07, 'epoch': 1.51}
{'loss': 1.2136, 'grad_norm': 2.908714771270752, 'learning_rate': 5.301341251093827e-07, 'epoch': 1.52}
{'loss': 1.1237, 'grad_norm': 2.9181325435638428, 'learning_rate': 5.272672070173682e-07, 'epoch': 1.52}
{'loss': 1.0994, 'grad_norm': 8.738744735717773, 'learning_rate': 5.243993895011833e-07, 'epoch': 1.53}
{'loss': 1.2041, 'grad_norm': 3.5948104858398438, 'learning_rate': 5.215307671574027e-07, 'epoch': 1.53}
{'loss': 1.2483, 'grad_norm': 49.367835998535156, 'learning_rate': 5.18661434609149e-07, 'epoch': 1.54}
{'loss': 1.1418, 'grad_norm': 4.231839179992676, 'learning_rate': 5.157914865029715e-07, 'epoch': 1.54}
{'loss': 1.3573, 'grad_norm': 4.087013244628906, 'learning_rate': 5.129210175057236e-07, 'epoch': 1.55}
{'loss': 1.0729, 'grad_norm': 3.0860729217529297, 'learning_rate': 5.100501223014407e-07, 'epoch': 1.55}
{'loss': 1.2128, 'grad_norm': 2.9950010776519775, 'learning_rate': 5.07178895588217e-07, 'epoch': 1.56}
{'loss': 1.1514, 'grad_norm': 3.312721014022827, 'learning_rate': 5.04307432075082e-07, 'epoch': 1.56}
{'loss': 1.192, 'grad_norm': 3.019256353378296, 'learning_rate': 5.014358264788755e-07, 'epoch': 1.57}
{'loss': 1.0175, 'grad_norm': 2.633563756942749, 'learning_rate': 4.985641735211245e-07, 'epoch': 1.57}
{'loss': 1.0011, 'grad_norm': 3.2760512828826904, 'learning_rate': 4.95692567924918e-07, 'epoch': 1.58}
{'loss': 1.0466, 'grad_norm': 11.15481185913086, 'learning_rate': 4.928211044117829e-07, 'epoch': 1.58}
{'loss': 1.1793, 'grad_norm': 2.9450173377990723, 'learning_rate': 4.899498776985593e-07, 'epoch': 1.59}
{'loss': 1.2671, 'grad_norm': 3.961686372756958, 'learning_rate': 4.870789824942765e-07, 'epoch': 1.59}
{'loss': 1.1784, 'grad_norm': 2.762634038925171, 'learning_rate': 4.842085134970286e-07, 'epoch': 1.6}
{'loss': 1.1317, 'grad_norm': 3.6225838661193848, 'learning_rate': 4.813385653908509e-07, 'epoch': 1.61}
{'loss': 1.0904, 'grad_norm': 2.97571063041687, 'learning_rate': 4.784692328425973e-07, 'epoch': 1.61}
{'loss': 1.2337, 'grad_norm': 6.386412620544434, 'learning_rate': 4.756006104988167e-07, 'epoch': 1.62}
{'loss': 1.0818, 'grad_norm': 3.6247940063476562, 'learning_rate': 4.727327929826318e-07, 'epoch': 1.62}
{'loss': 1.2368, 'grad_norm': 9.474085807800293, 'learning_rate': 4.698658748906174e-07, 'epoch': 1.63}
{'loss': 1.1117, 'grad_norm': 2.964973211288452, 'learning_rate': 4.6699995078968026e-07, 'epoch': 1.63}
{'loss': 1.0961, 'grad_norm': 2.7261297702789307, 'learning_rate': 4.6413511521394023e-07, 'epoch': 1.64}
{'loss': 1.2053, 'grad_norm': 3.0779809951782227, 'learning_rate': 4.6127146266161083e-07, 'epoch': 1.64}
{'loss': 1.2827, 'grad_norm': 3.7912027835845947, 'learning_rate': 4.5840908759188355e-07, 'epoch': 1.65}
{'loss': 1.1852, 'grad_norm': 9.649391174316406, 'learning_rate': 4.5554808442181104e-07, 'epoch': 1.65}
{'loss': 1.3163, 'grad_norm': 3.1731925010681152, 'learning_rate': 4.5268854752319323e-07, 'epoch': 1.66}
{'loss': 1.089, 'grad_norm': 6.115740776062012, 'learning_rate': 4.498305712194641e-07, 'epoch': 1.66}
{'loss': 1.1673, 'grad_norm': 3.357762098312378, 'learning_rate': 4.469742497825804e-07, 'epoch': 1.67}
{'loss': 1.0867, 'grad_norm': 2.8410484790802, 'learning_rate': 4.4411967742991287e-07, 'epoch': 1.67}
{'loss': 1.2689, 'grad_norm': 3.7471089363098145, 'learning_rate': 4.412669483211367e-07, 'epoch': 1.68}
{'loss': 1.2766, 'grad_norm': 2.6650543212890625, 'learning_rate': 4.3841615655512756e-07, 'epoch': 1.68}
{'loss': 1.2388, 'grad_norm': 2.8252646923065186, 'learning_rate': 4.3556739616685607e-07, 'epoch': 1.69}
{'loss': 1.2637, 'grad_norm': 3.0048208236694336, 'learning_rate': 4.3272076112428745e-07, 'epoch': 1.69}
{'loss': 1.1271, 'grad_norm': 4.586713790893555, 'learning_rate': 4.2987634532528046e-07, 'epoch': 1.7}
{'loss': 1.1736, 'grad_norm': 7.075591087341309, 'learning_rate': 4.2703424259449104e-07, 'epoch': 1.7}
{'loss': 1.2707, 'grad_norm': 3.315629482269287, 'learning_rate': 4.2419454668027785e-07, 'epoch': 1.71}
{'loss': 0.9859, 'grad_norm': 3.445917844772339, 'learning_rate': 4.213573512516085e-07, 'epoch': 1.71}
{'loss': 1.115, 'grad_norm': 4.321223735809326, 'learning_rate': 4.1852274989497145e-07, 'epoch': 1.72}
{'loss': 1.1636, 'grad_norm': 4.110436916351318, 'learning_rate': 4.1569083611128753e-07, 'epoch': 1.72}
{'loss': 1.2075, 'grad_norm': 10.721500396728516, 'learning_rate': 4.128617033128271e-07, 'epoch': 1.73}
{'loss': 1.0884, 'grad_norm': 4.763175964355469, 'learning_rate': 4.1003544482012777e-07, 'epoch': 1.74}
{'loss': 1.3136, 'grad_norm': 2.5449161529541016, 'learning_rate': 4.072121538589164e-07, 'epoch': 1.74}
{'loss': 1.3315, 'grad_norm': 2.771444797515869, 'learning_rate': 4.043919235570347e-07, 'epoch': 1.75}
{'loss': 1.2175, 'grad_norm': 3.469099283218384, 'learning_rate': 4.015748469413664e-07, 'epoch': 1.75}
{'loss': 1.1626, 'grad_norm': 3.6334879398345947, 'learning_rate': 3.9876101693476945e-07, 'epoch': 1.76}
{'loss': 1.0472, 'grad_norm': 3.08586049079895, 'learning_rate': 3.9595052635301e-07, 'epoch': 1.76}
{'loss': 1.0896, 'grad_norm': 3.024089813232422, 'learning_rate': 3.931434679017019e-07, 'epoch': 1.77}
{'loss': 1.2513, 'grad_norm': 3.8762855529785156, 'learning_rate': 3.903399341732482e-07, 'epoch': 1.77}
{'loss': 1.2154, 'grad_norm': 3.505140781402588, 'learning_rate': 3.8754001764378665e-07, 'epoch': 1.78}
{'loss': 1.1746, 'grad_norm': 4.690968990325928, 'learning_rate': 3.8474381067014e-07, 'epoch': 1.78}
{'loss': 1.1515, 'grad_norm': 2.642411708831787, 'learning_rate': 3.81951405486769e-07, 'epoch': 1.79}
{'loss': 1.4176, 'grad_norm': 3.426114082336426, 'learning_rate': 3.7916289420273064e-07, 'epoch': 1.79}
{'loss': 1.1935, 'grad_norm': 3.7555856704711914, 'learning_rate': 3.7637836879863856e-07, 'epoch': 1.8}
{'loss': 1.1642, 'grad_norm': 3.9671788215637207, 'learning_rate': 3.7359792112363085e-07, 'epoch': 1.8}
{'loss': 1.2208, 'grad_norm': 3.2274060249328613, 'learning_rate': 3.708216428923391e-07, 'epoch': 1.81}
{'loss': 1.0636, 'grad_norm': 2.766911506652832, 'learning_rate': 3.680496256818628e-07, 'epoch': 1.81}
{'loss': 1.2112, 'grad_norm': 2.586453437805176, 'learning_rate': 3.652819609287504e-07, 'epoch': 1.82}
{'loss': 1.2181, 'grad_norm': 10.855194091796875, 'learning_rate': 3.6251873992598126e-07, 'epoch': 1.82}
{'loss': 1.2343, 'grad_norm': 3.2347357273101807, 'learning_rate': 3.5976005381995565e-07, 'epoch': 1.83}
{'loss': 1.0566, 'grad_norm': 2.950873374938965, 'learning_rate': 3.570059936074871e-07, 'epoch': 1.83}
{'loss': 1.188, 'grad_norm': 3.664618730545044, 'learning_rate': 3.5425665013280213e-07, 'epoch': 1.84}
{'loss': 1.2404, 'grad_norm': 2.9155924320220947, 'learning_rate': 3.515121140845427e-07, 'epoch': 1.84}
{'loss': 1.2117, 'grad_norm': 3.064640998840332, 'learning_rate': 3.487724759927747e-07, 'epoch': 1.85}
{'loss': 1.2008, 'grad_norm': 2.8536343574523926, 'learning_rate': 3.4603782622600305e-07, 'epoch': 1.85}
{'loss': 1.1802, 'grad_norm': 2.8414478302001953, 'learning_rate': 3.4330825498818907e-07, 'epoch': 1.86}
{'loss': 1.0104, 'grad_norm': 5.165474891662598, 'learning_rate': 3.4058385231577673e-07, 'epoch': 1.86}
{'loss': 1.1196, 'grad_norm': 3.693739175796509, 'learning_rate': 3.3786470807472124e-07, 'epoch': 1.87}
{'loss': 1.0854, 'grad_norm': 3.2054378986358643, 'learning_rate': 3.3515091195752596e-07, 'epoch': 1.88}
{'loss': 1.2796, 'grad_norm': 3.812237501144409, 'learning_rate': 3.324425534802835e-07, 'epoch': 1.88}
{'loss': 0.9788, 'grad_norm': 2.6986501216888428, 'learning_rate': 3.297397219797221e-07, 'epoch': 1.89}
{'loss': 1.0788, 'grad_norm': 2.804433822631836, 'learning_rate': 3.2704250661026043e-07, 'epoch': 1.89}
{'loss': 1.1013, 'grad_norm': 3.478855609893799, 'learning_rate': 3.243509963410654e-07, 'epoch': 1.9}
{'loss': 1.0689, 'grad_norm': 3.1064374446868896, 'learning_rate': 3.2166527995311834e-07, 'epoch': 1.9}
{'loss': 1.3377, 'grad_norm': 4.4345245361328125, 'learning_rate': 3.189854460362856e-07, 'epoch': 1.91}
{'loss': 1.0671, 'grad_norm': 2.666527032852173, 'learning_rate': 3.163115829863975e-07, 'epoch': 1.91}
{'loss': 1.1268, 'grad_norm': 4.713126182556152, 'learning_rate': 3.136437790023316e-07, 'epoch': 1.92}
{'loss': 1.2219, 'grad_norm': 3.0727555751800537, 'learning_rate': 3.109821220831038e-07, 'epoch': 1.92}
{'loss': 1.2055, 'grad_norm': 2.9015610218048096, 'learning_rate': 3.083267000249658e-07, 'epoch': 1.93}
{'loss': 1.233, 'grad_norm': 2.7856335639953613, 'learning_rate': 3.0567760041850855e-07, 'epoch': 1.93}
{'loss': 1.2686, 'grad_norm': 3.236349582672119, 'learning_rate': 3.0303491064577395e-07, 'epoch': 1.94}
{'loss': 1.0993, 'grad_norm': 2.493133068084717, 'learning_rate': 3.0039871787737115e-07, 'epoch': 1.94}
{'loss': 1.1734, 'grad_norm': 3.179758310317993, 'learning_rate': 2.9776910906960265e-07, 'epoch': 1.95}
{'loss': 1.2765, 'grad_norm': 2.9077367782592773, 'learning_rate': 2.951461709615951e-07, 'epoch': 1.95}
{'loss': 1.1196, 'grad_norm': 3.328096866607666, 'learning_rate': 2.9252999007243784e-07, 'epoch': 1.96}
{'loss': 1.2652, 'grad_norm': 15.758977890014648, 'learning_rate': 2.899206526983303e-07, 'epoch': 1.96}
{'loss': 1.1174, 'grad_norm': 2.8011043071746826, 'learning_rate': 2.8731824490973445e-07, 'epoch': 1.97}
{'loss': 1.0935, 'grad_norm': 4.519021511077881, 'learning_rate': 2.847228525485359e-07, 'epoch': 1.97}
{'loss': 1.2177, 'grad_norm': 3.4273736476898193, 'learning_rate': 2.821345612252121e-07, 'epoch': 1.98}
{'loss': 1.0027, 'grad_norm': 5.130177021026611, 'learning_rate': 2.795534563160099e-07, 'epoch': 1.98}
{'loss': 1.1275, 'grad_norm': 3.3044564723968506, 'learning_rate': 2.7697962296012687e-07, 'epoch': 1.99}
{'loss': 1.2202, 'grad_norm': 3.001131296157837, 'learning_rate': 2.7441314605690485e-07, 'epoch': 1.99}
{'loss': 1.2941, 'grad_norm': 2.8730628490448, 'learning_rate': 2.7185411026302964e-07, 'epoch': 2.0}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-385/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-385/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-385/model.safetensors.index.json.
2025-01-05 22:58:36,173 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-385/pytorch_model_fsdp.bin
2025-01-05 22:59:16,571 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-385/pytorch_model_fsdp.bin
2025-01-05 22:59:47,819 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-385/optimizer.bin
2025-01-05 23:01:15,707 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-385/optimizer.bin
                                                                                                                                                                                               
{'loss': 1.1488, 'grad_norm': 2.741777181625366, 'learning_rate': 2.693025999897364e-07, 'epoch': 2.01}
{'loss': 1.0657, 'grad_norm': 2.5727951526641846, 'learning_rate': 2.667586994000283e-07, 'epoch': 2.01}
{'loss': 1.0584, 'grad_norm': 3.4766438007354736, 'learning_rate': 2.6422249240589767e-07, 'epoch': 2.02}
{'loss': 1.0726, 'grad_norm': 7.252644062042236, 'learning_rate': 2.616940626655598e-07, 'epoch': 2.02}
{'loss': 0.9661, 'grad_norm': 2.6759109497070312, 'learning_rate': 2.591734935806929e-07, 'epoch': 2.03}
{'loss': 1.1684, 'grad_norm': 5.039639472961426, 'learning_rate': 2.5666086829368675e-07, 'epoch': 2.03}
{'loss': 1.261, 'grad_norm': 3.0128839015960693, 'learning_rate': 2.5415626968490074e-07, 'epoch': 2.04}
{'loss': 1.1755, 'grad_norm': 8.530250549316406, 'learning_rate': 2.516597803699294e-07, 'epoch': 2.04}
{'loss': 1.2339, 'grad_norm': 4.15426778793335, 'learning_rate': 2.491714826968785e-07, 'epoch': 2.05}
{'loss': 1.231, 'grad_norm': 4.6143059730529785, 'learning_rate': 2.4669145874364653e-07, 'epoch': 2.05}
{'loss': 1.1672, 'grad_norm': 2.9525837898254395, 'learning_rate': 2.4421979031522006e-07, 'epoch': 2.06}
{'loss': 1.0786, 'grad_norm': 3.13696551322937, 'learning_rate': 2.417565589409733e-07, 'epoch': 2.06}
{'loss': 1.0408, 'grad_norm': 2.9040446281433105, 'learning_rate': 2.3930184587197897e-07, 'epoch': 2.07}
{'loss': 1.1479, 'grad_norm': 10.166651725769043, 'learning_rate': 2.3685573207832987e-07, 'epoch': 2.07}
{'loss': 1.1463, 'grad_norm': 3.899052619934082, 'learning_rate': 2.3441829824646602e-07, 'epoch': 2.08}
{'loss': 1.1869, 'grad_norm': 4.0638909339904785, 'learning_rate': 2.319896247765143e-07, 'epoch': 2.08}
{'loss': 1.1003, 'grad_norm': 6.931341648101807, 'learning_rate': 2.2956979177963598e-07, 'epoch': 2.09}
{'loss': 1.0609, 'grad_norm': 3.1381735801696777, 'learning_rate': 2.271588790753845e-07, 'epoch': 2.09}
{'loss': 1.2194, 'grad_norm': 2.6024556159973145, 'learning_rate': 2.2475696618907235e-07, 'epoch': 2.1}
{'loss': 1.1506, 'grad_norm': 4.0317182540893555, 'learning_rate': 2.2236413234914803e-07, 'epoch': 2.1}
{'loss': 1.1715, 'grad_norm': 2.9501287937164307, 'learning_rate': 2.1998045648458242e-07, 'epoch': 2.11}
{'loss': 1.1483, 'grad_norm': 4.37873649597168, 'learning_rate': 2.176060172222654e-07, 'epoch': 2.11}
{'loss': 1.1507, 'grad_norm': 3.031365394592285, 'learning_rate': 2.1524089288441311e-07, 'epoch': 2.12}
{'loss': 1.1816, 'grad_norm': 3.925825595855713, 'learning_rate': 2.1288516148598213e-07, 'epoch': 2.12}
{'loss': 1.3428, 'grad_norm': 5.231334209442139, 'learning_rate': 2.105389007320992e-07, 'epoch': 2.13}
{'loss': 1.1424, 'grad_norm': 2.73390531539917, 'learning_rate': 2.0820218801549577e-07, 'epoch': 2.14}
{'loss': 1.1054, 'grad_norm': 2.749872922897339, 'learning_rate': 2.058751004139555e-07, 'epoch': 2.14}
{'loss': 1.2549, 'grad_norm': 5.715569496154785, 'learning_rate': 2.0355771468777323e-07, 'epoch': 2.15}
{'loss': 1.0561, 'grad_norm': 2.8005385398864746, 'learning_rate': 2.012501072772213e-07, 'epoch': 2.15}
{'loss': 1.0663, 'grad_norm': 3.103882312774658, 'learning_rate': 1.9895235430002892e-07, 'epoch': 2.16}
{'loss': 1.2594, 'grad_norm': 3.342982769012451, 'learning_rate': 1.966645315488713e-07, 'epoch': 2.16}
{'loss': 1.1237, 'grad_norm': 2.7490663528442383, 'learning_rate': 1.9438671448886962e-07, 'epoch': 2.17}
{'loss': 1.0889, 'grad_norm': 3.2146291732788086, 'learning_rate': 1.921189782551016e-07, 'epoch': 2.17}
{'loss': 1.4018, 'grad_norm': 3.2051734924316406, 'learning_rate': 1.8986139765012327e-07, 'epoch': 2.18}
{'loss': 1.105, 'grad_norm': 4.4357829093933105, 'learning_rate': 1.8761404714150158e-07, 'epoch': 2.18}
{'loss': 1.1964, 'grad_norm': 3.377912998199463, 'learning_rate': 1.853770008593578e-07, 'epoch': 2.19}
{'loss': 1.2384, 'grad_norm': 3.0909149646759033, 'learning_rate': 1.831503325939231e-07, 'epoch': 2.19}
{'loss': 1.1575, 'grad_norm': 3.3706042766571045, 'learning_rate': 1.809341157931028e-07, 'epoch': 2.2}
{'loss': 1.1747, 'grad_norm': 2.829890489578247, 'learning_rate': 1.7872842356005597e-07, 'epoch': 2.2}
{'loss': 1.183, 'grad_norm': 3.5185210704803467, 'learning_rate': 1.765333286507824e-07, 'epoch': 2.21}
{'loss': 1.2734, 'grad_norm': 3.0620875358581543, 'learning_rate': 1.743489034717226e-07, 'epoch': 2.21}
{'loss': 1.2235, 'grad_norm': 4.610894680023193, 'learning_rate': 1.7217522007737106e-07, 'epoch': 2.22}
{'loss': 1.1848, 'grad_norm': 3.3612475395202637, 'learning_rate': 1.700123501678979e-07, 'epoch': 2.22}
{'loss': 1.1966, 'grad_norm': 2.8812270164489746, 'learning_rate': 1.6786036508678437e-07, 'epoch': 2.23}
{'loss': 1.1172, 'grad_norm': 4.309164047241211, 'learning_rate': 1.6571933581846965e-07, 'epoch': 2.23}
{'loss': 1.1721, 'grad_norm': 3.08255934715271, 'learning_rate': 1.6358933298600907e-07, 'epoch': 2.24}
{'loss': 1.1631, 'grad_norm': 3.7161619663238525, 'learning_rate': 1.6147042684874508e-07, 'epoch': 2.24}
{'loss': 1.0825, 'grad_norm': 2.5432794094085693, 'learning_rate': 1.5936268729998913e-07, 'epoch': 2.25}
{'loss': 1.0184, 'grad_norm': 11.532346725463867, 'learning_rate': 1.5726618386471656e-07, 'epoch': 2.25}
{'loss': 1.1086, 'grad_norm': 2.843454122543335, 'learning_rate': 1.55180985697273e-07, 'epoch': 2.26}
{'loss': 1.0941, 'grad_norm': 2.548389434814453, 'learning_rate': 1.531071615790942e-07, 'epoch': 2.26}
{'loss': 1.1769, 'grad_norm': 6.663864612579346, 'learning_rate': 1.5104477991643515e-07, 'epoch': 2.27}
{'loss': 1.0559, 'grad_norm': 2.7202179431915283, 'learning_rate': 1.489939087381164e-07, 'epoch': 2.28}
{'loss': 0.964, 'grad_norm': 2.4265921115875244, 'learning_rate': 1.46954615693278e-07, 'epoch': 2.28}
{'loss': 1.0904, 'grad_norm': 2.949496269226074, 'learning_rate': 1.449269680491484e-07, 'epoch': 2.29}
{'loss': 1.1949, 'grad_norm': 3.2885172367095947, 'learning_rate': 1.4291103268882677e-07, 'epoch': 2.29}
{'loss': 1.1564, 'grad_norm': 3.017908811569214, 'learning_rate': 1.4090687610907548e-07, 'epoch': 2.3}
{'loss': 1.255, 'grad_norm': 3.36702823638916, 'learning_rate': 1.3891456441812744e-07, 'epoch': 2.3}
{'loss': 1.1695, 'grad_norm': 3.152803659439087, 'learning_rate': 1.36934163333505e-07, 'epoch': 2.31}
{'loss': 1.3287, 'grad_norm': 3.3386902809143066, 'learning_rate': 1.3496573817985262e-07, 'epoch': 2.31}
{'loss': 1.123, 'grad_norm': 11.679232597351074, 'learning_rate': 1.3300935388678196e-07, 'epoch': 2.32}
{'loss': 1.1496, 'grad_norm': 2.7898380756378174, 'learning_rate': 1.3106507498672998e-07, 'epoch': 2.32}
{'loss': 1.1029, 'grad_norm': 2.5459046363830566, 'learning_rate': 1.2913296561283054e-07, 'epoch': 2.33}
{'loss': 1.1168, 'grad_norm': 3.5054969787597656, 'learning_rate': 1.2721308949679866e-07, 'epoch': 2.33}
{'loss': 1.0798, 'grad_norm': 2.9096648693084717, 'learning_rate': 1.2530550996682904e-07, 'epoch': 2.34}
{'loss': 1.0932, 'grad_norm': 3.6996257305145264, 'learning_rate': 1.2341028994550556e-07, 'epoch': 2.34}
{'loss': 1.0154, 'grad_norm': 3.943117618560791, 'learning_rate': 1.2152749194772783e-07, 'epoch': 2.35}
{'loss': 0.9818, 'grad_norm': 2.6275784969329834, 'learning_rate': 1.196571780786474e-07, 'epoch': 2.35}
{'loss': 1.0218, 'grad_norm': 5.0446672439575195, 'learning_rate': 1.1779941003161953e-07, 'epoch': 2.36}
{'loss': 1.25, 'grad_norm': 2.6905457973480225, 'learning_rate': 1.159542490861693e-07, 'epoch': 2.36}
{'loss': 1.1539, 'grad_norm': 3.231065511703491, 'learning_rate': 1.1412175610596897e-07, 'epoch': 2.37}
{'loss': 1.1593, 'grad_norm': 3.0816311836242676, 'learning_rate': 1.1230199153683078e-07, 'epoch': 2.37}
{'loss': 1.2344, 'grad_norm': 10.035135269165039, 'learning_rate': 1.1049501540471323e-07, 'epoch': 2.38}
{'loss': 1.1305, 'grad_norm': 2.8184165954589844, 'learning_rate': 1.0870088731374139e-07, 'epoch': 2.38}
{'loss': 1.304, 'grad_norm': 3.3029606342315674, 'learning_rate': 1.0691966644423984e-07, 'epoch': 2.39}
{'loss': 1.4083, 'grad_norm': 4.085733413696289, 'learning_rate': 1.0515141155078138e-07, 'epoch': 2.39}
{'loss': 1.0754, 'grad_norm': 2.7490456104278564, 'learning_rate': 1.0339618096024943e-07, 'epoch': 2.4}
{'loss': 1.1043, 'grad_norm': 2.87536883354187, 'learning_rate': 1.016540325699124e-07, 'epoch': 2.41}
{'loss': 1.03, 'grad_norm': 3.3279836177825928, 'learning_rate': 9.992502384551576e-08, 'epoch': 2.41}
{'loss': 1.0207, 'grad_norm': 3.0505504608154297, 'learning_rate': 9.820921181938546e-08, 'epoch': 2.42}
{'loss': 1.0275, 'grad_norm': 2.916471242904663, 'learning_rate': 9.650665308854678e-08, 'epoch': 2.42}
{'loss': 1.0229, 'grad_norm': 2.9231488704681396, 'learning_rate': 9.48174038128578e-08, 'epoch': 2.43}
{'loss': 1.1784, 'grad_norm': 3.219006061553955, 'learning_rate': 9.314151971315664e-08, 'epoch': 2.43}
{'loss': 1.0587, 'grad_norm': 3.188244581222534, 'learning_rate': 9.147905606942363e-08, 'epoch': 2.44}
{'loss': 1.0402, 'grad_norm': 2.856393575668335, 'learning_rate': 8.983006771895763e-08, 'epoch': 2.44}
{'loss': 1.2666, 'grad_norm': 3.03692889213562, 'learning_rate': 8.81946090545676e-08, 'epoch': 2.45}
{'loss': 1.1042, 'grad_norm': 2.9820311069488525, 'learning_rate': 8.657273402277798e-08, 'epoch': 2.45}
{'loss': 1.3734, 'grad_norm': 2.608438014984131, 'learning_rate': 8.496449612204982e-08, 'epoch': 2.46}
{'loss': 1.2538, 'grad_norm': 2.865356922149658, 'learning_rate': 8.336994840101513e-08, 'epoch': 2.46}
{'loss': 1.2723, 'grad_norm': 3.49648380279541, 'learning_rate': 8.1789143456728e-08, 'epoch': 2.47}
{'loss': 1.0885, 'grad_norm': 3.2975988388061523, 'learning_rate': 8.022213343292955e-08, 'epoch': 2.47}
{'loss': 1.3043, 'grad_norm': 2.9918200969696045, 'learning_rate': 7.866897001832695e-08, 'epoch': 2.48}
{'loss': 1.0774, 'grad_norm': 7.488659381866455, 'learning_rate': 7.712970444489003e-08, 'epoch': 2.48}
{'loss': 1.1198, 'grad_norm': 4.941891193389893, 'learning_rate': 7.560438748615982e-08, 'epoch': 2.49}
{'loss': 1.1361, 'grad_norm': 3.5506503582000732, 'learning_rate': 7.409306945557487e-08, 'epoch': 2.49}
{'loss': 1.2083, 'grad_norm': 2.7855539321899414, 'learning_rate': 7.259580020481092e-08, 'epoch': 2.5}
{'loss': 0.9654, 'grad_norm': 2.8283531665802, 'learning_rate': 7.111262912213706e-08, 'epoch': 2.5}
{'loss': 1.2056, 'grad_norm': 5.446806907653809, 'learning_rate': 6.96436051307861e-08, 'epoch': 2.51}
{'loss': 1.1312, 'grad_norm': 3.7342400550842285, 'learning_rate': 6.81887766873413e-08, 'epoch': 2.51}
{'loss': 1.2488, 'grad_norm': 2.8912200927734375, 'learning_rate': 6.674819178013769e-08, 'epoch': 2.52}
{'loss': 1.1115, 'grad_norm': 3.0679433345794678, 'learning_rate': 6.532189792767922e-08, 'epoch': 2.52}
{'loss': 1.1747, 'grad_norm': 3.2953505516052246, 'learning_rate': 6.390994217707141e-08, 'epoch': 2.53}
{'loss': 1.1519, 'grad_norm': 4.736024856567383, 'learning_rate': 6.251237110246943e-08, 'epoch': 2.54}
{'loss': 1.2032, 'grad_norm': 2.811323881149292, 'learning_rate': 6.112923080354165e-08, 'epoch': 2.54}
{'loss': 1.0646, 'grad_norm': 2.8345699310302734, 'learning_rate': 5.976056690394959e-08, 'epoch': 2.55}
{'loss': 0.9879, 'grad_norm': 3.4297492504119873, 'learning_rate': 5.840642454984196e-08, 'epoch': 2.55}
{'loss': 1.086, 'grad_norm': 3.973128080368042, 'learning_rate': 5.706684840836673e-08, 'epoch': 2.56}
{'loss': 1.2819, 'grad_norm': 4.073806285858154, 'learning_rate': 5.574188266619695e-08, 'epoch': 2.56}
{'loss': 1.105, 'grad_norm': 3.3079113960266113, 'learning_rate': 5.4431571028073054e-08, 'epoch': 2.57}
{'loss': 1.0393, 'grad_norm': 2.7560982704162598, 'learning_rate': 5.31359567153622e-08, 'epoch': 2.57}
{'loss': 1.0914, 'grad_norm': 3.989513397216797, 'learning_rate': 5.185508246463161e-08, 'epoch': 2.58}
{'loss': 1.0447, 'grad_norm': 2.8672070503234863, 'learning_rate': 5.058899052623933e-08, 'epoch': 2.58}
{'loss': 1.022, 'grad_norm': 2.6810247898101807, 'learning_rate': 4.933772266294067e-08, 'epoch': 2.59}
{'loss': 1.1521, 'grad_norm': 2.6735246181488037, 'learning_rate': 4.810132014851026e-08, 'epoch': 2.59}
{'loss': 1.1755, 'grad_norm': 2.9995152950286865, 'learning_rate': 4.6879823766381e-08, 'epoch': 2.6}
{'loss': 1.0553, 'grad_norm': 2.8481836318969727, 'learning_rate': 4.5673273808298494e-08, 'epoch': 2.6}
{'loss': 1.2115, 'grad_norm': 2.8657124042510986, 'learning_rate': 4.4481710072992284e-08, 'epoch': 2.61}
{'loss': 1.1793, 'grad_norm': 2.9240987300872803, 'learning_rate': 4.3305171864862655e-08, 'epoch': 2.61}
{'loss': 1.1787, 'grad_norm': 3.0435874462127686, 'learning_rate': 4.214369799268497e-08, 'epoch': 2.62}
{'loss': 1.1927, 'grad_norm': 3.282274007797241, 'learning_rate': 4.099732676832818e-08, 'epoch': 2.62}
{'loss': 1.1428, 'grad_norm': 3.386986494064331, 'learning_rate': 3.9866096005492676e-08, 'epoch': 2.63}
{'loss': 1.2541, 'grad_norm': 3.5540435314178467, 'learning_rate': 3.8750043018461854e-08, 'epoch': 2.63}
{'loss': 1.0643, 'grad_norm': 9.358654022216797, 'learning_rate': 3.7649204620871346e-08, 'epoch': 2.64}
{'loss': 1.0373, 'grad_norm': 2.524505376815796, 'learning_rate': 3.656361712449557e-08, 'epoch': 2.64}
{'loss': 1.1257, 'grad_norm': 2.6205759048461914, 'learning_rate': 3.549331633804908e-08, 'epoch': 2.65}
{'loss': 1.1119, 'grad_norm': 2.8008553981781006, 'learning_rate': 3.443833756600567e-08, 'epoch': 2.65}
{'loss': 0.9741, 'grad_norm': 2.74320650100708, 'learning_rate': 3.3398715607433795e-08, 'epoch': 2.66}
{'loss': 1.0985, 'grad_norm': 3.0790395736694336, 'learning_rate': 3.237448475484922e-08, 'epoch': 2.66}
{'loss': 1.0266, 'grad_norm': 4.8201704025268555, 'learning_rate': 3.1365678793082826e-08, 'epoch': 2.67}
{'loss': 1.1422, 'grad_norm': 3.374826669692993, 'learning_rate': 3.037233099816705e-08, 'epoch': 2.68}
{'loss': 1.1684, 'grad_norm': 3.1315760612487793, 'learning_rate': 2.9394474136238246e-08, 'epoch': 2.68}
{'loss': 0.9927, 'grad_norm': 3.1105165481567383, 'learning_rate': 2.843214046245507e-08, 'epoch': 2.69}
{'loss': 1.248, 'grad_norm': 25.270753860473633, 'learning_rate': 2.748536171993565e-08, 'epoch': 2.69}
{'loss': 1.0214, 'grad_norm': 2.9538259506225586, 'learning_rate': 2.6554169138709558e-08, 'epoch': 2.7}
{'loss': 1.163, 'grad_norm': 2.863475799560547, 'learning_rate': 2.5638593434688218e-08, 'epoch': 2.7}
{'loss': 0.9982, 'grad_norm': 2.452584981918335, 'learning_rate': 2.4738664808651498e-08, 'epoch': 2.71}
{'loss': 1.2361, 'grad_norm': 2.8793962001800537, 'learning_rate': 2.3854412945251756e-08, 'epoch': 2.71}
{'loss': 1.3658, 'grad_norm': 3.903094530105591, 'learning_rate': 2.2985867012034365e-08, 'epoch': 2.72}
{'loss': 1.1524, 'grad_norm': 2.816079616546631, 'learning_rate': 2.213305565847573e-08, 'epoch': 2.72}
{'loss': 1.3209, 'grad_norm': 2.9978244304656982, 'learning_rate': 2.1296007015038365e-08, 'epoch': 2.73}
{'loss': 1.253, 'grad_norm': 3.2207987308502197, 'learning_rate': 2.047474869224286e-08, 'epoch': 2.73}
{'loss': 1.1173, 'grad_norm': 3.3296520709991455, 'learning_rate': 1.966930777975734e-08, 'epoch': 2.74}
{'loss': 0.9653, 'grad_norm': 4.755191326141357, 'learning_rate': 1.8879710845503604e-08, 'epoch': 2.74}
{'loss': 1.3413, 'grad_norm': 3.2416391372680664, 'learning_rate': 1.81059839347808e-08, 'epoch': 2.75}
{'loss': 1.0956, 'grad_norm': 5.5494384765625, 'learning_rate': 1.7348152569406748e-08, 'epoch': 2.75}
{'loss': 1.2101, 'grad_norm': 2.931553363800049, 'learning_rate': 1.660624174687547e-08, 'epoch': 2.76}
{'loss': 1.2888, 'grad_norm': 3.0103113651275635, 'learning_rate': 1.588027593953306e-08, 'epoch': 2.76}
{'loss': 1.1756, 'grad_norm': 2.7607455253601074, 'learning_rate': 1.517027909377028e-08, 'epoch': 2.77}
{'loss': 1.0595, 'grad_norm': 4.670892238616943, 'learning_rate': 1.4476274629232677e-08, 'epoch': 2.77}
{'loss': 1.2276, 'grad_norm': 3.1784980297088623, 'learning_rate': 1.3798285438048118e-08, 'epoch': 2.78}
{'loss': 1.2117, 'grad_norm': 2.996286392211914, 'learning_rate': 1.3136333884071704e-08, 'epoch': 2.78}
{'loss': 1.1178, 'grad_norm': 2.709106683731079, 'learning_rate': 1.2490441802148032e-08, 'epoch': 2.79}
{'loss': 1.2441, 'grad_norm': 2.947356939315796, 'learning_rate': 1.186063049739089e-08, 'epoch': 2.79}
{'loss': 1.0391, 'grad_norm': 3.639431953430176, 'learning_rate': 1.1246920744480692e-08, 'epoch': 2.8}
{'loss': 1.1302, 'grad_norm': 2.682616949081421, 'learning_rate': 1.0649332786979049e-08, 'epoch': 2.81}
{'loss': 1.0571, 'grad_norm': 2.8154265880584717, 'learning_rate': 1.0067886336661113e-08, 'epoch': 2.81}
{'loss': 1.153, 'grad_norm': 3.0069994926452637, 'learning_rate': 9.502600572865282e-09, 'epoch': 2.82}
{'loss': 1.1441, 'grad_norm': 2.847773790359497, 'learning_rate': 8.953494141860584e-09, 'epoch': 2.82}
{'loss': 1.2249, 'grad_norm': 5.049594402313232, 'learning_rate': 8.42058515623184e-09, 'epoch': 2.83}
{'loss': 1.1903, 'grad_norm': 2.493154764175415, 'learning_rate': 7.903891194281753e-09, 'epoch': 2.83}
{'loss': 1.2702, 'grad_norm': 7.103283882141113, 'learning_rate': 7.403429299451536e-09, 'epoch': 2.84}
{'loss': 1.1736, 'grad_norm': 3.355923891067505, 'learning_rate': 6.919215979758475e-09, 'epoch': 2.84}
{'loss': 1.1999, 'grad_norm': 2.739354133605957, 'learning_rate': 6.451267207251421e-09, 'epoch': 2.85}
{'loss': 1.2364, 'grad_norm': 3.120504379272461, 'learning_rate': 5.999598417484042e-09, 'epoch': 2.85}
{'loss': 1.1118, 'grad_norm': 3.1773219108581543, 'learning_rate': 5.5642245090055664e-09, 'epoch': 2.86}
{'loss': 1.0731, 'grad_norm': 24.885074615478516, 'learning_rate': 5.145159842869396e-09, 'epoch': 2.86}
{'loss': 1.2276, 'grad_norm': 2.8742337226867676, 'learning_rate': 4.742418242159485e-09, 'epoch': 2.87}
{'loss': 1.1189, 'grad_norm': 10.47349739074707, 'learning_rate': 4.356012991534097e-09, 'epoch': 2.87}
{'loss': 1.1853, 'grad_norm': 2.766819715499878, 'learning_rate': 3.985956836787985e-09, 'epoch': 2.88}
{'loss': 1.157, 'grad_norm': 2.716413736343384, 'learning_rate': 3.6322619844317282e-09, 'epoch': 2.88}
{'loss': 1.2684, 'grad_norm': 3.0024468898773193, 'learning_rate': 3.294940101289001e-09, 'epoch': 2.89}
{'loss': 1.1521, 'grad_norm': 2.9641520977020264, 'learning_rate': 2.974002314112045e-09, 'epoch': 2.89}
{'loss': 1.1998, 'grad_norm': 3.0103323459625244, 'learning_rate': 2.6694592092144642e-09, 'epoch': 2.9}
{'loss': 1.2036, 'grad_norm': 4.714664459228516, 'learning_rate': 2.3813208321218357e-09, 'epoch': 2.9}
{'loss': 1.1537, 'grad_norm': 2.9094552993774414, 'learning_rate': 2.1095966872407556e-09, 'epoch': 2.91}
{'loss': 1.1278, 'grad_norm': 3.2205188274383545, 'learning_rate': 1.8542957375451417e-09, 'epoch': 2.91}
{'loss': 0.9801, 'grad_norm': 3.440531015396118, 'learning_rate': 1.6154264042805287e-09, 'epoch': 2.92}
{'loss': 1.166, 'grad_norm': 4.294218063354492, 'learning_rate': 1.3929965666861776e-09, 'epoch': 2.92}
{'loss': 1.1877, 'grad_norm': 5.377525329589844, 'learning_rate': 1.187013561735617e-09, 'epoch': 2.93}
{'loss': 1.03, 'grad_norm': 4.9705095291137695, 'learning_rate': 9.97484183894115e-10, 'epoch': 2.94}
{'loss': 1.0134, 'grad_norm': 5.449610233306885, 'learning_rate': 8.244146848949141e-10, 'epoch': 2.94}
{'loss': 1.2203, 'grad_norm': 3.2167747020721436, 'learning_rate': 6.678107735328398e-10, 'epoch': 2.95}
{'loss': 1.0741, 'grad_norm': 2.7471346855163574, 'learning_rate': 5.276776154760631e-10, 'epoch': 2.95}
{'loss': 1.0446, 'grad_norm': 10.105093955993652, 'learning_rate': 4.0401983309568124e-10, 'epoch': 2.96}
{'loss': 1.1009, 'grad_norm': 2.7622761726379395, 'learning_rate': 2.968415053131723e-10, 'epoch': 2.96}
{'loss': 1.1248, 'grad_norm': 3.100080728530884, 'learning_rate': 2.061461674661147e-10, 'epoch': 2.97}
{'loss': 1.0571, 'grad_norm': 6.019531726837158, 'learning_rate': 1.3193681119116895e-10, 'epoch': 2.97}
{'loss': 1.0418, 'grad_norm': 2.815997362136841, 'learning_rate': 7.421588432576786e-11, 'epoch': 2.98}
{'loss': 1.2681, 'grad_norm': 2.8796727657318115, 'learning_rate': 3.298529082718105e-11, 'epoch': 2.98}
{'loss': 1.2252, 'grad_norm': 2.896230936050415, 'learning_rate': 8.246390709787388e-12, 'epoch': 2.99}
{'loss': 1.2352, 'grad_norm': 4.112131595611572, 'learning_rate': 0.0, 'epoch': 2.99}
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-576/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-576/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-576/model.safetensors.index.json.
2025-01-05 23:12:07,958 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-576/pytorch_model_fsdp.bin
2025-01-05 23:13:00,428 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-576/pytorch_model_fsdp.bin
2025-01-05 23:13:31,671 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-576/optimizer.bin
2025-01-05 23:14:55,483 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-576/optimizer.bin
Saving model checkpoint to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-576
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-576/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-576/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-576/model.safetensors.index.json.
2025-01-05 23:16:56,491 - INFO - Saving model to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-576/pytorch_model_fsdp.bin
2025-01-05 23:17:40,557 - INFO - Model saved to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-576/pytorch_model_fsdp.bin
2025-01-05 23:18:11,453 - INFO - Saving Optimizer state to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-576/optimizer.bin
2025-01-05 23:19:29,663 - INFO - Optimizer state saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/checkpoint-576/optimizer.bin


Training completed. Do not forget to share your model on huggingface.co/models =)


100%|| 576/576 [46:58<00:00,  4.89s/it]
{'train_runtime': 2820.3182, 'train_samples_per_second': 1.638, 'train_steps_per_second': 0.204, 'train_loss': 1.2267391776873007, 'epoch': 2.99}
Saving model checkpoint to /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/config.json
Configuration saved in /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 7 checkpoint shards. You can find where each parameters has been saved in the index located at /share/goyal/lio/knowledge_update/continued_pretraining/model/instruct-explicitnews_sft-train-lr1e-06-rt1-rr0.9-epochs3-blocksize2048-bs32-wd0.01-warmup0.05-new_knowledgenewhandpicked_rephrased5newslr5e06rt3rr0.1epochs2blocksize2048bs16wd0.01warmup0.05Llama3.18B_checkpoint762/model.safetensors.index.json.
